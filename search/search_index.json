{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#vector-databases-theory-engineering-and-frontiers","title":"Vector Databases \u2014 Theory, Engineering, and Frontiers","text":"<p>Welcome to the open-source technical book on vector database internals. This resource covers everything from the mathematical foundations of high-dimensional search to production-grade distributed system architectures.</p>"},{"location":"#what-youll-learn","title":"What You'll Learn","text":"<ul> <li> <p> Part I \u2014 Foundations</p> <p>High-dimensional geometry, ANN algorithms (HNSW, LSH, PQ), index\u2013storage trade-offs, query semantics, and vectorization pipelines.</p> <p> Start reading</p> </li> <li> <p> Part II \u2014 System Architecture</p> <p>Core components, storage engines, distributed sharding, hybrid search, hardware acceleration (SIMD/GPU/FPGA), and observability.</p> <p> Start reading</p> </li> <li> <p> Part III \u2014 Implementation Deep-Dive</p> <p>Build an HNSW store in Rust, GPU-accelerated PQ-IVF, transactional vector inserts, elastic scaling, and benchmark harnesses.</p> <p> Start reading</p> </li> <li> <p> Part IV \u2014 Advanced Topics &amp; Research Frontiers</p> <p>Privacy-preserving search, continual learning, Gen-AI agent pipelines, and future directions (learned indexing, vector SQL).</p> <p> Start reading</p> </li> </ul>"},{"location":"#who-this-book-is-for","title":"Who This Book Is For","text":"<ul> <li>ML/AI Engineers building retrieval-augmented generation (RAG) pipelines</li> <li>Database Engineers designing or evaluating vector storage systems</li> <li>Systems Programmers interested in high-performance search infrastructure</li> <li>Researchers exploring the frontier of approximate nearest neighbor search</li> <li>Students seeking a rigorous yet practical treatment of the field</li> </ul>"},{"location":"#how-to-use-this-book","title":"How to Use This Book","text":"<p>Each chapter is self-contained \u2014 you can read linearly or jump to any topic of interest. Chapters include:</p> <ul> <li>Mathematical notation rendered with MathJax ($L_2$, cosine similarity, etc.)</li> <li>Code examples in Python, Rust, and C++ with copy-to-clipboard</li> <li>Architecture diagrams built with Mermaid</li> <li>Admonitions highlighting key insights, warnings, and practical tips</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>This is an open-source project. Contributions are welcome! See the GitHub repository for how to contribute.</p>"},{"location":"api-reference/","title":"API Reference (C++ and Rust)","text":"","tags":["api","reference","cpp","rust"]},{"location":"api-reference/#api-reference-algorithms","title":"API Reference (Algorithms)","text":"<p>This reference documents the core algorithmic implementations that back the theoretical explanations throughout the book. All implementations are thoroughly commented specifically for educational reading.</p>","tags":["api","reference","cpp","rust"]},{"location":"api-reference/#1-c-distance-metrics","title":"1. C++ Distance Metrics","text":"<p>The backbone of any vector database is mathematical distance calculation. For production scale, raw scalar <code>for</code> loops are too slow, and AVX2/AVX-512 SIMD (Single Instruction, Multiple Data) intrinsically accelerated kernels are required.</p> src/cpp/distances.cpp<pre><code>/**\n * SIMD-optimized distance computations for vector search.\n *\n * Demonstrates how production vector databases accelerate\n * distance calculations using AVX2/AVX-512 intrinsics.\n *\n * Compile: g++ -O3 -mavx2 -mfma -o distances distances.cpp\n */\n\n#include &lt;cmath&gt;\n#include &lt;cstddef&gt;\n#include &lt;vector&gt;\n#include &lt;algorithm&gt;\n#include &lt;numeric&gt;\n\n/**\n * Naive L2 squared distance \u2014 scalar loop.\n * Complexity: O(d)\n */\nfloat l2_distance_naive(const float* x, const float* y, size_t d) {\n    float sum = 0.0f;\n    for (size_t i = 0; i &lt; d; ++i) {\n        float diff = x[i] - y[i];\n        sum += diff * diff;\n    }\n    return sum;\n}\n\n\n#ifdef __AVX2__\n#include &lt;immintrin.h&gt;\n\n/**\n * AVX2-optimized L2 squared distance.\n *\n * Processes 8 floats per iteration using 256-bit SIMD registers.\n * ~4-8x faster than scalar on modern CPUs.\n */\nfloat l2_distance_avx2(const float* x, const float* y, size_t d) {\n    __m256 sum = _mm256_setzero_ps();\n    size_t i = 0;\n\n    // Process 8 floats at a time\n    for (; i + 8 &lt;= d; i += 8) {\n        __m256 vx = _mm256_loadu_ps(x + i);\n        __m256 vy = _mm256_loadu_ps(y + i);\n        __m256 diff = _mm256_sub_ps(vx, vy);\n        sum = _mm256_fmadd_ps(diff, diff, sum);  // FMA: sum += diff * diff\n    }\n\n    // Horizontal sum of 8 floats in sum register\n    __m128 hi = _mm256_extractf128_ps(sum, 1);\n    __m128 lo = _mm256_castps256_ps128(sum);\n    __m128 sum128 = _mm_add_ps(lo, hi);\n    sum128 = _mm_hadd_ps(sum128, sum128);\n    sum128 = _mm_hadd_ps(sum128, sum128);\n    float result = _mm_cvtss_f32(sum128);\n\n    // Handle remaining elements\n    for (; i &lt; d; ++i) {\n        float diff = x[i] - y[i];\n        result += diff * diff;\n    }\n\n    return result;\n}\n#endif\n\n\n#ifdef __AVX2__\n/**\n * AVX2-optimized inner product.\n */\nfloat inner_product_avx2(const float* x, const float* y, size_t d) {\n    __m256 sum = _mm256_setzero_ps();\n    size_t i = 0;\n\n    for (; i + 8 &lt;= d; i += 8) {\n        __m256 vx = _mm256_loadu_ps(x + i);\n        __m256 vy = _mm256_loadu_ps(y + i);\n        sum = _mm256_fmadd_ps(vx, vy, sum);\n    }\n\n    __m128 hi = _mm256_extractf128_ps(sum, 1);\n    __m128 lo = _mm256_castps256_ps128(sum);\n    __m128 sum128 = _mm_add_ps(lo, hi);\n    sum128 = _mm_hadd_ps(sum128, sum128);\n    sum128 = _mm_hadd_ps(sum128, sum128);\n    float result = _mm_cvtss_f32(sum128);\n\n    for (; i &lt; d; ++i) {\n        result += x[i] * y[i];\n    }\n\n    return result;\n}\n#endif\n\n\n/**\n * Brute-force k-NN search \u2014 the baseline that all ANN\n * algorithms are compared against.\n *\n * Returns indices of k nearest vectors to query.\n */\nstruct SearchResult {\n    size_t index;\n    float distance;\n    bool operator&lt;(const SearchResult&amp; other) const {\n        return distance &lt; other.distance;\n    }\n};\n\nstd::vector&lt;SearchResult&gt; brute_force_knn(\n    const float* query,\n    const float* database,  // row-major: n \u00d7 d\n    size_t n,\n    size_t d,\n    size_t k\n) {\n    std::vector&lt;SearchResult&gt; results(n);\n    for (size_t i = 0; i &lt; n; ++i) {\n        results[i] = {i, l2_distance_naive(query, database + i * d, d)};\n    }\n\n    // Partial sort for top-k\n    std::partial_sort(\n        results.begin(),\n        results.begin() + std::min(k, n),\n        results.end()\n    );\n\n    results.resize(std::min(k, n));\n    return results;\n}\n</code></pre>","tags":["api","reference","cpp","rust"]},{"location":"api-reference/#2-c-locality-sensitive-hashing-lsh","title":"2. C++ Locality-Sensitive Hashing (LSH)","text":"<p>Locality-Sensitive Hashing uses random hyperplane projection to build probabilistic buckets. Similar vectors have a mathematically high probability of landing in the same bucket via identical binary signature patterns.</p> src/cpp/lsh.hpp<pre><code>/**\n * Locality-Sensitive Hashing (LSH) for approximate nearest neighbor search.\n *\n * Implements random-hyperplane LSH (cosine similarity) and\n * p-stable distribution LSH (Euclidean distance).\n *\n * Compile: g++ -std=c++17 -O3 -o lsh lsh.cpp\n */\n\n#pragma once\n\n#include &lt;algorithm&gt;\n#include &lt;cassert&gt;\n#include &lt;cmath&gt;\n#include &lt;cstddef&gt;\n#include &lt;functional&gt;\n#include &lt;numeric&gt;\n#include &lt;random&gt;\n#include &lt;string&gt;\n#include &lt;unordered_map&gt;\n#include &lt;unordered_set&gt;\n#include &lt;vector&gt;\n\n/**\n * Hash signature \u2014 a sequence of bits/ints that represents\n * a vector's position in a hash table.\n */\nstruct HashSignature {\n  std::vector&lt;int&gt; bits;\n\n  bool operator==(const HashSignature &amp;other) const {\n    return bits == other.bits;\n  }\n};\n\nstruct HashSignatureHash {\n  size_t operator()(const HashSignature &amp;sig) const {\n    size_t seed = sig.bits.size();\n    for (auto &amp;b : sig.bits) {\n      seed ^= std::hash&lt;int&gt;{}(b) + 0x9e3779b9 + (seed &lt;&lt; 6) + (seed &gt;&gt; 2);\n    }\n    return seed;\n  }\n};\n\n/**\n * Random Hyperplane LSH for cosine similarity.\n *\n * Each hash function: h(x) = sign(r \u00b7 x)\n * where r is a random Gaussian vector.\n *\n * Collision probability:\n *   Pr[h(x) = h(y)] = 1 - \u03b8(x,y) / \u03c0\n *\n * Parameters:\n *   dim         \u2014 dimensionality of input vectors\n *   num_tables  \u2014 number of hash tables L (more tables \u2192 higher recall)\n *   num_hashes  \u2014 hash bits per table k (more bits \u2192 higher precision)\n */\nclass RandomHyperplaneLSH {\npublic:\n  RandomHyperplaneLSH(size_t dim, size_t num_tables = 10, size_t num_hashes = 8)\n      : dim_(dim), num_tables_(num_tables), num_hashes_(num_hashes) {\n    std::mt19937 rng(42);\n    std::normal_distribution&lt;float&gt; normal(0.0f, 1.0f);\n\n    // Generate random hyperplanes for each table\n    hyperplanes_.resize(num_tables);\n    for (size_t t = 0; t &lt; num_tables; ++t) {\n      hyperplanes_[t].resize(num_hashes * dim);\n      for (auto &amp;val : hyperplanes_[t]) {\n        val = normal(rng);\n      }\n    }\n\n    tables_.resize(num_tables);\n  }\n\n  /**\n   * Build the index from a set of vectors.\n   */\n  void build(const std::vector&lt;std::vector&lt;float&gt;&gt; &amp;vectors) {\n    vectors_ = vectors;\n    for (auto &amp;table : tables_)\n      table.clear();\n\n    for (size_t i = 0; i &lt; vectors.size(); ++i) {\n      for (size_t t = 0; t &lt; num_tables_; ++t) {\n        auto sig = hash(vectors[i], t);\n        tables_[t][sig].push_back(i);\n      }\n    }\n  }\n\n  /**\n   * Query for k approximate nearest neighbors.\n   *\n   * 1. Hash query into each table\n   * 2. Collect all candidate IDs from matching buckets\n   * 3. Re-rank candidates by exact cosine similarity\n   */\n  std::vector&lt;size_t&gt; query(const std::vector&lt;float&gt; &amp;q, size_t k) const {\n    std::unordered_set&lt;size_t&gt; candidates;\n\n    for (size_t t = 0; t &lt; num_tables_; ++t) {\n      auto sig = hash(q, t);\n      auto it = tables_[t].find(sig);\n      if (it != tables_[t].end()) {\n        for (size_t idx : it-&gt;second) {\n          candidates.insert(idx);\n        }\n      }\n    }\n\n    // Re-rank by cosine similarity\n    std::vector&lt;std::pair&lt;float, size_t&gt;&gt; scored;\n    scored.reserve(candidates.size());\n    for (size_t idx : candidates) {\n      float sim = cosine_sim(q, vectors_[idx]);\n      scored.push_back({-sim, idx}); // negate for ascending sort\n    }\n    std::sort(scored.begin(), scored.end());\n\n    std::vector&lt;size_t&gt; result;\n    for (size_t i = 0; i &lt; std::min(k, scored.size()); ++i) {\n      result.push_back(scored[i].second);\n    }\n    return result;\n  }\n\n  size_t num_vectors() const { return vectors_.size(); }\n\nprivate:\n  HashSignature hash(const std::vector&lt;float&gt; &amp;vec, size_t table_idx) const {\n    HashSignature sig;\n    sig.bits.resize(num_hashes_);\n    for (size_t h = 0; h &lt; num_hashes_; ++h) {\n      float dot = 0.0f;\n      const float *plane = &amp;hyperplanes_[table_idx][h * dim_];\n      for (size_t d = 0; d &lt; dim_; ++d) {\n        dot += plane[d] * vec[d];\n      }\n      sig.bits[h] = (dot &gt; 0.0f) ? 1 : 0;\n    }\n    return sig;\n  }\n\n  static float cosine_sim(const std::vector&lt;float&gt; &amp;a,\n                          const std::vector&lt;float&gt; &amp;b) {\n    float dot = 0, na = 0, nb = 0;\n    for (size_t i = 0; i &lt; a.size(); ++i) {\n      dot += a[i] * b[i];\n      na += a[i] * a[i];\n      nb += b[i] * b[i];\n    }\n    float denom = std::sqrt(na) * std::sqrt(nb);\n    return (denom &gt; 1e-10f) ? dot / denom : 0.0f;\n  }\n\n  size_t dim_, num_tables_, num_hashes_;\n  std::vector&lt;std::vector&lt;float&gt;&gt; hyperplanes_; // [table][hash*dim + d]\n  std::vector&lt;\n      std::unordered_map&lt;HashSignature, std::vector&lt;size_t&gt;, HashSignatureHash&gt;&gt;\n      tables_;\n  std::vector&lt;std::vector&lt;float&gt;&gt; vectors_;\n};\n\n/**\n * p-stable distribution LSH for Euclidean distance.\n *\n * Hash function: h(x) = floor((a \u00b7 x + b) / w)\n * where a ~ N(0,I), b ~ Uniform(0,w).\n *\n * Parameters:\n *   bucket_width \u2014 width of hash buckets (w)\n */\nclass EuclideanLSH {\npublic:\n  EuclideanLSH(size_t dim, size_t num_tables = 10, size_t num_hashes = 8,\n               float bucket_width = 4.0f)\n      : dim_(dim), num_tables_(num_tables), num_hashes_(num_hashes),\n        w_(bucket_width) {\n    std::mt19937 rng(123);\n    std::normal_distribution&lt;float&gt; normal(0.0f, 1.0f);\n    std::uniform_real_distribution&lt;float&gt; uniform(0.0f, bucket_width);\n\n    projections_.resize(num_tables);\n    offsets_.resize(num_tables);\n    for (size_t t = 0; t &lt; num_tables; ++t) {\n      projections_[t].resize(num_hashes * dim);\n      offsets_[t].resize(num_hashes);\n      for (auto &amp;v : projections_[t])\n        v = normal(rng);\n      for (auto &amp;v : offsets_[t])\n        v = uniform(rng);\n    }\n    tables_.resize(num_tables);\n  }\n\n  void build(const std::vector&lt;std::vector&lt;float&gt;&gt; &amp;vectors) {\n    vectors_ = vectors;\n    for (auto &amp;table : tables_)\n      table.clear();\n\n    for (size_t i = 0; i &lt; vectors.size(); ++i) {\n      for (size_t t = 0; t &lt; num_tables_; ++t) {\n        auto sig = hash(vectors[i], t);\n        tables_[t][sig].push_back(i);\n      }\n    }\n  }\n\n  std::vector&lt;size_t&gt; query(const std::vector&lt;float&gt; &amp;q, size_t k) const {\n    std::unordered_set&lt;size_t&gt; candidates;\n    for (size_t t = 0; t &lt; num_tables_; ++t) {\n      auto sig = hash(q, t);\n      auto it = tables_[t].find(sig);\n      if (it != tables_[t].end()) {\n        for (size_t idx : it-&gt;second)\n          candidates.insert(idx);\n      }\n    }\n\n    std::vector&lt;std::pair&lt;float, size_t&gt;&gt; scored;\n    for (size_t idx : candidates) {\n      scored.push_back({l2_squared(q, vectors_[idx]), idx});\n    }\n    std::sort(scored.begin(), scored.end());\n\n    std::vector&lt;size_t&gt; result;\n    for (size_t i = 0; i &lt; std::min(k, scored.size()); ++i) {\n      result.push_back(scored[i].second);\n    }\n    return result;\n  }\n\nprivate:\n  HashSignature hash(const std::vector&lt;float&gt; &amp;vec, size_t table_idx) const {\n    HashSignature sig;\n    sig.bits.resize(num_hashes_);\n    for (size_t h = 0; h &lt; num_hashes_; ++h) {\n      float proj = offsets_[table_idx][h];\n      const float *a = &amp;projections_[table_idx][h * dim_];\n      for (size_t d = 0; d &lt; dim_; ++d)\n        proj += a[d] * vec[d];\n      sig.bits[h] = static_cast&lt;int&gt;(std::floor(proj / w_));\n    }\n    return sig;\n  }\n\n  static float l2_squared(const std::vector&lt;float&gt; &amp;a,\n                          const std::vector&lt;float&gt; &amp;b) {\n    float sum = 0;\n    for (size_t i = 0; i &lt; a.size(); ++i) {\n      float d = a[i] - b[i];\n      sum += d * d;\n    }\n    return sum;\n  }\n\n  size_t dim_, num_tables_, num_hashes_;\n  float w_;\n  std::vector&lt;std::vector&lt;float&gt;&gt; projections_;\n  std::vector&lt;std::vector&lt;float&gt;&gt; offsets_;\n  std::vector&lt;\n      std::unordered_map&lt;HashSignature, std::vector&lt;size_t&gt;, HashSignatureHash&gt;&gt;\n      tables_;\n  std::vector&lt;std::vector&lt;float&gt;&gt; vectors_;\n};\n</code></pre>","tags":["api","reference","cpp","rust"]},{"location":"api-reference/#3-c-product-quantization-pq","title":"3. C++ Product Quantization (PQ)","text":"<p>Product Quantization aggressively chunks high-dimensional vectors into $M$ sub-spaces, and trains a <code>k-means</code> dictionary codebook for each chunk. Memory footprint shrinks up to 96x.</p> src/cpp/pq.hpp<pre><code>/**\n * Product Quantization (PQ) for vector compression and approximate search.\n *\n * Decomposes d-dimensional vectors into M subspaces and quantizes\n * each independently using k-means clustering.\n *\n * Compile: g++ -std=c++17 -O3 -o pq pq.hpp\n */\n\n#pragma once\n\n#include &lt;algorithm&gt;\n#include &lt;cassert&gt;\n#include &lt;cmath&gt;\n#include &lt;cstdint&gt;\n#include &lt;limits&gt;\n#include &lt;numeric&gt;\n#include &lt;random&gt;\n#include &lt;vector&gt;\n\n/**\n * Product Quantizer.\n *\n * Compresses d-dimensional float vectors into M bytes (one code per subspace).\n *\n * Compression ratio: d \u00d7 4 bytes \u2192 M bytes (e.g. 128-dim \u00d7 4B = 512B \u2192 8B).\n *\n * Workflow:\n *   1. train()  \u2014 learn M codebooks of K=256 centroids each via k-means\n *   2. encode() \u2014 compress vectors to PQ codes (M uint8 per vector)\n *   3. search() \u2014 approximate distance using ADC lookup tables\n *\n * Asymmetric Distance Computation (ADC):\n *   dist(q, x\u0303)\u00b2 \u2248 \u03a3_m || q^(m) - c_{code_m}^(m) ||\u00b2\n *   Precompute a (M \u00d7 K) distance table, then M lookups per candidate.\n */\nclass ProductQuantizer {\npublic:\n  ProductQuantizer(size_t dim, size_t M = 8, size_t K = 256)\n      : dim_(dim), M_(M), K_(K), ds_(dim / M) {\n    assert(dim % M == 0 &amp;&amp; \"dim must be divisible by M\");\n    codebooks_.resize(\n        M, std::vector&lt;std::vector&lt;float&gt;&gt;(K, std::vector&lt;float&gt;(ds_)));\n  }\n\n  /**\n   * Train codebooks with k-means on each subspace.\n   */\n  void train(const std::vector&lt;std::vector&lt;float&gt;&gt; &amp;data, size_t n_iter = 25) {\n    std::mt19937 rng(42);\n    size_t n = data.size();\n\n    for (size_t m = 0; m &lt; M_; ++m) {\n      // Extract sub-vectors for subspace m\n      std::vector&lt;std::vector&lt;float&gt;&gt; sub(n, std::vector&lt;float&gt;(ds_));\n      for (size_t i = 0; i &lt; n; ++i) {\n        for (size_t d = 0; d &lt; ds_; ++d) {\n          sub[i][d] = data[i][m * ds_ + d];\n        }\n      }\n\n      // Initialize centroids randomly\n      std::vector&lt;size_t&gt; indices(n);\n      std::iota(indices.begin(), indices.end(), 0);\n      std::shuffle(indices.begin(), indices.end(), rng);\n      for (size_t k = 0; k &lt; K_; ++k) {\n        codebooks_[m][k] = sub[indices[k % n]];\n      }\n\n      // k-means iterations\n      std::vector&lt;size_t&gt; assignments(n);\n      for (size_t iter = 0; iter &lt; n_iter; ++iter) {\n        // Assign\n        for (size_t i = 0; i &lt; n; ++i) {\n          float best_dist = std::numeric_limits&lt;float&gt;::max();\n          for (size_t k = 0; k &lt; K_; ++k) {\n            float d = l2_sq(sub[i], codebooks_[m][k]);\n            if (d &lt; best_dist) {\n              best_dist = d;\n              assignments[i] = k;\n            }\n          }\n        }\n\n        // Update centroids\n        std::vector&lt;std::vector&lt;float&gt;&gt; sums(K_, std::vector&lt;float&gt;(ds_, 0));\n        std::vector&lt;size_t&gt; counts(K_, 0);\n        for (size_t i = 0; i &lt; n; ++i) {\n          size_t k = assignments[i];\n          counts[k]++;\n          for (size_t d = 0; d &lt; ds_; ++d) {\n            sums[k][d] += sub[i][d];\n          }\n        }\n        for (size_t k = 0; k &lt; K_; ++k) {\n          if (counts[k] &gt; 0) {\n            for (size_t d = 0; d &lt; ds_; ++d) {\n              codebooks_[m][k][d] = sums[k][d] / counts[k];\n            }\n          }\n        }\n      }\n    }\n    trained_ = true;\n  }\n\n  /**\n   * Encode vectors to PQ codes (M uint8 per vector).\n   */\n  std::vector&lt;std::vector&lt;uint8_t&gt;&gt;\n  encode(const std::vector&lt;std::vector&lt;float&gt;&gt; &amp;data) const {\n    assert(trained_);\n    size_t n = data.size();\n    std::vector&lt;std::vector&lt;uint8_t&gt;&gt; codes(n, std::vector&lt;uint8_t&gt;(M_));\n\n    for (size_t i = 0; i &lt; n; ++i) {\n      for (size_t m = 0; m &lt; M_; ++m) {\n        float best_dist = std::numeric_limits&lt;float&gt;::max();\n        uint8_t best_k = 0;\n        for (size_t k = 0; k &lt; K_; ++k) {\n          float d = 0;\n          for (size_t dd = 0; dd &lt; ds_; ++dd) {\n            float diff = data[i][m * ds_ + dd] - codebooks_[m][k][dd];\n            d += diff * diff;\n          }\n          if (d &lt; best_dist) {\n            best_dist = d;\n            best_k = static_cast&lt;uint8_t&gt;(k);\n          }\n        }\n        codes[i][m] = best_k;\n      }\n    }\n    return codes;\n  }\n\n  /**\n   * Decode PQ codes back to approximate vectors.\n   */\n  std::vector&lt;float&gt; decode(const std::vector&lt;uint8_t&gt; &amp;code) const {\n    assert(trained_);\n    std::vector&lt;float&gt; vec(dim_);\n    for (size_t m = 0; m &lt; M_; ++m) {\n      for (size_t d = 0; d &lt; ds_; ++d) {\n        vec[m * ds_ + d] = codebooks_[m][code[m]][d];\n      }\n    }\n    return vec;\n  }\n\n  /**\n   * Asymmetric Distance Computation (ADC) search.\n   *\n   * 1. Build distance table: dist_table[m][k] = ||q_m - c_mk||\u00b2\n   * 2. For each database code, sum M table lookups\n   * 3. Return top-k nearest\n   *\n   * Complexity: O(M\u00b7K\u00b7ds) to build table + O(n\u00b7M) to scan\n   */\n  struct SearchResult {\n    float distance;\n    size_t id;\n    bool operator&lt;(const SearchResult &amp;o) const {\n      return distance &lt; o.distance;\n    }\n  };\n\n  std::vector&lt;SearchResult&gt;\n  search_adc(const std::vector&lt;float&gt; &amp;query,\n             const std::vector&lt;std::vector&lt;uint8_t&gt;&gt; &amp;codes, size_t k) const {\n    assert(trained_);\n    size_t n = codes.size();\n\n    // Precompute distance table: M \u00d7 K\n    std::vector&lt;std::vector&lt;float&gt;&gt; dist_table(M_, std::vector&lt;float&gt;(K_));\n    for (size_t m = 0; m &lt; M_; ++m) {\n      for (size_t kk = 0; kk &lt; K_; ++kk) {\n        float d = 0;\n        for (size_t dd = 0; dd &lt; ds_; ++dd) {\n          float diff = query[m * ds_ + dd] - codebooks_[m][kk][dd];\n          d += diff * diff;\n        }\n        dist_table[m][kk] = d;\n      }\n    }\n\n    // Compute approximate distances via table lookups\n    std::vector&lt;SearchResult&gt; results(n);\n    for (size_t i = 0; i &lt; n; ++i) {\n      float d = 0;\n      for (size_t m = 0; m &lt; M_; ++m) {\n        d += dist_table[m][codes[i][m]];\n      }\n      results[i] = {std::sqrt(d), i};\n    }\n\n    // Partial sort for top-k\n    k = std::min(k, n);\n    std::partial_sort(results.begin(), results.begin() + k, results.end());\n    results.resize(k);\n    return results;\n  }\n\nprivate:\n  static float l2_sq(const std::vector&lt;float&gt; &amp;a, const std::vector&lt;float&gt; &amp;b) {\n    float s = 0;\n    for (size_t i = 0; i &lt; a.size(); ++i) {\n      float d = a[i] - b[i];\n      s += d * d;\n    }\n    return s;\n  }\n\n  size_t dim_, M_, K_, ds_;\n  bool trained_ = false;\n  // codebooks_[m][k][d] = centroid value\n  std::vector&lt;std::vector&lt;std::vector&lt;float&gt;&gt;&gt; codebooks_;\n};\n</code></pre>","tags":["api","reference","cpp","rust"]},{"location":"api-reference/#4-c-hnsw-graph","title":"4. C++ HNSW Graph","text":"<p>Hierarchical Navigable Small World graphs are multi-layer proximity graphs. Search jumps layer by layer (skipping massive distances like an interstate highway) until dropping to Layer 0 to execute dense local navigation.</p> src/cpp/hnsw.hpp<pre><code>/**\n * Hierarchical Navigable Small World (HNSW) graph index.\n *\n * A complete C++ implementation of the HNSW algorithm.\n * Reference: Malkov &amp; Yashunin, \"Efficient and Robust Approximate\n *            Nearest Neighbor Search Using HNSW Graphs\" (2020)\n *\n * Compile: g++ -std=c++17 -O3 -o hnsw hnsw.hpp\n */\n\n#pragma once\n\n#include &lt;algorithm&gt;\n#include &lt;cassert&gt;\n#include &lt;cmath&gt;\n#include &lt;cstddef&gt;\n#include &lt;limits&gt;\n#include &lt;queue&gt;\n#include &lt;random&gt;\n#include &lt;unordered_set&gt;\n#include &lt;vector&gt;\n\n/**\n * HNSW Index for approximate nearest neighbor search.\n *\n * Builds a multi-layer navigable small-world graph.\n * - Layer 0 is the densest (all nodes present)\n * - Higher layers are exponentially sparser\n * - Search descends from top layer greedily, then does\n *   beam search at layer 0.\n *\n * Template parameters are avoided for clarity; uses float vectors.\n *\n * Key parameters:\n *   M               \u2014 max edges per node per layer (default 16)\n *   M_max0          \u2014 max edges at layer 0 (default 2*M)\n *   ef_construction  \u2014 beam width during build\n *   ef_search        \u2014 beam width during query\n *   mL              \u2014 level generation factor = 1/ln(M)\n */\nclass HNSWIndex {\npublic:\n  struct SearchResult {\n    float distance;\n    size_t id;\n    bool operator&gt;(const SearchResult &amp;o) const {\n      return distance &gt; o.distance;\n    }\n    bool operator&lt;(const SearchResult &amp;o) const {\n      return distance &lt; o.distance;\n    }\n  };\n\n  HNSWIndex(size_t dim, size_t M = 16, size_t ef_construction = 200,\n            size_t ef_search = 50)\n      : dim_(dim), M_(M), M_max0_(2 * M), ef_construction_(ef_construction),\n        ef_search_(ef_search), mL_(1.0 / std::log(static_cast&lt;double&gt;(M))),\n        entry_point_(NONE), max_layer_(0), rng_(42), uniform_(0.0, 1.0) {}\n\n  /**\n   * Insert a single vector into the index.\n   *\n   * Algorithm (simplified):\n   * 1. Draw random level l ~ Geometric(mL)\n   * 2. From entry point, greedily descend to layer l+1\n   * 3. At each layer [l..0], beam-search for ef_construction\n   *    neighbors and add bidirectional edges\n   */\n  size_t insert(const std::vector&lt;float&gt; &amp;vec) {\n    size_t id = vectors_.size();\n    vectors_.push_back(vec);\n\n    int level = random_level();\n\n    // Grow graph layers if needed\n    while (static_cast&lt;int&gt;(graph_.size()) &lt;= level) {\n      graph_.emplace_back();\n    }\n\n    // First element\n    if (entry_point_ == NONE) {\n      entry_point_ = id;\n      max_layer_ = level;\n      for (int l = 0; l &lt;= level; ++l) {\n        if (graph_[l].size() &lt;= id)\n          graph_[l].resize(id + 1);\n      }\n      return id;\n    }\n\n    // Ensure node has adjacency lists at all its layers\n    for (int l = 0; l &lt;= level; ++l) {\n      if (graph_[l].size() &lt;= id)\n        graph_[l].resize(id + 1);\n    }\n\n    size_t current = entry_point_;\n\n    // Phase 1: Greedy descent from max_layer to level+1\n    for (int l = max_layer_; l &gt; level; --l) {\n      auto nearest = search_layer(vec, current, 1, l);\n      if (!nearest.empty())\n        current = nearest[0].id;\n    }\n\n    // Phase 2: Insert at layers [min(level, max_layer)..0]\n    for (int l = std::min(level, max_layer_); l &gt;= 0; --l) {\n      auto candidates = search_layer(vec, current, ef_construction_, l);\n      size_t M_max = (l == 0) ? M_max0_ : M_;\n      auto neighbors = select_neighbors(candidates, M_max);\n\n      // Add bidirectional edges\n      for (auto &amp;nb : neighbors) {\n        graph_[l][id].push_back(nb.id);\n        graph_[l][nb.id].push_back(id);\n\n        // Prune neighbor if over capacity\n        if (graph_[l][nb.id].size() &gt; M_max) {\n          prune(nb.id, l, M_max);\n        }\n      }\n\n      if (!candidates.empty())\n        current = candidates[0].id;\n    }\n\n    if (level &gt; max_layer_) {\n      entry_point_ = id;\n      max_layer_ = level;\n    }\n\n    return id;\n  }\n\n  /**\n   * Search for k approximate nearest neighbors.\n   *\n   * 1. Greedy descent from top layer to layer 1\n   * 2. Beam search at layer 0 with ef = max(ef_search, k)\n   * 3. Return top-k results sorted by distance\n   */\n  std::vector&lt;SearchResult&gt; search(const std::vector&lt;float&gt; &amp;query,\n                                   size_t k) const {\n    if (entry_point_ == NONE)\n      return {};\n\n    size_t current = entry_point_;\n\n    // Descend from top\n    for (int l = max_layer_; l &gt; 0; --l) {\n      auto nearest = search_layer(query, current, 1, l);\n      if (!nearest.empty())\n        current = nearest[0].id;\n    }\n\n    size_t ef = std::max(ef_search_, k);\n    auto results = search_layer(query, current, ef, 0);\n\n    // Take sqrt for actual Euclidean distances\n    if (results.size() &gt; k)\n      results.resize(k);\n    for (auto &amp;r : results) {\n      r.distance = std::sqrt(r.distance);\n    }\n    return results;\n  }\n\n  /**\n   * Bulk insert all vectors.\n   */\n  void build(const std::vector&lt;std::vector&lt;float&gt;&gt; &amp;vectors) {\n    for (const auto &amp;v : vectors)\n      insert(v);\n  }\n\n  size_t size() const { return vectors_.size(); }\n  size_t num_layers() const { return graph_.size(); }\n\n  void set_ef_search(size_t ef) { ef_search_ = ef; }\n\nprivate:\n  static constexpr size_t NONE = std::numeric_limits&lt;size_t&gt;::max();\n\n  float distance_sq(const std::vector&lt;float&gt; &amp;a,\n                    const std::vector&lt;float&gt; &amp;b) const {\n    float sum = 0.0f;\n    for (size_t i = 0; i &lt; dim_; ++i) {\n      float d = a[i] - b[i];\n      sum += d * d;\n    }\n    return sum;\n  }\n\n  int random_level() {\n    return static_cast&lt;int&gt;(-std::log(uniform_(rng_)) * mL_);\n  }\n\n  /**\n   * Beam search in a single layer.\n   * Returns up to ef nearest elements, sorted by distance (ascending).\n   */\n  std::vector&lt;SearchResult&gt; search_layer(const std::vector&lt;float&gt; &amp;query,\n                                         size_t entry, size_t ef,\n                                         int layer) const {\n    if (layer &gt;= static_cast&lt;int&gt;(graph_.size()))\n      return {};\n    if (entry &gt;= graph_[layer].size())\n      return {};\n\n    std::unordered_set&lt;size_t&gt; visited;\n    visited.insert(entry);\n\n    float d = distance_sq(query, vectors_[entry]);\n\n    // candidates: min-heap (closest first)\n    std::priority_queue&lt;SearchResult, std::vector&lt;SearchResult&gt;,\n                        std::greater&lt;SearchResult&gt;&gt;\n        candidates;\n    // results: max-heap (farthest first, for bounding)\n    std::priority_queue&lt;SearchResult&gt; results;\n\n    candidates.push({d, entry});\n    results.push({d, entry});\n\n    while (!candidates.empty()) {\n      auto [c_dist, c_id] = candidates.top();\n      candidates.pop();\n\n      float farthest = results.top().distance;\n      if (c_dist &gt; farthest)\n        break;\n\n      // Expand neighbors\n      if (c_id &lt; graph_[layer].size()) {\n        for (size_t nb : graph_[layer][c_id]) {\n          if (visited.count(nb))\n            continue;\n          visited.insert(nb);\n\n          float nb_dist = distance_sq(query, vectors_[nb]);\n          farthest = results.top().distance;\n\n          if (nb_dist &lt; farthest || results.size() &lt; ef) {\n            candidates.push({nb_dist, nb});\n            results.push({nb_dist, nb});\n            if (results.size() &gt; ef)\n              results.pop();\n          }\n        }\n      }\n    }\n\n    // Extract sorted results\n    std::vector&lt;SearchResult&gt; out;\n    out.reserve(results.size());\n    while (!results.empty()) {\n      out.push_back(results.top());\n      results.pop();\n    }\n    std::sort(out.begin(), out.end());\n    return out;\n  }\n\n  std::vector&lt;SearchResult&gt;\n  select_neighbors(const std::vector&lt;SearchResult&gt; &amp;candidates,\n                   size_t M) const {\n    auto sorted = candidates;\n    std::sort(sorted.begin(), sorted.end());\n    if (sorted.size() &gt; M)\n      sorted.resize(M);\n    return sorted;\n  }\n\n  void prune(size_t node, int layer, size_t M_max) {\n    auto &amp;adj = graph_[layer][node];\n    std::vector&lt;SearchResult&gt; scored;\n    for (size_t nb : adj) {\n      scored.push_back({distance_sq(vectors_[node], vectors_[nb]), nb});\n    }\n    std::sort(scored.begin(), scored.end());\n    adj.clear();\n    for (size_t i = 0; i &lt; std::min(M_max, scored.size()); ++i) {\n      adj.push_back(scored[i].id);\n    }\n  }\n\n  size_t dim_;\n  size_t M_, M_max0_;\n  size_t ef_construction_, ef_search_;\n  double mL_;\n  size_t entry_point_;\n  int max_layer_;\n\n  std::mt19937 rng_;\n  std::uniform_real_distribution&lt;double&gt; uniform_;\n\n  std::vector&lt;std::vector&lt;float&gt;&gt; vectors_;\n  // graph_[layer][node_id] = list of neighbor IDs\n  std::vector&lt;std::vector&lt;std::vector&lt;size_t&gt;&gt;&gt; graph_;\n};\n</code></pre>","tags":["api","reference","cpp","rust"]},{"location":"api-reference/#5-c-inverted-file-index-ivf","title":"5. C++ Inverted File Index (IVF)","text":"<p>IVF uses k-means to slice the entire valid embedding space into distinct \"Voronoi Cells\". During an incoming query, the database routes the query to the <code>nprobe</code> nearest cell centroids, entirely skipping computation in faraway regions.</p> src/cpp/ivf.hpp<pre><code>/**\n * Inverted File Index (IVF) for approximate nearest neighbor search.\n *\n * Partitions vector space into Voronoi cells using k-means,\n * then searches only the nprobe nearest cells at query time.\n *\n * Compile: g++ -std=c++17 -O3 -o ivf ivf.hpp\n */\n\n#pragma once\n\n#include &lt;algorithm&gt;\n#include &lt;cassert&gt;\n#include &lt;cmath&gt;\n#include &lt;limits&gt;\n#include &lt;numeric&gt;\n#include &lt;random&gt;\n#include &lt;vector&gt;\n\n/**\n * Inverted File Index.\n *\n * Search complexity: O(nprobe \u00d7 n/nlist \u00d7 d) vs O(n \u00d7 d) brute-force.\n *\n * Parameters:\n *   nlist  \u2014 number of Voronoi cells (centroids)\n *   nprobe \u2014 number of cells to search (trade-off: recall vs speed)\n */\nclass IVFIndex {\npublic:\n  struct SearchResult {\n    float distance;\n    size_t id;\n    bool operator&lt;(const SearchResult &amp;o) const {\n      return distance &lt; o.distance;\n    }\n  };\n\n  IVFIndex(size_t dim, size_t nlist = 100, size_t nprobe = 10)\n      : dim_(dim), nlist_(nlist), nprobe_(nprobe) {\n    inverted_lists_.resize(nlist);\n  }\n\n  /**\n   * Train centroids using k-means.\n   */\n  void train(const std::vector&lt;std::vector&lt;float&gt;&gt; &amp;data, size_t n_iter = 20) {\n    size_t n = data.size();\n    centroids_.resize(nlist_, std::vector&lt;float&gt;(dim_));\n\n    std::mt19937 rng(42);\n    std::vector&lt;size_t&gt; indices(n);\n    std::iota(indices.begin(), indices.end(), 0);\n    std::shuffle(indices.begin(), indices.end(), rng);\n\n    for (size_t c = 0; c &lt; nlist_; ++c) {\n      centroids_[c] = data[indices[c % n]];\n    }\n\n    std::vector&lt;size_t&gt; assignments(n);\n    for (size_t iter = 0; iter &lt; n_iter; ++iter) {\n      // Assign to nearest centroid\n      for (size_t i = 0; i &lt; n; ++i) {\n        float best = std::numeric_limits&lt;float&gt;::max();\n        for (size_t c = 0; c &lt; nlist_; ++c) {\n          float d = l2_sq(data[i], centroids_[c]);\n          if (d &lt; best) {\n            best = d;\n            assignments[i] = c;\n          }\n        }\n      }\n      // Update centroids\n      std::vector&lt;std::vector&lt;float&gt;&gt; sums(nlist_, std::vector&lt;float&gt;(dim_, 0));\n      std::vector&lt;size_t&gt; counts(nlist_, 0);\n      for (size_t i = 0; i &lt; n; ++i) {\n        counts[assignments[i]]++;\n        for (size_t d = 0; d &lt; dim_; ++d)\n          sums[assignments[i]][d] += data[i][d];\n      }\n      for (size_t c = 0; c &lt; nlist_; ++c) {\n        if (counts[c] &gt; 0) {\n          for (size_t d = 0; d &lt; dim_; ++d)\n            centroids_[c][d] = sums[c][d] / counts[c];\n        }\n      }\n    }\n    trained_ = true;\n  }\n\n  /**\n   * Add vectors to the inverted lists.\n   */\n  void add(const std::vector&lt;std::vector&lt;float&gt;&gt; &amp;data) {\n    assert(trained_);\n    vectors_ = data;\n    for (auto &amp;list : inverted_lists_)\n      list.clear();\n\n    for (size_t i = 0; i &lt; data.size(); ++i) {\n      float best = std::numeric_limits&lt;float&gt;::max();\n      size_t best_c = 0;\n      for (size_t c = 0; c &lt; nlist_; ++c) {\n        float d = l2_sq(data[i], centroids_[c]);\n        if (d &lt; best) {\n          best = d;\n          best_c = c;\n        }\n      }\n      inverted_lists_[best_c].push_back(i);\n    }\n  }\n\n  /**\n   * Search for k approximate nearest neighbors.\n   *\n   * 1. Find nprobe nearest centroids\n   * 2. Scan vectors in those cells\n   * 3. Return top-k\n   */\n  std::vector&lt;SearchResult&gt; search(const std::vector&lt;float&gt; &amp;query,\n                                   size_t k) const {\n    assert(trained_);\n\n    // Find nearest centroids\n    std::vector&lt;std::pair&lt;float, size_t&gt;&gt; centroid_dists(nlist_);\n    for (size_t c = 0; c &lt; nlist_; ++c) {\n      centroid_dists[c] = {l2_sq(query, centroids_[c]), c};\n    }\n    std::partial_sort(centroid_dists.begin(),\n                      centroid_dists.begin() + std::min(nprobe_, nlist_),\n                      centroid_dists.end());\n\n    // Collect and score candidates\n    std::vector&lt;SearchResult&gt; candidates;\n    for (size_t p = 0; p &lt; std::min(nprobe_, nlist_); ++p) {\n      size_t cell = centroid_dists[p].second;\n      for (size_t idx : inverted_lists_[cell]) {\n        float d = std::sqrt(l2_sq(query, vectors_[idx]));\n        candidates.push_back({d, idx});\n      }\n    }\n\n    k = std::min(k, candidates.size());\n    if (k &gt; 0) {\n      std::partial_sort(candidates.begin(), candidates.begin() + k,\n                        candidates.end());\n      candidates.resize(k);\n    }\n    return candidates;\n  }\n\n  void set_nprobe(size_t nprobe) { nprobe_ = nprobe; }\n  size_t size() const { return vectors_.size(); }\n\nprivate:\n  static float l2_sq(const std::vector&lt;float&gt; &amp;a, const std::vector&lt;float&gt; &amp;b) {\n    float s = 0;\n    for (size_t i = 0; i &lt; a.size(); ++i) {\n      float d = a[i] - b[i];\n      s += d * d;\n    }\n    return s;\n  }\n\n  size_t dim_, nlist_, nprobe_;\n  bool trained_ = false;\n  std::vector&lt;std::vector&lt;float&gt;&gt; centroids_;\n  std::vector&lt;std::vector&lt;size_t&gt;&gt; inverted_lists_;\n  std::vector&lt;std::vector&lt;float&gt;&gt; vectors_;\n};\n</code></pre>","tags":["api","reference","cpp","rust"]},{"location":"appendices/","title":"Appendices","text":""},{"location":"appendices/#appendices","title":"Appendices","text":"Appendix Contents A. Math Reference Key formulas and notation used throughout the book B. Glossary ~150 key terms defined C. Bibliography Annotated bibliography of canonical research papers D. DB Comparison Matrix Side-by-side comparison of open-source vector databases"},{"location":"appendices/bibliography/","title":"Appendix C \u2014 Bibliography","text":"","tags":["appendix","bibliography"]},{"location":"appendices/bibliography/#appendix-c-annotated-bibliography","title":"Appendix C \u2014 Annotated Bibliography","text":"","tags":["appendix","bibliography"]},{"location":"appendices/bibliography/#foundational-algorithms","title":"Foundational Algorithms","text":"<ol> <li> <p>Indyk, P., &amp; Motwani, R. (1998). Approximate Nearest Neighbors: Towards Removing the Curse of Dimensionality. STOC.     \u2014 Introduced the theoretical framework for LSH and $(1+\\epsilon)$-approximate NN.</p> </li> <li> <p>Malkov, Y. A., &amp; Yashunin, D. A. (2020). Efficient and Robust Approximate Nearest Neighbor Search Using Hierarchical Navigable Small World Graphs. IEEE TPAMI.     \u2014 The HNSW paper. Basis for most production vector database indexes.</p> </li> <li> <p>J\u00e9gou, H., Douze, M., &amp; Schmid, C. (2011). Product Quantization for Nearest Neighbor Search. IEEE TPAMI.     \u2014 Introduced PQ and ADC. Foundation of IVF-PQ used in FAISS.</p> </li> <li> <p>Johnson, J., Douze, M., &amp; J\u00e9gou, H. (2019). Billion-scale Similarity Search with GPUs. IEEE TBD.     \u2014 FAISS paper. GPU-accelerated IVF-PQ and flat search.</p> </li> <li> <p>Subramanya, S. J., et al. (2019). DiskANN: Fast Accurate Billion-point Nearest Neighbor Search on a Single Node. NeurIPS.     \u2014 SSD-resident graph search. Single-machine billion-scale.</p> </li> <li> <p>Guo, R., et al. (2020). Accelerating Large-Scale Inference with Anisotropic Vector Quantization. ICML.     \u2014 ScaNN: learned quantization that optimizes ranking, not just reconstruction.</p> </li> </ol>","tags":["appendix","bibliography"]},{"location":"appendices/bibliography/#geometry-and-theory","title":"Geometry and Theory","text":"<ol> <li> <p>Aggarwal, C. C., Hinneburg, A., &amp; Keim, D. A. (2001). On the Surprising Behavior of Distance Metrics in High Dimensional Spaces. ICDT.     \u2014 Empirical study of distance concentration.</p> </li> <li> <p>Johnson, W. B., &amp; Lindenstrauss, J. (1984). Extensions of Lipschitz Mappings into a Hilbert Space. Contemporary Mathematics.     \u2014 The JL lemma: random projections preserve distances.</p> </li> <li> <p>Blum, A., Hopcroft, J., &amp; Kannan, R. (2020). Foundations of Data Science. Cambridge University Press.     \u2014 Textbook chapter on high-dimensional geometry.</p> </li> </ol>","tags":["appendix","bibliography"]},{"location":"appendices/bibliography/#embeddings-and-nlp","title":"Embeddings and NLP","text":"<ol> <li> <p>Reimers, N., &amp; Gurevych, I. (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. EMNLP.     \u2014 Made BERT practical for semantic similarity search.</p> </li> <li> <p>Radford, A., et al. (2021). Learning Transferable Visual Models From Natural Language Supervision. ICML.     \u2014 CLIP: shared text-image embedding space.</p> </li> <li> <p>Muennighoff, N., et al. (2023). MTEB: Massive Text Embedding Benchmark. EACL.     \u2014 Standard benchmark for comparing embedding models.</p> </li> <li> <p>Kusupati, A., et al. (2022). Matryoshka Representation Learning. NeurIPS.     \u2014 Variable-dimension embeddings: any prefix is a valid embedding.</p> </li> </ol>","tags":["appendix","bibliography"]},{"location":"appendices/bibliography/#rag-and-applications","title":"RAG and Applications","text":"<ol> <li> <p>Lewis, P., et al. (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. NeurIPS.     \u2014 Introduced RAG: combining retrieval with generation.</p> </li> <li> <p>Gao, L., et al. (2023). Precise Zero-Shot Dense Retrieval without Relevance Labels. ACL.     \u2014 HyDE: generate hypothetical answers for better retrieval.</p> </li> <li> <p>Khattab, O., &amp; Zaharia, M. (2020). ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT. SIGIR.     \u2014 Multi-vector retrieval with MaxSim scoring.</p> </li> </ol>","tags":["appendix","bibliography"]},{"location":"appendices/bibliography/#systems","title":"Systems","text":"<ol> <li> <p>Wang, J., et al. (2021). Milvus: A Purpose-Built Vector Data Management System. SIGMOD.     \u2014 Architecture of a production vector database.</p> </li> <li> <p>Wei, J., et al. (2023). Filtered-DiskANN: Graph Algorithms for Approximate Nearest Neighbor Search with Filters. WWW.     \u2014 Combining metadata filtering with graph-based ANN.</p> </li> </ol>","tags":["appendix","bibliography"]},{"location":"appendices/bibliography/#privacy-and-security","title":"Privacy and Security","text":"<ol> <li> <p>Morris, J. X., et al. (2023). Text Embeddings Reveal (Almost) As Much As Text. EMNLP.     \u2014 Demonstrates embedding inversion attacks.</p> </li> <li> <p>Dwork, C. (2006). Differential Privacy. ICALP.     \u2014 Foundational framework for privacy-preserving data analysis.</p> </li> </ol>","tags":["appendix","bibliography"]},{"location":"appendices/bibliography/#benchmarks","title":"Benchmarks","text":"<ol> <li> <p>Aum\u00fcller, M., Bernhardsson, E., &amp; Faithfull, A. (2020). ANN-Benchmarks: A Benchmarking Tool for Approximate Nearest Neighbor Algorithms. Information Systems.     \u2014 Standard evaluation framework for ANN algorithms.</p> </li> <li> <p>Simhadri, H., et al. (2022). Results of the NeurIPS'21 Challenge on Billion-Scale ANN Search. NeurIPS.     \u2014 Big-ANN-Benchmarks: billion-scale evaluation.</p> </li> </ol>","tags":["appendix","bibliography"]},{"location":"appendices/comparison-matrix/","title":"Appendix D \u2014 Vector Database Comparison Matrix","text":"","tags":["appendix","comparison"]},{"location":"appendices/comparison-matrix/#appendix-d-vector-database-comparison-matrix","title":"Appendix D \u2014 Vector Database Comparison Matrix","text":"<p>Last updated: February 2025</p>","tags":["appendix","comparison"]},{"location":"appendices/comparison-matrix/#d1-architecture-comparison","title":"D.1 Architecture Comparison","text":"System Language License Architecture Deployment Pinecone Unknown Proprietary Managed cloud SaaS only Weaviate Go BSD-3 Monolithic binary Self-host / Cloud Qdrant Rust Apache-2.0 Segments + Raft Self-host / Cloud Milvus Go/C++ Apache-2.0 Microservices Self-host / Zilliz Cloud ChromaDB Python Apache-2.0 Embedded / Client-server Self-host pgvector C PostgreSQL PostgreSQL extension Anywhere PG runs LanceDB Rust Apache-2.0 Embedded, columnar Self-host Vespa Java/C++ Apache-2.0 Distributed platform Self-host / Cloud","tags":["appendix","comparison"]},{"location":"appendices/comparison-matrix/#d2-index-and-search-features","title":"D.2 Index and Search Features","text":"System HNSW IVF PQ/SQ Disk Index Hybrid Search Filtering Pinecone \u2705 \u2705 \u2705 \u2705 \u2705 (sparse-dense) \u2705 Weaviate \u2705 \u274c \u2705 (SQ) \u274c \u2705 (BM25 + vector) \u2705 Qdrant \u2705 \u274c \u2705 (SQ + PQ) \u2705 (mmap) \u2705 (sparse + dense) \u2705 Milvus \u2705 \u2705 \u2705 \u2705 (DiskANN) \u2705 \u2705 ChromaDB \u2705 \u274c \u274c \u274c \u274c \u2705 (basic) pgvector \u2705 \u2705 \u274c \u274c \u2705 (via PG FTS) \u2705 (SQL) LanceDB \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 (SQL) Vespa \u2705 \u274c \u274c \u274c \u2705 (native) \u2705","tags":["appendix","comparison"]},{"location":"appendices/comparison-matrix/#d3-scale-and-performance","title":"D.3 Scale and Performance","text":"System Max Vectors (Tested) Dimensions Replicas Sharding Pinecone Billions (managed) Up to 20K Automatic Automatic Weaviate ~100M per node Up to 65K \u2705 \u2705 (hash) Qdrant ~100M per node Up to 65K \u2705 (Raft) \u2705 Milvus Billions (cluster) Up to 32K \u2705 \u2705 (time-based) ChromaDB ~1M (embedded) No limit \u274c \u274c pgvector ~10M (practical) Up to 2000 PG replicas PG partitioning LanceDB ~100M Up to 2048 \u274c \u274c Vespa Billions (cluster) Up to 65K \u2705 \u2705","tags":["appendix","comparison"]},{"location":"appendices/comparison-matrix/#d4-api-and-ecosystem","title":"D.4 API and Ecosystem","text":"System API SDKs LangChain LlamaIndex Pinecone REST, gRPC Python, Node, Go, Java \u2705 \u2705 Weaviate REST, GraphQL, gRPC Python, JS, Go, Java \u2705 \u2705 Qdrant REST, gRPC Python, JS, Rust, Go \u2705 \u2705 Milvus gRPC, REST Python, Java, Go, Node \u2705 \u2705 ChromaDB Python, REST Python, JS \u2705 \u2705 pgvector SQL Any PG driver \u2705 \u2705 LanceDB Python, REST Python, JS \u2705 \u2705 Vespa REST, Java Python, Java \u2705 \u2705","tags":["appendix","comparison"]},{"location":"appendices/comparison-matrix/#d5-decision-guide","title":"D.5 Decision Guide","text":"<pre><code>flowchart TD\n    A{Already using PostgreSQL?}\n    A --&gt;|Yes| B[pgvector]\n    A --&gt;|No| C{Scale?}\n    C --&gt;|\"Under 1M, prototype\"| D[ChromaDB or LanceDB]\n    C --&gt;|\"1-100M, production\"| E{Self-host?}\n    C --&gt;|\"Over 100M, enterprise\"| F{Budget?}\n    E --&gt;|Yes| G[Qdrant or Weaviate]\n    E --&gt;|No| H[Pinecone]\n    F --&gt;|Managed| H\n    F --&gt;|Self-host| I[Milvus or Vespa]</code></pre>","tags":["appendix","comparison"]},{"location":"appendices/comparison-matrix/#d6-pricing-comparison-as-of-feb-2025","title":"D.6 Pricing Comparison (as of Feb 2025)","text":"<p>Prices are approximate</p> <p>Managed service pricing changes frequently. Self-hosted costs depend on instance type and provider.</p> System Free Tier Starting Price For 10M vectors (768-dim) Pinecone 100K vectors ~$70/month (s1.x1) ~$250/month Weaviate Cloud 1M vectors (sandbox) ~$25/month ~$300/month Qdrant Cloud 1M vectors (free) ~$9/month ~$150/month Zilliz Cloud (Milvus) 100K vectors ~$65/month ~$400/month pgvector (self-host) N/A EC2/RDS cost ~$200/month (r6g.xlarge)","tags":["appendix","comparison"]},{"location":"appendices/glossary/","title":"Appendix B \u2014 Glossary","text":"","tags":["appendix","glossary"]},{"location":"appendices/glossary/#appendix-b-glossary","title":"Appendix B \u2014 Glossary","text":"Term Definition ADC Asymmetric Distance Computation \u2014 PQ search where the query is not quantized ANN Approximate Nearest Neighbor \u2014 finding near-optimal closest vectors in sub-linear time AVX2 Advanced Vector Extensions 2 \u2014 Intel SIMD instruction set (256-bit registers) Beam search Graph traversal maintaining a priority queue of $ef$ best candidates BM25 Best Matching 25 \u2014 probabilistic lexical ranking function (keyword search) CLIP Contrastive Language-Image Pretraining \u2014 model producing shared text/image embeddings Codebook Set of centroid vectors used in quantization (typically $K = 256$ entries) ColBERT Contextualized Late Interaction over BERT \u2014 multi-vector retrieval model Compaction Background process that merges small segments and removes tombstones Cosine distance $1 - \\cos(\\theta)$ \u2014 distance derived from cosine similarity Cosine similarity $\\frac{\\mathbf{x} \\cdot \\mathbf{y}}{\\|\\mathbf{x}\\|\\|\\mathbf{y}\\|}$ \u2014 angular similarity between vectors Cross-encoder Model that scores (query, document) pairs jointly \u2014 more accurate than bi-encoder Curse of dimensionality Phenomenon where distances concentrate in high dimensions Dense embedding Fixed-length float vector from a neural encoder (e.g., 768-dim BERT) Differential privacy Privacy guarantee via calibrated noise addition DiskANN Microsoft's disk-resident graph-based ANN index (Vamana algorithm) ef_construction HNSW parameter: beam width during index building ef_search HNSW parameter: beam width during query Embedding Dense vector representation of data (text, image, etc.) FAISS Facebook AI Similarity Search \u2014 Meta's vector search library FMA Fused Multiply-Add \u2014 SIMD instruction: $a \\leftarrow a + b \\times c$ FP16 16-bit floating point FP32 32-bit floating point (standard) Ground truth Exact nearest neighbors computed by brute-force Hamming distance Number of bit positions where two binary vectors differ HBM High Bandwidth Memory \u2014 GPU memory technology HNSW Hierarchical Navigable Small World \u2014 multi-layer graph-based ANN algorithm Homomorphic encryption Encryption scheme allowing computation on ciphertext HyDE Hypothetical Document Embeddings \u2014 retrieve using LLM-generated answer INT8 (SQ8) 8-bit integer scalar quantization IVF Inverted File Index \u2014 partition-based ANN using Voronoi cells JL Lemma Johnson-Lindenstrauss \u2014 random projection preserves distances k-NN k-Nearest Neighbors \u2014 find $k$ closest vectors to a query KD-tree Space-partitioning tree using coordinate-aligned splits LSH Locality-Sensitive Hashing \u2014 hash-based ANN algorithm LSM tree Log-Structured Merge tree \u2014 write-optimized storage structure M HNSW parameter: maximum connections per node per layer Matryoshka embeddings Embeddings where any prefix of dimensions is a valid embedding MaxSim Maximum similarity \u2014 ColBERT scoring: per-token max cosine, then sum MIPS Maximum Inner Product Search mmap Memory-mapped file I/O \u2014 let OS manage file-to-memory paging MMD Maximum Mean Discrepancy \u2014 statistical test for distribution shift MTEB Massive Text Embedding Benchmark MVCC Multi-Version Concurrency Control \u2014 snapshot-based isolation nDCG Normalized Discounted Cumulative Gain \u2014 ranking quality metric nlist IVF parameter: number of Voronoi cells (clusters) nprobe IVF parameter: number of cells searched at query time NSG Navigating Spreading-out Graph \u2014 optimized proximity graph NUMA Non-Uniform Memory Access \u2014 multi-socket server memory topology PCA Principal Component Analysis \u2014 linear dimensionality reduction PQ Product Quantization \u2014 subspace decomposition for compression RAG Retrieval-Augmented Generation \u2014 LLM + vector search RDMA Remote Direct Memory Access \u2014 kernel-bypass network Recall@k Fraction of true $k$ nearest neighbors found by ANN RRF Reciprocal Rank Fusion \u2014 rank combination method Segment Self-contained, immutable index unit (sealed after reaching threshold) SIMD Single Instruction, Multiple Data \u2014 parallel CPU instructions Sparse vector Vector with mostly zero entries (e.g., TF-IDF, BM25) SQ4 4-bit scalar quantization t-SNE t-distributed Stochastic Neighbor Embedding \u2014 nonlinear visualization TEE Trusted Execution Environment \u2014 hardware-isolated enclave Tombstone Marker indicating a deleted vector (physical removal deferred) UMAP Uniform Manifold Approximation and Projection \u2014 nonlinear reduction Vamana Graph algorithm behind DiskANN VP-tree Vantage-Point tree \u2014 metric space partitioning WAL Write-Ahead Log \u2014 durability mechanism for writes","tags":["appendix","glossary"]},{"location":"appendices/math-reference/","title":"Appendix A \u2014 Math Reference","text":"","tags":["appendix","math"]},{"location":"appendices/math-reference/#appendix-a-math-reference","title":"Appendix A \u2014 Math Reference","text":"","tags":["appendix","math"]},{"location":"appendices/math-reference/#a1-linear-algebra","title":"A.1 Linear Algebra","text":"","tags":["appendix","math"]},{"location":"appendices/math-reference/#vectors-and-matrices","title":"Vectors and Matrices","text":"Notation Meaning $\\mathbf{x} \\in \\mathbb{R}^d$ Column vector of $d$ real numbers $\\|\\mathbf{x}\\|_p$ $L_p$ norm: $\\left(\\sum_i $\\|\\mathbf{x}\\|_2$ Euclidean norm: $\\sqrt{\\sum x_i^2}$ $\\mathbf{x} \\cdot \\mathbf{y}$ Dot product: $\\sum_i x_i y_i$ $X \\in \\mathbb{R}^{n \\times d}$ Matrix: $n$ rows, $d$ columns $X^T$ Transpose $X^{-1}$ Inverse (if square and non-singular) $\\text{tr}(A)$ Trace: $\\sum_i a_{ii}$ $\\det(A)$ Determinant","tags":["appendix","math"]},{"location":"appendices/math-reference/#eigendecomposition","title":"Eigendecomposition","text":"<p>For symmetric $A \\in \\mathbb{R}^{d \\times d}$:</p> $$ A = Q \\Lambda Q^T, \\quad Q^T Q = I $$ <p>where $\\Lambda = \\text{diag}(\\lambda_1, \\ldots, \\lambda_d)$ are eigenvalues and columns of $Q$ are eigenvectors.</p>","tags":["appendix","math"]},{"location":"appendices/math-reference/#svd-singular-value-decomposition","title":"SVD (Singular Value Decomposition)","text":"<p>Any $X \\in \\mathbb{R}^{n \\times d}$ can be decomposed:</p> $$ X = U \\Sigma V^T $$ <p>where $U \\in \\mathbb{R}^{n \\times n}$, $\\Sigma \\in \\mathbb{R}^{n \\times d}$ (diagonal), $V \\in \\mathbb{R}^{d \\times d}$. PCA uses the top-$k$ right singular vectors (columns of $V$).</p>","tags":["appendix","math"]},{"location":"appendices/math-reference/#a2-distance-metrics-summary","title":"A.2 Distance Metrics Summary","text":"Metric Formula Range Properties Euclidean ($L_2$) $\\sqrt{\\sum (x_i - y_i)^2}$ $[0, \\infty)$ Metric Manhattan ($L_1$) $\\sum x_i - y_i $ Chebyshev ($L_\\infty$) $\\max_i x_i - y_i $ Cosine distance $1 - \\frac{\\mathbf{x} \\cdot \\mathbf{y}}{\\|\\mathbf{x}\\|\\|\\mathbf{y}\\|}$ $[0, 2]$ Semimetric Inner product $\\sum x_i y_i$ $(-\\infty, \\infty)$ Not a distance Hamming $\\sum \\mathbb{1}[x_i \\neq y_i]$ $[0, d]$ Metric Jaccard $1 - \\frac{ A \\cap B }{","tags":["appendix","math"]},{"location":"appendices/math-reference/#a3-probability-and-statistics","title":"A.3 Probability and Statistics","text":"","tags":["appendix","math"]},{"location":"appendices/math-reference/#key-distributions","title":"Key Distributions","text":"Distribution PDF/PMF Mean Variance $\\mathcal{N}(\\mu, \\sigma^2)$ $\\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$ $\\mu$ $\\sigma^2$ $\\text{Uniform}(a, b)$ $\\frac{1}{b-a}$ $\\frac{a+b}{2}$ $\\frac{(b-a)^2}{12}$ $\\text{Geometric}(p)$ $(1-p)^{k-1} p$ $\\frac{1}{p}$ $\\frac{1-p}{p^2}$","tags":["appendix","math"]},{"location":"appendices/math-reference/#useful-concentration-inequalities","title":"Useful Concentration Inequalities","text":"<p>Hoeffding's inequality: For bounded independent random variables $X_i \\in [a_i, b_i]$:</p> $$ Pr\\left[\\left|\\frac{1}{n}\\sum X_i - \\mathbb{E}\\left[\\frac{1}{n}\\sum X_i\\right]\\right| \\geq t\\right] \\leq 2 \\exp\\left(-\\frac{2n^2 t^2}{\\sum (b_i - a_i)^2}\\right) $$ <p>Johnson-Lindenstrauss (simplified): Random projection into $k = O(\\epsilon^{-2} \\log n)$ dimensions preserves pairwise distances within $(1 \\pm \\epsilon)$.</p>","tags":["appendix","math"]},{"location":"appendices/math-reference/#a4-information-theory","title":"A.4 Information Theory","text":"Measure Formula Use in Vector DBs Entropy $H(X) = -\\sum p(x) \\log p(x)$ Quantization codebook quality KL Divergence $D_{KL}(P\\|Q) = \\sum p(x) \\log \\frac{p(x)}{q(x)}$ Distribution drift detection Mutual Information $I(X;Y) = H(X) - H(X Y)$","tags":["appendix","math"]},{"location":"appendices/math-reference/#a5-complexity-notation","title":"A.5 Complexity Notation","text":"Notation Meaning Example $O(f)$ Upper bound (worst case) Brute-force k-NN: $O(n \\cdot d)$ $\\Omega(f)$ Lower bound Any comparison-based search: $\\Omega(\\log n)$ $\\Theta(f)$ Tight bound Sorted array search: $\\Theta(\\log n)$ $\\tilde{O}(f)$ Ignoring log factors HNSW query: $\\tilde{O}(d \\cdot M)$","tags":["appendix","math"]},{"location":"part-1-foundations/","title":"Part I \u2014 Foundations","text":""},{"location":"part-1-foundations/#part-i-foundations","title":"Part I \u2014 Foundations","text":"<p>This section builds the theoretical and algorithmic bedrock needed to understand vector databases. We start with the geometry of high-dimensional spaces, work through the major families of approximate nearest neighbor algorithms, and finish with the practical engineering of data ingestion pipelines.</p>"},{"location":"part-1-foundations/#chapters","title":"Chapters","text":"# Chapter Key Topics 1 High-Dimensional Geometry Vector spaces, norms, cosine similarity, curse of dimensionality, dimensionality reduction 2 ANN Algorithms KD-Trees, LSH, HNSW, NSG, Product Quantization, Annoy, ScaNN, DiskANN 3 Index-Storage Trade-offs Memory hierarchies, cache-oblivious layouts, quantization vs. recall 4 Query Semantics &amp; Similarities k-NN vs. range search, hybrid predicates, multi-vector queries 5 Data Ingestion &amp; Vectorization Transformers, word2vec, multimodal embeddings, batch vs. streaming <p>Prerequisites</p> <p>Familiarity with linear algebra (vectors, matrices, inner products) and basic algorithm analysis (Big-O) is assumed. Appendix A provides a concise math refresher.</p>"},{"location":"part-1-foundations/ann-algorithms/","title":"Chapter 2 \u2014 Approximate Nearest Neighbor (ANN) Algorithms","text":"","tags":["foundations","algorithms","ann","hnsw","lsh"]},{"location":"part-1-foundations/ann-algorithms/#2-approximate-nearest-neighbor-ann-algorithms","title":"2. Approximate Nearest Neighbor (ANN) Algorithms","text":"<p>An exact, brute-force search requires calculating the distance between your query and every single vector in the database \u2014 an $O(n \\cdot d)$ operation per query. At a billion vectors and 768 dimensions, that represents thousands of gigabytes of raw math per query. </p> <p>To make real-time applications possible, vector databases abandon the idea of finding the absolute perfect nearest neighbor. Instead, they use algorithms that guarantee they will find an exceptionally close neighbor, just much faster. This chapter covers the four major families of Approximate Nearest Neighbor (ANN) algorithms that power the industry.</p>","tags":["foundations","algorithms","ann","hnsw","lsh"]},{"location":"part-1-foundations/ann-algorithms/#21-exact-vs-approximate-search","title":"2.1 Exact vs. Approximate Search","text":"","tags":["foundations","algorithms","ann","hnsw","lsh"]},{"location":"part-1-foundations/ann-algorithms/#why-approximate","title":"Why Approximate?","text":"Exact k-NN Approximate k-NN Complexity $O(n \\cdot d)$ $O(\\text{polylog}(n) \\cdot d)$ Search Time (1B vectors) Minutes Milliseconds Accuracy (Recall) 1.0 (Mathematically perfect) 0.90\u20130.99 (Tunable) <p>ELI5: Exact search is like finding a phone number by reading the phonebook from page 1 to page 500, checking every single name. Approximate search is like using an index to flip directly to the \"S\" section, and grabbing the first number that mostly matches your intent. It takes milliseconds, and 95% of the time, you get the person you actually wanted.</p> <p>The key metric measuring this accuracy is Recall@k: Out of the true mathematical top $k$ results, what percentage did our fast algorithm successfully find? </p> $$ \\text{Recall@}k = \\frac{|\\mathcal{R}_{\\text{approx}} \\cap \\mathcal{R}_{\\text{exact}}|}{k} $$ <p>For applications like Retrieval Augmented Generation (RAG) or recommendations, a recall of 95% is functionally indistinguishable to end-users from 100%.</p>","tags":["foundations","algorithms","ann","hnsw","lsh"]},{"location":"part-1-foundations/ann-algorithms/#22-tree-based-methods","title":"2.2 Tree-Based Methods","text":"<p>Tree-based methods slice the spatial universe into smaller and smaller boxes, helping queries narrow down where points live.</p>","tags":["foundations","algorithms","ann","hnsw","lsh"]},{"location":"part-1-foundations/ann-algorithms/#kd-trees","title":"KD-Trees","text":"<p>A KD-tree splits space by drawing a line strictly along one dimension (e.g., the X-axis), then looking inside those boxes and splitting them along another dimension (e.g., the Y-axis), and so on.</p> <pre><code>flowchart TD\n    subgraph KDSearch [\"KD-Tree Construction\"]\n        Root{\"Split Dimension 1&lt;br/&gt;(x\u2081 &lt; 5.0)\"}\n        L1{\"Split Dimension 2&lt;br/&gt;(x\u2082 &lt; 3.0)\"}\n        R1{\"Split Dimension 2&lt;br/&gt;(x\u2082 &lt; 7.0)\"}\n        Leaf1[\"Leaf Node A&lt;br/&gt;{p\u2081, p\u2082}\"]\n        Leaf2[\"Leaf Node B&lt;br/&gt;{p\u2083}\"]\n        Leaf3[\"Leaf Node C&lt;br/&gt;{p\u2084, p\u2085}\"]\n        Leaf4[\"Leaf Node D&lt;br/&gt;{p\u2086}\"]\n\n        Root -- Yes --&gt; L1\n        Root -- No --&gt; R1\n        L1 -- Yes --&gt; Leaf1\n        L1 -- No --&gt; Leaf2\n        R1 -- Yes --&gt; Leaf3\n        R1 -- No --&gt; Leaf4\n    end</code></pre> <p>Why KD-trees fail for AI</p> <p>KD-trees are brilliant for 2D maps or 3D video game rendering. However, in 768 dimensions, the \"boxes\" become incredibly complex. Because of the curse of dimensionality, a query point will often sit awkwardly close to hundreds of box boundaries. The algorithm is forced to backtrack and check almost every box, devolving purely into a slow brute-force scan.</p>","tags":["foundations","algorithms","ann","hnsw","lsh"]},{"location":"part-1-foundations/ann-algorithms/#ball-trees-and-vp-trees","title":"Ball Trees and VP-Trees","text":"<p>Instead of drawing straight lines to form boxes, Ball Trees draw intersecting circles (hyper-spheres) around clusters of points. </p> <p>Vantage-Point Trees (VP-Trees) pick a random central \"Vantage Point\" and split the data into \"points closer than the median\" and \"points further than the median\". These spherical approaches survive slightly better in higher dimensions than KD-trees, but still largely degrade past 50 dimensions.</p>","tags":["foundations","algorithms","ann","hnsw","lsh"]},{"location":"part-1-foundations/ann-algorithms/#23-hashing-based-methods-lsh","title":"2.3 Hashing-Based Methods (LSH)","text":"","tags":["foundations","algorithms","ann","hnsw","lsh"]},{"location":"part-1-foundations/ann-algorithms/#core-idea","title":"Core Idea","text":"<p>Traditional database hashing guarantees that <code>hash(\"apple\")</code> always equals exactly <code>hash(\"apple\")</code>, but <code>hash(\"app\")</code> yields a totally different random string. This is terrible for similarity searches.</p> <p>Locality-Sensitive Hashing (LSH) flips this logic. LSH creates a mathematical hash function where similar inputs produce identical outputs. </p> <p>ELI5: Imagine slicing a room full of people in half randomly with a laser pointer. You assign everyone on the left a <code>0</code> and everyone on the right a <code>1</code>. You do this 5 times from different angles. If Bob and Alice are standing right next to each other, there is a very high probability they will end up with the exact same 5-digit code (e.g., <code>10110</code>). The query just calculates its own code, goes to the <code>10110</code> bucket, and only compares distances against the people inside that bucket.</p>","tags":["foundations","algorithms","ann","hnsw","lsh"]},{"location":"part-1-foundations/ann-algorithms/#random-hyperplane-lsh-cosine-similarity","title":"Random Hyperplane LSH (Cosine Similarity)","text":"<p>Each slice (hash function) tests which side of a random plane a vector sits on:</p> $$ h(\\mathbf{x}) = \\text{sign}(\\mathbf{r} \\cdot \\mathbf{x}), \\quad \\mathbf{r} \\sim \\mathcal{N}(0, I_d) $$","tags":["foundations","algorithms","ann","hnsw","lsh"]},{"location":"part-1-foundations/ann-algorithms/#multi-table-routing","title":"Multi-Table Routing","text":"<p>To prevent false negatives (Alice and Bob accidentally getting split by a laser), we build multiple tables. If a point shares a bucket in at least one out of $L$ tables, we consider it a candidate.</p> <pre><code>flowchart LR\n    Q[Query Vector] --&gt; HashFunc[\"Calculate LSH Hashes\"]\n    HashFunc --&gt; Table1[\"Hash Table 1&lt;br/&gt;Bucket '100'\"]\n    HashFunc --&gt; Table2[\"Hash Table 2&lt;br/&gt;Bucket '011'\"]\n    HashFunc --&gt; Table3[\"Hash Table 3&lt;br/&gt;Bucket '101'\"]\n\n    Table1 --&gt; Candidates[Candidate Vectors Pool]\n    Table2 --&gt; Candidates\n    Table3 --&gt; Candidates\n\n    Candidates --&gt; ExactDist[\"Compute Exact Distance&lt;br/&gt;on small subset\"]\n    ExactDist --&gt; Results((Top-K Results))\n\n    style Candidates fill:#fff3e0,stroke:#f57c00\n    style Results fill:#e8f5e9,stroke:#4caf50</code></pre> C++ Implementation: Random Hyperplane LSH (click to expand) <pre><code>/**\n * Random Hyperplane LSH for cosine similarity.\n *\n * Each hash function: h(x) = sign(r \u00b7 x)\n * where r is a random Gaussian vector.\n *\n * Collision probability:\n *   Pr[h(x) = h(y)] = 1 - \u03b8(x,y) / \u03c0\n *\n * Parameters:\n *   dim         \u2014 dimensionality of input vectors\n *   num_tables  \u2014 number of hash tables L (more tables \u2192 higher recall)\n *   num_hashes  \u2014 hash bits per table k (more bits \u2192 higher precision)\n */\nclass RandomHyperplaneLSH {\npublic:\n  RandomHyperplaneLSH(size_t dim, size_t num_tables = 10, size_t num_hashes = 8)\n      : dim_(dim), num_tables_(num_tables), num_hashes_(num_hashes) {\n    std::mt19937 rng(42);\n    std::normal_distribution&lt;float&gt; normal(0.0f, 1.0f);\n\n    // Generate random hyperplanes for each table\n    hyperplanes_.resize(num_tables);\n    for (size_t t = 0; t &lt; num_tables; ++t) {\n      hyperplanes_[t].resize(num_hashes * dim);\n      for (auto &amp;val : hyperplanes_[t]) {\n        val = normal(rng);\n      }\n    }\n\n    tables_.resize(num_tables);\n  }\n\n  /**\n   * Build the index from a set of vectors.\n   */\n  void build(const std::vector&lt;std::vector&lt;float&gt;&gt; &amp;vectors) {\n    vectors_ = vectors;\n    for (auto &amp;table : tables_)\n      table.clear();\n\n    for (size_t i = 0; i &lt; vectors.size(); ++i) {\n      for (size_t t = 0; t &lt; num_tables_; ++t) {\n        auto sig = hash(vectors[i], t);\n        tables_[t][sig].push_back(i);\n      }\n    }\n  }\n\n  /**\n   * Query for k approximate nearest neighbors.\n   *\n   * 1. Hash query into each table\n   * 2. Collect all candidate IDs from matching buckets\n   * 3. Re-rank candidates by exact cosine similarity\n   */\n  std::vector&lt;size_t&gt; query(const std::vector&lt;float&gt; &amp;q, size_t k) const {\n    std::unordered_set&lt;size_t&gt; candidates;\n\n    for (size_t t = 0; t &lt; num_tables_; ++t) {\n      auto sig = hash(q, t);\n      auto it = tables_[t].find(sig);\n      if (it != tables_[t].end()) {\n        for (size_t idx : it-&gt;second) {\n          candidates.insert(idx);\n        }\n      }\n    }\n\n    // Re-rank by cosine similarity\n    std::vector&lt;std::pair&lt;float, size_t&gt;&gt; scored;\n    scored.reserve(candidates.size());\n    for (size_t idx : candidates) {\n      float sim = cosine_sim(q, vectors_[idx]);\n      scored.push_back({-sim, idx}); // negate for ascending sort\n    }\n    std::sort(scored.begin(), scored.end());\n\n    std::vector&lt;size_t&gt; result;\n    for (size_t i = 0; i &lt; std::min(k, scored.size()); ++i) {\n      result.push_back(scored[i].second);\n    }\n    return result;\n  }\n\n  size_t num_vectors() const { return vectors_.size(); }\n\nprivate:\n  HashSignature hash(const std::vector&lt;float&gt; &amp;vec, size_t table_idx) const {\n    HashSignature sig;\n    sig.bits.resize(num_hashes_);\n    for (size_t h = 0; h &lt; num_hashes_; ++h) {\n      float dot = 0.0f;\n      const float *plane = &amp;hyperplanes_[table_idx][h * dim_];\n      for (size_t d = 0; d &lt; dim_; ++d) {\n        dot += plane[d] * vec[d];\n      }\n      sig.bits[h] = (dot &gt; 0.0f) ? 1 : 0;\n    }\n    return sig;\n  }\n\n  static float cosine_sim(const std::vector&lt;float&gt; &amp;a,\n                          const std::vector&lt;float&gt; &amp;b) {\n    float dot = 0, na = 0, nb = 0;\n    for (size_t i = 0; i &lt; a.size(); ++i) {\n      dot += a[i] * b[i];\n      na += a[i] * a[i];\n      nb += b[i] * b[i];\n    }\n    float denom = std::sqrt(na) * std::sqrt(nb);\n    return (denom &gt; 1e-10f) ? dot / denom : 0.0f;\n  }\n\n  size_t dim_, num_tables_, num_hashes_;\n  std::vector&lt;std::vector&lt;float&gt;&gt; hyperplanes_; // [table][hash*dim + d]\n  std::vector&lt;\n      std::unordered_map&lt;HashSignature, std::vector&lt;size_t&gt;, HashSignatureHash&gt;&gt;\n      tables_;\n  std::vector&lt;std::vector&lt;float&gt;&gt; vectors_;\n};\n</code></pre>","tags":["foundations","algorithms","ann","hnsw","lsh"]},{"location":"part-1-foundations/ann-algorithms/#24-graph-based-methods","title":"2.4 Graph-Based Methods","text":"","tags":["foundations","algorithms","ann","hnsw","lsh"]},{"location":"part-1-foundations/ann-algorithms/#hierarchical-navigable-small-world-hnsw","title":"Hierarchical Navigable Small World (HNSW)","text":"<p>HNSW is currently the undisputed king of vector search. It powers almost every major production vector database today (Pinecone, Qdrant, Weaviate, Milvus).</p> <p>It is based on the idea of a \"Small World Network\" \u2014 much like the \"Six Degrees of Kevin Bacon\". You don't need to know everyone in the world; you just need to know a few distant hubs, and a few local neighbours, and you can navigate to anyone in a few hops.</p> <p>ELI5: Imagine navigating a highway system. To get from a small town in Texas to a small town in New York, you don't drive on local backroads the whole way. You: 1. Drive local roads to the nearest interstate highway on-ramp. 2. Hop on the massive, sparse interstate system spanning the country. 3. Exit near New York and take local dense streets to the exact address.</p> <p>HNSW builds exactly this: a multi-layered graph. The top layers are the \"interstate\", holding only a few sparse points that span vast distances. The bottom layer contains every single vector in dense \"local streets\". </p> <pre><code>flowchart TD\n    subgraph Layer2 [\"Layer 2 (The Highway - Super Sparse)\"]\n        direction LR\n        L2A((Node A)) &lt;--&gt; L2E((Node E))\n    end\n\n    subgraph Layer1 [\"Layer 1 (State Roads - Medium Density)\"]\n        direction LR\n        L1A((Node A)) &lt;--&gt; L1C((Node C))\n        L1C &lt;--&gt; L1E((Node E))\n    end\n\n    subgraph Layer0 [\"Layer 0 (Local Streets - Deeply Dense)\"]\n        direction LR\n        L0A((Node A)) &lt;--&gt; L0B((Node B))\n        L0B &lt;--&gt; L0C((Node C))\n        L0C &lt;--&gt; L0D((Node D))\n        L0D &lt;--&gt; L0E((Node E))\n        L0A &lt;--&gt; L0C\n    end\n\n    Layer2 -.-&gt; Layer1\n    Layer1 -.-&gt; Layer0\n\n    style Layer2 fill:#e3f2fd,stroke:#1e88e5\n    style Layer1 fill:#bbdefb,stroke:#1976d2\n    style Layer0 fill:#90caf9,stroke:#1565c0</code></pre>","tags":["foundations","algorithms","ann","hnsw","lsh"]},{"location":"part-1-foundations/ann-algorithms/#hnsw-algorithm-querying","title":"HNSW Algorithm: Querying","text":"<ol> <li>Start at a predefined entry point on the topmost layer.</li> <li>Look at the neighbours. Jump strictly to the neighbour that is mathematically closer to your query.</li> <li>Keep jumping until every neighbour is further away than the point you are currently standing on (a local minimum).</li> <li>Drop down to the next layer and repeat, using your current spot as the new starting point.</li> <li>Keep dropping until you hit Layer 0. The points you arrive at are your nearest neighbours.</li> </ol> Key Parameter Default Effect on Database <code>M</code> (Max connections) 16-64 Determines how many \"highways\" connect. Higher means much higher recall accuracy, but significantly more RAM usage. <code>ef_construction</code> 200 Search quality during graph building. Higher means a better quality graph, but takes vastly longer to import data. <code>ef_search</code> 50+ The width of the \"net\" cast during a user query. Higher means more accurate search results, but higher latency. C++ Implementation: HNSW Index (click to expand) <pre><code>/**\n * HNSW Index for approximate nearest neighbor search.\n *\n * Builds a multi-layer navigable small-world graph.\n * - Layer 0 is the densest (all nodes present)\n * - Higher layers are exponentially sparser\n * - Search descends from top layer greedily, then does\n *   beam search at layer 0.\n *\n * Template parameters are avoided for clarity; uses float vectors.\n *\n * Key parameters:\n *   M               \u2014 max edges per node per layer (default 16)\n *   M_max0          \u2014 max edges at layer 0 (default 2*M)\n *   ef_construction  \u2014 beam width during build\n *   ef_search        \u2014 beam width during query\n *   mL              \u2014 level generation factor = 1/ln(M)\n */\nclass HNSWIndex {\npublic:\n  struct SearchResult {\n    float distance;\n    size_t id;\n    bool operator&gt;(const SearchResult &amp;o) const {\n      return distance &gt; o.distance;\n    }\n    bool operator&lt;(const SearchResult &amp;o) const {\n      return distance &lt; o.distance;\n    }\n  };\n\n  HNSWIndex(size_t dim, size_t M = 16, size_t ef_construction = 200,\n            size_t ef_search = 50)\n      : dim_(dim), M_(M), M_max0_(2 * M), ef_construction_(ef_construction),\n        ef_search_(ef_search), mL_(1.0 / std::log(static_cast&lt;double&gt;(M))),\n        entry_point_(NONE), max_layer_(0), rng_(42), uniform_(0.0, 1.0) {}\n\n  /**\n   * Insert a single vector into the index.\n   *\n   * Algorithm (simplified):\n   * 1. Draw random level l ~ Geometric(mL)\n   * 2. From entry point, greedily descend to layer l+1\n   * 3. At each layer [l..0], beam-search for ef_construction\n   *    neighbors and add bidirectional edges\n   */\n  size_t insert(const std::vector&lt;float&gt; &amp;vec) {\n    size_t id = vectors_.size();\n    vectors_.push_back(vec);\n\n    int level = random_level();\n\n    // Grow graph layers if needed\n    while (static_cast&lt;int&gt;(graph_.size()) &lt;= level) {\n      graph_.emplace_back();\n    }\n\n    // First element\n    if (entry_point_ == NONE) {\n      entry_point_ = id;\n      max_layer_ = level;\n      for (int l = 0; l &lt;= level; ++l) {\n        if (graph_[l].size() &lt;= id)\n          graph_[l].resize(id + 1);\n      }\n      return id;\n    }\n\n    // Ensure node has adjacency lists at all its layers\n    for (int l = 0; l &lt;= level; ++l) {\n      if (graph_[l].size() &lt;= id)\n        graph_[l].resize(id + 1);\n    }\n\n    size_t current = entry_point_;\n\n    // Phase 1: Greedy descent from max_layer to level+1\n    for (int l = max_layer_; l &gt; level; --l) {\n      auto nearest = search_layer(vec, current, 1, l);\n      if (!nearest.empty())\n        current = nearest[0].id;\n    }\n\n    // Phase 2: Insert at layers [min(level, max_layer)..0]\n    for (int l = std::min(level, max_layer_); l &gt;= 0; --l) {\n      auto candidates = search_layer(vec, current, ef_construction_, l);\n      size_t M_max = (l == 0) ? M_max0_ : M_;\n      auto neighbors = select_neighbors(candidates, M_max);\n\n      // Add bidirectional edges\n      for (auto &amp;nb : neighbors) {\n        graph_[l][id].push_back(nb.id);\n        graph_[l][nb.id].push_back(id);\n\n        // Prune neighbor if over capacity\n        if (graph_[l][nb.id].size() &gt; M_max) {\n          prune(nb.id, l, M_max);\n        }\n      }\n\n      if (!candidates.empty())\n        current = candidates[0].id;\n    }\n\n    if (level &gt; max_layer_) {\n      entry_point_ = id;\n      max_layer_ = level;\n    }\n\n    return id;\n  }\n\n  /**\n   * Search for k approximate nearest neighbors.\n   *\n   * 1. Greedy descent from top layer to layer 1\n   * 2. Beam search at layer 0 with ef = max(ef_search, k)\n   * 3. Return top-k results sorted by distance\n   */\n  std::vector&lt;SearchResult&gt; search(const std::vector&lt;float&gt; &amp;query,\n                                   size_t k) const {\n    if (entry_point_ == NONE)\n      return {};\n\n    size_t current = entry_point_;\n\n    // Descend from top\n    for (int l = max_layer_; l &gt; 0; --l) {\n      auto nearest = search_layer(query, current, 1, l);\n      if (!nearest.empty())\n        current = nearest[0].id;\n    }\n\n    size_t ef = std::max(ef_search_, k);\n    auto results = search_layer(query, current, ef, 0);\n\n    // Take sqrt for actual Euclidean distances\n    if (results.size() &gt; k)\n      results.resize(k);\n    for (auto &amp;r : results) {\n      r.distance = std::sqrt(r.distance);\n    }\n    return results;\n  }\n\n  /**\n   * Bulk insert all vectors.\n   */\n  void build(const std::vector&lt;std::vector&lt;float&gt;&gt; &amp;vectors) {\n    for (const auto &amp;v : vectors)\n      insert(v);\n  }\n\n  size_t size() const { return vectors_.size(); }\n  size_t num_layers() const { return graph_.size(); }\n\n  void set_ef_search(size_t ef) { ef_search_ = ef; }\n\nprivate:\n  static constexpr size_t NONE = std::numeric_limits&lt;size_t&gt;::max();\n\n  float distance_sq(const std::vector&lt;float&gt; &amp;a,\n                    const std::vector&lt;float&gt; &amp;b) const {\n    float sum = 0.0f;\n    for (size_t i = 0; i &lt; dim_; ++i) {\n      float d = a[i] - b[i];\n      sum += d * d;\n    }\n    return sum;\n  }\n\n  int random_level() {\n    return static_cast&lt;int&gt;(-std::log(uniform_(rng_)) * mL_);\n  }\n\n  /**\n   * Beam search in a single layer.\n   * Returns up to ef nearest elements, sorted by distance (ascending).\n   */\n  std::vector&lt;SearchResult&gt; search_layer(const std::vector&lt;float&gt; &amp;query,\n                                         size_t entry, size_t ef,\n                                         int layer) const {\n    if (layer &gt;= static_cast&lt;int&gt;(graph_.size()))\n      return {};\n    if (entry &gt;= graph_[layer].size())\n      return {};\n\n    std::unordered_set&lt;size_t&gt; visited;\n    visited.insert(entry);\n\n    float d = distance_sq(query, vectors_[entry]);\n\n    // candidates: min-heap (closest first)\n    std::priority_queue&lt;SearchResult, std::vector&lt;SearchResult&gt;,\n                        std::greater&lt;SearchResult&gt;&gt;\n        candidates;\n    // results: max-heap (farthest first, for bounding)\n    std::priority_queue&lt;SearchResult&gt; results;\n\n    candidates.push({d, entry});\n    results.push({d, entry});\n\n    while (!candidates.empty()) {\n      auto [c_dist, c_id] = candidates.top();\n      candidates.pop();\n\n      float farthest = results.top().distance;\n      if (c_dist &gt; farthest)\n        break;\n\n      // Expand neighbors\n      if (c_id &lt; graph_[layer].size()) {\n        for (size_t nb : graph_[layer][c_id]) {\n          if (visited.count(nb))\n            continue;\n          visited.insert(nb);\n\n          float nb_dist = distance_sq(query, vectors_[nb]);\n          farthest = results.top().distance;\n\n          if (nb_dist &lt; farthest || results.size() &lt; ef) {\n            candidates.push({nb_dist, nb});\n            results.push({nb_dist, nb});\n            if (results.size() &gt; ef)\n              results.pop();\n          }\n        }\n      }\n    }\n\n    // Extract sorted results\n    std::vector&lt;SearchResult&gt; out;\n    out.reserve(results.size());\n    while (!results.empty()) {\n      out.push_back(results.top());\n      results.pop();\n    }\n    std::sort(out.begin(), out.end());\n    return out;\n  }\n\n  std::vector&lt;SearchResult&gt;\n  select_neighbors(const std::vector&lt;SearchResult&gt; &amp;candidates,\n                   size_t M) const {\n    auto sorted = candidates;\n    std::sort(sorted.begin(), sorted.end());\n    if (sorted.size() &gt; M)\n      sorted.resize(M);\n    return sorted;\n  }\n\n  void prune(size_t node, int layer, size_t M_max) {\n    auto &amp;adj = graph_[layer][node];\n    std::vector&lt;SearchResult&gt; scored;\n    for (size_t nb : adj) {\n      scored.push_back({distance_sq(vectors_[node], vectors_[nb]), nb});\n    }\n    std::sort(scored.begin(), scored.end());\n    adj.clear();\n    for (size_t i = 0; i &lt; std::min(M_max, scored.size()); ++i) {\n      adj.push_back(scored[i].id);\n    }\n  }\n\n  size_t dim_;\n  size_t M_, M_max0_;\n  size_t ef_construction_, ef_search_;\n  double mL_;\n  size_t entry_point_;\n  int max_layer_;\n\n  std::mt19937 rng_;\n  std::uniform_real_distribution&lt;double&gt; uniform_;\n\n  std::vector&lt;std::vector&lt;float&gt;&gt; vectors_;\n  // graph_[layer][node_id] = list of neighbor IDs\n  std::vector&lt;std::vector&lt;std::vector&lt;size_t&gt;&gt;&gt; graph_;\n};\n</code></pre>","tags":["foundations","algorithms","ann","hnsw","lsh"]},{"location":"part-1-foundations/ann-algorithms/#vamana-diskann","title":"Vamana / DiskANN","text":"<p>HNSW relies heavily on storing the entire graph structure in RAM to execute those quick multi-layer hops, which becomes prohibitively expensive at billion-scale datasets. DiskANN/Vamana is an algorithm designed by Microsoft specifically to store the graph mostly on NVMe SSD drives. It utilizes asynchronous I/O batch reads to fetch neighborhoods from disk, pulling latencies down to &lt;5ms despite operating on cheap storage.</p>","tags":["foundations","algorithms","ann","hnsw","lsh"]},{"location":"part-1-foundations/ann-algorithms/#25-quantization-based-methods","title":"2.5 Quantization-Based Methods","text":"<p>High-dimensional data eats massive amounts of RAM. Quantization is the mathematical technique of brutally compressing vectors while trying to retain their semantic shape.</p>","tags":["foundations","algorithms","ann","hnsw","lsh"]},{"location":"part-1-foundations/ann-algorithms/#product-quantization-pq","title":"Product Quantization (PQ)","text":"<p>Product Quantization breaks massive vectors up into tiny sub-chunks, and replaces the massive arrays of random floats with tiny 8-bit integers.</p> <p>ELI5: Imagine trying to store highly detailed RGB color codes for a photograph (e.g. <code>[251.3, 12.1, 88.9]</code>). Instead of storing those exact floats, you look at an 8-color crayon box. You decide that pixel looks closest to \"red\". So instead of storing 3 floats, you just store the ID number <code>2</code> (the red crayon). You've lost some fine detail, but you compressed the pixel massively. </p> <p>PQ does this, but for 768-dimensional language vectors. It chops a 768-dim vector into 32 sub-chunks, finds the \"closest crayon colour\" for each chunk, and stores 32 bytes instead of 3072 bytes (a massive 96x compression).</p>","tags":["foundations","algorithms","ann","hnsw","lsh"]},{"location":"part-1-foundations/ann-algorithms/#asymmetric-distance-computation-adc","title":"Asymmetric Distance Computation (ADC)","text":"<p>When the query comes in, it is not quantized. We compute the exact distance between the pure uncompressed query vector, and the tiny compressed memory codes. </p> Step Complexity Look up pre-calculated table $O(M \\cdot K \\cdot d_s)$ \u2014 once per query Scan $n$ codes in DB $O(n \\cdot M)$ \u2014 just fast integer lookups, no math C++ Implementation: Product Quantizer (click to expand) <pre><code>/**\n * Product Quantizer.\n *\n * Compresses d-dimensional float vectors into M bytes (one code per subspace).\n *\n * Compression ratio: d \u00d7 4 bytes \u2192 M bytes (e.g. 128-dim \u00d7 4B = 512B \u2192 8B).\n *\n * Workflow:\n *   1. train()  \u2014 learn M codebooks of K=256 centroids each via k-means\n *   2. encode() \u2014 compress vectors to PQ codes (M uint8 per vector)\n *   3. search() \u2014 approximate distance using ADC lookup tables\n *\n * Asymmetric Distance Computation (ADC):\n *   dist(q, x\u0303)\u00b2 \u2248 \u03a3_m || q^(m) - c_{code_m}^(m) ||\u00b2\n *   Precompute a (M \u00d7 K) distance table, then M lookups per candidate.\n */\nclass ProductQuantizer {\npublic:\n  ProductQuantizer(size_t dim, size_t M = 8, size_t K = 256)\n      : dim_(dim), M_(M), K_(K), ds_(dim / M) {\n    assert(dim % M == 0 &amp;&amp; \"dim must be divisible by M\");\n    codebooks_.resize(\n        M, std::vector&lt;std::vector&lt;float&gt;&gt;(K, std::vector&lt;float&gt;(ds_)));\n  }\n\n  /**\n   * Train codebooks with k-means on each subspace.\n   */\n  void train(const std::vector&lt;std::vector&lt;float&gt;&gt; &amp;data, size_t n_iter = 25) {\n    std::mt19937 rng(42);\n    size_t n = data.size();\n\n    for (size_t m = 0; m &lt; M_; ++m) {\n      // Extract sub-vectors for subspace m\n      std::vector&lt;std::vector&lt;float&gt;&gt; sub(n, std::vector&lt;float&gt;(ds_));\n      for (size_t i = 0; i &lt; n; ++i) {\n        for (size_t d = 0; d &lt; ds_; ++d) {\n          sub[i][d] = data[i][m * ds_ + d];\n        }\n      }\n\n      // Initialize centroids randomly\n      std::vector&lt;size_t&gt; indices(n);\n      std::iota(indices.begin(), indices.end(), 0);\n      std::shuffle(indices.begin(), indices.end(), rng);\n      for (size_t k = 0; k &lt; K_; ++k) {\n        codebooks_[m][k] = sub[indices[k % n]];\n      }\n\n      // k-means iterations\n      std::vector&lt;size_t&gt; assignments(n);\n      for (size_t iter = 0; iter &lt; n_iter; ++iter) {\n        // Assign\n        for (size_t i = 0; i &lt; n; ++i) {\n          float best_dist = std::numeric_limits&lt;float&gt;::max();\n          for (size_t k = 0; k &lt; K_; ++k) {\n            float d = l2_sq(sub[i], codebooks_[m][k]);\n            if (d &lt; best_dist) {\n              best_dist = d;\n              assignments[i] = k;\n            }\n          }\n        }\n\n        // Update centroids\n        std::vector&lt;std::vector&lt;float&gt;&gt; sums(K_, std::vector&lt;float&gt;(ds_, 0));\n        std::vector&lt;size_t&gt; counts(K_, 0);\n        for (size_t i = 0; i &lt; n; ++i) {\n          size_t k = assignments[i];\n          counts[k]++;\n          for (size_t d = 0; d &lt; ds_; ++d) {\n            sums[k][d] += sub[i][d];\n          }\n        }\n        for (size_t k = 0; k &lt; K_; ++k) {\n          if (counts[k] &gt; 0) {\n            for (size_t d = 0; d &lt; ds_; ++d) {\n              codebooks_[m][k][d] = sums[k][d] / counts[k];\n            }\n          }\n        }\n      }\n    }\n    trained_ = true;\n  }\n\n  /**\n   * Encode vectors to PQ codes (M uint8 per vector).\n   */\n  std::vector&lt;std::vector&lt;uint8_t&gt;&gt;\n  encode(const std::vector&lt;std::vector&lt;float&gt;&gt; &amp;data) const {\n    assert(trained_);\n    size_t n = data.size();\n    std::vector&lt;std::vector&lt;uint8_t&gt;&gt; codes(n, std::vector&lt;uint8_t&gt;(M_));\n\n    for (size_t i = 0; i &lt; n; ++i) {\n      for (size_t m = 0; m &lt; M_; ++m) {\n        float best_dist = std::numeric_limits&lt;float&gt;::max();\n        uint8_t best_k = 0;\n        for (size_t k = 0; k &lt; K_; ++k) {\n          float d = 0;\n          for (size_t dd = 0; dd &lt; ds_; ++dd) {\n            float diff = data[i][m * ds_ + dd] - codebooks_[m][k][dd];\n            d += diff * diff;\n          }\n          if (d &lt; best_dist) {\n            best_dist = d;\n            best_k = static_cast&lt;uint8_t&gt;(k);\n          }\n        }\n        codes[i][m] = best_k;\n      }\n    }\n    return codes;\n  }\n\n  /**\n   * Decode PQ codes back to approximate vectors.\n   */\n  std::vector&lt;float&gt; decode(const std::vector&lt;uint8_t&gt; &amp;code) const {\n    assert(trained_);\n    std::vector&lt;float&gt; vec(dim_);\n    for (size_t m = 0; m &lt; M_; ++m) {\n      for (size_t d = 0; d &lt; ds_; ++d) {\n        vec[m * ds_ + d] = codebooks_[m][code[m]][d];\n      }\n    }\n    return vec;\n  }\n</code></pre>","tags":["foundations","algorithms","ann","hnsw","lsh"]},{"location":"part-1-foundations/ann-algorithms/#26-hybrid-and-composite-indexes","title":"2.6 Hybrid and Composite Indexes","text":"<p>Production systems mix and match these theories for maximum power. The most common combination historically used in libraries like Meta's FAISS is IVF-PQ (Inverted File Index with Product Quantization).</p> <ol> <li>IVF: Group the entire space into distinct clusters (voronoi cells).</li> <li>PQ: Compress all vectors inside those clusters aggressively.</li> <li>Query: Find the closest 12 clusters to the query, jump into them, and scan the heavily compressed PQ codes inside.</li> </ol> C++ Implementation: IVF Index (click to expand) <pre><code>/**\n * Inverted File Index.\n *\n * Search complexity: O(nprobe \u00d7 n/nlist \u00d7 d) vs O(n \u00d7 d) brute-force.\n *\n * Parameters:\n *   nlist  \u2014 number of Voronoi cells (centroids)\n *   nprobe \u2014 number of cells to search (trade-off: recall vs speed)\n */\nclass IVFIndex {\npublic:\n  struct SearchResult {\n    float distance;\n    size_t id;\n    bool operator&lt;(const SearchResult &amp;o) const {\n      return distance &lt; o.distance;\n    }\n  };\n\n  IVFIndex(size_t dim, size_t nlist = 100, size_t nprobe = 10)\n      : dim_(dim), nlist_(nlist), nprobe_(nprobe) {\n    inverted_lists_.resize(nlist);\n  }\n\n  /**\n   * Train centroids using k-means.\n   */\n  void train(const std::vector&lt;std::vector&lt;float&gt;&gt; &amp;data, size_t n_iter = 20) {\n    size_t n = data.size();\n    centroids_.resize(nlist_, std::vector&lt;float&gt;(dim_));\n\n    std::mt19937 rng(42);\n    std::vector&lt;size_t&gt; indices(n);\n    std::iota(indices.begin(), indices.end(), 0);\n    std::shuffle(indices.begin(), indices.end(), rng);\n\n    for (size_t c = 0; c &lt; nlist_; ++c) {\n      centroids_[c] = data[indices[c % n]];\n    }\n\n    std::vector&lt;size_t&gt; assignments(n);\n    for (size_t iter = 0; iter &lt; n_iter; ++iter) {\n      // Assign to nearest centroid\n      for (size_t i = 0; i &lt; n; ++i) {\n        float best = std::numeric_limits&lt;float&gt;::max();\n        for (size_t c = 0; c &lt; nlist_; ++c) {\n          float d = l2_sq(data[i], centroids_[c]);\n          if (d &lt; best) {\n            best = d;\n            assignments[i] = c;\n          }\n        }\n      }\n      // Update centroids\n      std::vector&lt;std::vector&lt;float&gt;&gt; sums(nlist_, std::vector&lt;float&gt;(dim_, 0));\n      std::vector&lt;size_t&gt; counts(nlist_, 0);\n      for (size_t i = 0; i &lt; n; ++i) {\n        counts[assignments[i]]++;\n        for (size_t d = 0; d &lt; dim_; ++d)\n          sums[assignments[i]][d] += data[i][d];\n      }\n      for (size_t c = 0; c &lt; nlist_; ++c) {\n        if (counts[c] &gt; 0) {\n          for (size_t d = 0; d &lt; dim_; ++d)\n            centroids_[c][d] = sums[c][d] / counts[c];\n        }\n      }\n    }\n    trained_ = true;\n  }\n\n  /**\n   * Add vectors to the inverted lists.\n   */\n  void add(const std::vector&lt;std::vector&lt;float&gt;&gt; &amp;data) {\n    assert(trained_);\n    vectors_ = data;\n    for (auto &amp;list : inverted_lists_)\n      list.clear();\n\n    for (size_t i = 0; i &lt; data.size(); ++i) {\n      float best = std::numeric_limits&lt;float&gt;::max();\n      size_t best_c = 0;\n      for (size_t c = 0; c &lt; nlist_; ++c) {\n        float d = l2_sq(data[i], centroids_[c]);\n        if (d &lt; best) {\n          best = d;\n          best_c = c;\n        }\n      }\n      inverted_lists_[best_c].push_back(i);\n    }\n  }\n\n  /**\n   * Search for k approximate nearest neighbors.\n   *\n   * 1. Find nprobe nearest centroids\n   * 2. Scan vectors in those cells\n   * 3. Return top-k\n   */\n  std::vector&lt;SearchResult&gt; search(const std::vector&lt;float&gt; &amp;query,\n                                   size_t k) const {\n    assert(trained_);\n\n    // Find nearest centroids\n    std::vector&lt;std::pair&lt;float, size_t&gt;&gt; centroid_dists(nlist_);\n    for (size_t c = 0; c &lt; nlist_; ++c) {\n      centroid_dists[c] = {l2_sq(query, centroids_[c]), c};\n    }\n    std::partial_sort(centroid_dists.begin(),\n                      centroid_dists.begin() + std::min(nprobe_, nlist_),\n                      centroid_dists.end());\n\n    // Collect and score candidates\n    std::vector&lt;SearchResult&gt; candidates;\n    for (size_t p = 0; p &lt; std::min(nprobe_, nlist_); ++p) {\n      size_t cell = centroid_dists[p].second;\n      for (size_t idx : inverted_lists_[cell]) {\n        float d = std::sqrt(l2_sq(query, vectors_[idx]));\n        candidates.push_back({d, idx});\n      }\n    }\n\n    k = std::min(k, candidates.size());\n    if (k &gt; 0) {\n      std::partial_sort(candidates.begin(), candidates.begin() + k,\n                        candidates.end());\n      candidates.resize(k);\n    }\n    return candidates;\n  }\n\n  void set_nprobe(size_t nprobe) { nprobe_ = nprobe; }\n  size_t size() const { return vectors_.size(); }\n\nprivate:\n  static float l2_sq(const std::vector&lt;float&gt; &amp;a, const std::vector&lt;float&gt; &amp;b) {\n    float s = 0;\n    for (size_t i = 0; i &lt; a.size(); ++i) {\n      float d = a[i] - b[i];\n      s += d * d;\n    }\n    return s;\n  }\n\n  size_t dim_, nlist_, nprobe_;\n  bool trained_ = false;\n  std::vector&lt;std::vector&lt;float&gt;&gt; centroids_;\n  std::vector&lt;std::vector&lt;size_t&gt;&gt; inverted_lists_;\n  std::vector&lt;std::vector&lt;float&gt;&gt; vectors_;\n};\n</code></pre>","tags":["foundations","algorithms","ann","hnsw","lsh"]},{"location":"part-1-foundations/ann-algorithms/#27-algorithm-selection-guide","title":"2.7 Algorithm Selection Guide","text":"<pre><code>flowchart TD\n    A[How many vectors?] --&gt;|\"Under 100K\"| B[Brute-Force Flat Search]\n    A --&gt;|\"100K to 10M\"| C[HNSW in RAM]\n    A --&gt;|\"Over 10M\"| D{Infrastructure Budget?}\n\n    D --&gt;|High Budget| E[HNSW + 8-bit Quantized RAM]\n    D --&gt;|Tight Budget| F[DiskANN SSD or IVF-PQ]\n\n    style B fill:#fff9c4,stroke:#fbc02d\n    style C fill:#c8e6c9,stroke:#388e3c\n    style E fill:#c8e6c9,stroke:#388e3c\n    style F fill:#bbdefb,stroke:#1976d2</code></pre>","tags":["foundations","algorithms","ann","hnsw","lsh"]},{"location":"part-1-foundations/ann-algorithms/#assignment-implement-a-k-means-ivf-index","title":"Assignment: Implement a K-Means IVF Index","text":"<p>In Chapter 0, you built a naive \"Index\" that hardcoded two buckets based on whether the first dimension was positive or negative. In this assignment, you will upgrade your <code>FastMiniVectorDB</code> to use a true Inverted File Index (IVF) based on K-Means centroids.</p>","tags":["foundations","algorithms","ann","hnsw","lsh"]},{"location":"part-1-foundations/ann-algorithms/#goal","title":"Goal","text":"<p>Define $K$ centroids (for example, $K=4$). Write an ingestion pipeline that calculates the distance between a new vector and all 4 centroids, and pushes the vector ID into the bucket (inverted list) of the closest centroid. During search, implement the <code>nprobe</code> parameter to only scan the 2 closest buckets.</p> Exercise: Implement IVF<pre><code>#include &lt;vector&gt;\n#include &lt;iostream&gt;\n#include &lt;limits&gt;\n\nclass IVFVectorDB {\nprivate:\n    std::unordered_map&lt;size_t, Record&gt; storage;\n    size_t next_id = 1;\n\n    // The K Centroids (e.g., K = 4)\n    std::vector&lt;std::vector&lt;float&gt;&gt; centroids;\n\n    // The Inverted Lists (Buckets). Maps a centroid index (0 to K-1) \n    // to a list of Vector IDs.\n    std::vector&lt;std::vector&lt;size_t&gt;&gt; inverted_lists;\n\npublic:\n    IVFVectorDB(const std::vector&lt;std::vector&lt;float&gt;&gt;&amp; initial_centroids) {\n        centroids = initial_centroids;\n        inverted_lists.resize(centroids.size());\n    }\n\n    size_t insert(const std::vector&lt;float&gt;&amp; vec) {\n        size_t id = next_id++;\n        storage[id] = {id, vec, \"\"};\n\n        // EXERCISE 1: Find the nearest centroid\n        int best_centroid_idx = -1;\n        float min_dist = std::numeric_limits&lt;float&gt;::max();\n\n        /* Write your loop here: compare `vec` to all `centroids` */\n\n        // Push to the correct bucket\n        if (best_centroid_idx != -1) {\n            inverted_lists[best_centroid_idx].push_back(id);\n        }\n        return id;\n    }\n\n    std::vector&lt;SearchResult&gt; search(const std::vector&lt;float&gt;&amp; query, int k, int nprobe) {\n        // EXERCISE 2: Implement nprobe routing\n        // 1. Find the distance from `query` to all `centroids`.\n        // 2. Sort the centroids by distance.\n        // 3. Take the top `nprobe` closest centroids.\n        // 4. Iterate *only* over the `inverted_lists` belonging to those specific centroids.\n        // 5. Calculate exact distances and return the top-K.\n\n        std::vector&lt;SearchResult&gt; results;\n\n        /* Write your routing and scanning logic here */\n\n        return results;\n    }\n};\n</code></pre>","tags":["foundations","algorithms","ann","hnsw","lsh"]},{"location":"part-1-foundations/ann-algorithms/#references","title":"References","text":"<ol> <li>Malkov, Y. A., &amp; Yashunin, D. A. (2020). Efficient and Robust Approximate Nearest Neighbor Search Using HNSW Graphs. IEEE TPAMI.</li> <li>Jegou, H., Douze, M., &amp; Schmid, C. (2011). Product Quantization for Nearest Neighbor Search. IEEE TPAMI.</li> <li>Subramanya, S. J., et al. (2019). DiskANN: Fast Accurate Billion-point Nearest Neighbor Search on a Single Node. NeurIPS.</li> <li>Indyk, P., &amp; Motwani, R. (1998). Approximate Nearest Neighbors: Towards Removing the Curse of Dimensionality. STOC.</li> </ol>","tags":["foundations","algorithms","ann","hnsw","lsh"]},{"location":"part-1-foundations/data-ingestion/","title":"Chapter 5 \u2014 Data Ingestion & Vectorization Pipelines","text":"","tags":["foundations","ingestion","embeddings","chunking"]},{"location":"part-1-foundations/data-ingestion/#5-data-ingestion-vectorization-pipelines","title":"5. Data Ingestion &amp; Vectorization Pipelines","text":"<p>Vector databases are entirely \"dumb\" to human language. If you send the string <code>\"Hello World\"</code> to Milvus, it will throw an error. A vector database is strictly a math engine\u2014it stores coordinates and calculates distances between them. </p> <p>The most critical factor in the success of an AI application is not the database you choose, but the Data Ingestion Pipeline that sits in front of the database. This pipeline translates messy human realities (PDFs, customer support transcripts, images) into highly structured math (dense embeddings).</p> <p>This chapter breaks down the theory and practice of ingestion pipelines.</p>","tags":["foundations","ingestion","embeddings","chunking"]},{"location":"part-1-foundations/data-ingestion/#51-the-journey-from-document-to-vector","title":"5.1 The Journey from Document to Vector","text":"<p>The ingestion pipeline generally follows a strict sequence of operations:</p> <pre><code>flowchart LR\n    Source[(\"Raw Documents&lt;br/&gt;S3 / Postgres / Notion\")] --&gt; Extract[\"Text Extraction&lt;br/&gt;OCR / PyPDF\"]\n    Extract --&gt; Chunk[\"Chunking&lt;br/&gt;Split into paragraphs\"]\n    Chunk --&gt; Embed[\"Embedding Model&lt;br/&gt;e.g. text-embedding-ada-002\"]\n    Embed --&gt; DB[(\"Vector DB&lt;br/&gt;Insert Vectors + Metadata\")]\n\n    style Source fill:#eceff1,stroke:#607d8b\n    style DB fill:#e3f2fd,stroke:#1e88e5</code></pre> <p>If any step in this sequence is configured poorly, the search accuracy of your entire system will crash, regardless of how perfectly you tuned your HNSW graph parameters in the database.</p>","tags":["foundations","ingestion","embeddings","chunking"]},{"location":"part-1-foundations/data-ingestion/#52-the-science-of-chunking","title":"5.2 The Science of Chunking","text":"<p>You cannot feed an entire 500-page book into an embedding model and get a single 768-dimensional vector back. Neural network embedding models have strict context windows (usually between 512 and 8,000 tokens). Furthermore, even if a model could process 500 pages, a single vector cannot mathematically represent 500 pages of distinct ideas simultaneously (this phenomenon is called \"semantic collapse\").</p> <p>To solve this, we parse huge documents into tiny, distinct Chunks. </p>","tags":["foundations","ingestion","embeddings","chunking"]},{"location":"part-1-foundations/data-ingestion/#chunking-strategies","title":"Chunking Strategies","text":"<p>There is no \"perfect\" chunking size; it entirely depends on the nature of the questions your users will ask.</p> Strategy How it works When to use it Fixed-Size (Token) Chunking Strictly split text every 300 tokens, regardless of grammar. Fast baseline. But it often cuts sentences perfectly in half, destroying the semantic meaning. Sentence-Window Chunking Split strictly by periods (<code>.</code>). Create chunks that are \"Sentence X, plus 2 sentences before and after\". High precision for factual QA systems. Preserves local context perfectly. Recursive Character Chunking Tries to split by double-newline <code>\\n\\n</code> (paragraphs). If a paragraph is too long, it falls back to single newlines, then spaces. The most common industry default (LangChain's default). Respects author's structural intent. Semantic Chunking Calculates real-time cosine distance between continuous sentences. If two sentences are mathematically far apart, it assumes a topic shift occurred and splits the chunk there. Cutting-edge. Produces highly cohesive chunks, but is incredibly slow / expensive to compute during ingestion. <p>The Golden Rule of Chunk Overlap: When using size-based chunking, you must always enable an \"overlap\" (e.g., chunks of 300 tokens, with 50 tokens of overlap). Otherwise, a crucial fact might be split perfectly down the middle between Chunk A and Chunk B, causing neither chunk to contain sufficient context to match a user's prompt.</p>","tags":["foundations","ingestion","embeddings","chunking"]},{"location":"part-1-foundations/data-ingestion/#53-embedding-models-explained","title":"5.3 Embedding Models Explained","text":"<p>An embedding model is a supervised deep learning model (typically an Encoder-only Transformer like BERT) trained via Contrastive Learning.</p> <p>In contrastive learning, the model is shown three things: an \"Anchor\" sentence (e.g. \"What is a cat?\"), a \"Positive\" sentence (e.g. \"Felines are mammals\"), and a \"Negative\" sentence (e.g. \"Cars have 4 wheels\"). The neural network adjusts its internal weights to pull the Anchor and Positive closer together in 768-dimensional space, and push the Anchor and Negative further apart.</p> <p>After seeing billions of these triplets, the model learns the geometric layout of human language semantics.</p>","tags":["foundations","ingestion","embeddings","chunking"]},{"location":"part-1-foundations/data-ingestion/#families-of-embedding-models","title":"Families of Embedding Models","text":"<ol> <li>Symmetric (Semantic Similarity): Best for matching user queries against other user queries (e.g., deduplicating a support forum). Both inputs are the same size and tone. (e.g., <code>all-MiniLM-L6-v2</code>).</li> <li>Asymmetric (QA / Retrieval): Best for standard Retrieval Augmented Generation (RAG). The user query is short (\"How do I reset my password?\"), but the target document is long (a huge IT manual). The model is specifically trained to map short questions to long answers.</li> <li>Multi-Modal (CLIP): The model is trained on both text and images simultaneously. The sentence \"A golden retriever playing\" produces the exact same vector as a JPEG photograph of a golden retriever playing.</li> </ol>","tags":["foundations","ingestion","embeddings","chunking"]},{"location":"part-1-foundations/data-ingestion/#benchmarking-models-mteb","title":"Benchmarking Models (MTEB)","text":"<p>Because building new embedding models is a highly competitive space between companies like OpenAI, Cohere, BGE, and Nomic, the industry relies on the MTEB (Massive Text Embedding Benchmark). </p> <p>MTEB tests an embedding model against 100+ different tasks (classification, clustering, retrieval) across 100+ languages to provide an aggregate score. Before starting a project, engineers check the HuggingFace MTEB Leaderboard to select the current State of the Art model that fits their latency budget.</p>","tags":["foundations","ingestion","embeddings","chunking"]},{"location":"part-1-foundations/data-ingestion/#54-metadata-extraction-decoration","title":"5.4 Metadata Extraction &amp; Decoration","text":"<p>A raw chunk of text is not enough. To power Hybrid Search (Chapter 10) and enable the vector database to restrict searches, the ingestion pipeline must extract scalar data.</p> <p>If a chunk is a paragraph from an SEC 10-K filing, the pipeline should extract: * <code>ticker</code>: \"AAPL\" * <code>year</code>: 2024 * <code>section</code>: \"Risk Factors\"</p> <p>During ingestion, the pipeline stitches the 768-D float array generated by the embedding model together with this JSON metadata dictionary, creating the final Payload that is transmitted to the Vector Database API (described in Chapter 6).</p>","tags":["foundations","ingestion","embeddings","chunking"]},{"location":"part-1-foundations/data-ingestion/#references","title":"References","text":"<ol> <li>Reimers, N., &amp; Gurevych, I. (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. EMNLP.</li> <li>Muennighoff, N., et al. (2023). MTEB: Massive Text Embedding Benchmark. EACL.</li> <li>LangChain Documentation: Text Splitters.</li> </ol>","tags":["foundations","ingestion","embeddings","chunking"]},{"location":"part-1-foundations/high-dimensional-geometry/","title":"Chapter 1 \u2014 High-Dimensional Geometry Refresher","text":"","tags":["foundations","geometry","dimensionality"]},{"location":"part-1-foundations/high-dimensional-geometry/#1-high-dimensional-geometry-refresher","title":"1. High-Dimensional Geometry Refresher","text":"<p>Vector databases operate in high-dimensional spaces \u2014 typically ranging from 64 to 4,096 dimensions depending on the neural network generating the embeddings. For many developers, 3D space is intuitive, but visualising 1000-dimensional space breaks our standard mental models. </p> <p>This chapter builds geometric intuition for these high-dimensional spaces. We'll introduce the distance metrics that underpin similarity search, and explain a phenomenon called the \"Curse of Dimensionality\" which forces us to rethink how search algorithms work.</p>","tags":["foundations","geometry","dimensionality"]},{"location":"part-1-foundations/high-dimensional-geometry/#11-vector-spaces-and-representations","title":"1.1 Vector Spaces and Representations","text":"<p>At its simplest, a vector $\\mathbf{x} \\in \\mathbb{R}^d$ is just an ordered list of $d$ numbers. In the context of vector databases, these lists of numbers represent complex concepts like words, images, or entire documents.</p> <p>There are two main types of vectors you will encounter:</p> <ul> <li>Dense embeddings: These are fixed-length lists of floating-point numbers produced by deep learning models (e.g., 768-dim from BERT, or 1536-dim from OpenAI's <code>text-embedding-3-small</code> model). Most of the values are non-zero.</li> <li>Sparse vectors: These are extremely high-dimensional lists (often &gt;100,000 dimensions) where almost all the values are exactly zero. Examples include TF-IDF or BM25 term weights, where each dimension represents a specific word in an entire language vocabulary.</li> </ul> <p>ELI5: Why dense embeddings dominate</p> <p>Imagine you are matching the sentence \"The king ruled the country\" with \"The monarch governed the nation\". </p> <p>If you use sparse vectors (which just check if exact words match), the overlap is basically zero because the English words used are completely different. </p> <p>If you use dense embeddings, a neural network understands the meaning. It projects both sentences to the exact same neighbourhood in a mathematical space because they mean the same thing. Dense embeddings capture semantic similarity, not just lexical overlap.</p>","tags":["foundations","geometry","dimensionality"]},{"location":"part-1-foundations/high-dimensional-geometry/#vector-as-a-point-in-space","title":"Vector as a Point in Space","text":"<p>If a 2D vector like <code>[3, 4]</code> represents a point on a flat sheet of paper, a 768-dimensional vector represents a point in a 768-dimensional universe. </p> <p>Nearest neighbor search in a vector database is fundamentally a geometric problem: If my query is a specific point in this universe, how do I quickly find the dataset points that are physically closest to it?</p>","tags":["foundations","geometry","dimensionality"]},{"location":"part-1-foundations/high-dimensional-geometry/#12-norms-and-distance-metrics","title":"1.2 Norms and Distance Metrics","text":"<p>To figure out which points are \"closest,\" we need a way to measure the distance between two vectors. There are several ways to do this, depending on what kind of data you have.</p>","tags":["foundations","geometry","dimensionality"]},{"location":"part-1-foundations/high-dimensional-geometry/#the-minkowski-family","title":"The Minkowski Family","text":"<p>The Minkowski distance is a generalized mathematical formula that covers many standard ways of measuring distance. Its equation of order $p$ is:</p> $$ d_p(\\mathbf{x}, \\mathbf{y}) = \\left( \\sum_{i=1}^{d} |x_i - y_i|^p \\right)^{1/p} $$ <p>By changing the value of $p$, we get different common distance metrics:</p> Metric $p$ Formula Real-World Analogy Use case Manhattan ($L_1$) 1 $\\sum \\|x_i - y_i\\|$ Driving a taxi through city blocks. You can only move along a grid. Sparse data, robust to outliers Euclidean ($L_2$) 2 $\\sqrt{\\sum (x_i - y_i)^2}$ Taking a helicopter straight from A to B (as the crow flies). The most common default distance Chebyshev ($L_\\infty$) $\\infty$ $\\max_i \\|x_i - y_i\\|$ The distance is just the single largest difference across any one dimension. Worst-case difference analysis","tags":["foundations","geometry","dimensionality"]},{"location":"part-1-foundations/high-dimensional-geometry/#cosine-similarity","title":"Cosine Similarity","text":"<p>While Euclidean distance measures the physical distance between points, Cosine Similarity measures the angle between the two vectors, completely ignoring how \"long\" the vectors are.</p> $$ \\text{cos}(\\mathbf{x}, \\mathbf{y}) = \\frac{\\mathbf{x} \\cdot \\mathbf{y}}{\\|\\mathbf{x}\\| \\, \\|\\mathbf{y}\\|} = \\frac{\\sum_{i=1}^{d} x_i y_i}{\\sqrt{\\sum x_i^2} \\cdot \\sqrt{\\sum y_i^2}} $$ <ul> <li>$\\text{cos} = 1$: The vectors point in the exact same direction.</li> <li>$\\text{cos} = 0$: The vectors are exactly at a 90-degree angle (orthogonal/unrelated).</li> <li>$\\text{cos} = -1$: The vectors point in exactly opposite directions.</li> </ul> <p>ELI5: Cosine Distance vs. Similarity</p> <p>If you're writing a book review, and Alice writes a 1-paragraph positive review while Bob writes a 10-page positive review, the Euclidean distance between their vectors might be huge because Bob's vector is much longer (larger magnitude).  However, the Cosine Similarity will recognize they are both pointing in the \"positive\" direction and score them highly similar. </p> <p>Note: Databases usually compute cosine distance ($1 - \\text{cos}$) because search algorithms inherently look for the \"smallest\" distance.</p>","tags":["foundations","geometry","dimensionality"]},{"location":"part-1-foundations/high-dimensional-geometry/#inner-product-dot-product","title":"Inner Product (Dot Product)","text":"$$ \\text{IP}(\\mathbf{x}, \\mathbf{y}) = \\sum_{i=1}^{d} x_i \\, y_i $$ <p>The Inner Product multiplies matching dimensions and adds them up. It is widely used in Maximum Inner Product Search (MIPS), which is crucial for recommendation systems where the vectors represent user profiles and item profiles, and the dot product represents the \"score\" or likelihood a user clicks an item.</p>","tags":["foundations","geometry","dimensionality"]},{"location":"part-1-foundations/high-dimensional-geometry/#hamming-distance","title":"Hamming Distance","text":"<p>For binary vectors (lists that only contain 0s and 1s), we use the Hamming Distance:</p> $$ d_H(\\mathbf{x}, \\mathbf{y}) = \\sum_{i=1}^{d} \\mathbb{1}[x_i \\neq y_i] $$ <p>This simply counts how many positions are different. It is incredibly fast for computers to calculate using low-level XOR CPU instructions.</p>","tags":["foundations","geometry","dimensionality"]},{"location":"part-1-foundations/high-dimensional-geometry/#implementation","title":"Implementation","text":"<p>Here is a C++ implementation of these core distance metrics. Notice how heavily optimized the AVX2 SIMD version is compared to the naive loop.</p> Key implementation: L2 distance (click to expand) <pre><code>/**\n * Naive L2 squared distance \u2014 scalar loop.\n * Complexity: O(d)\n */\nfloat l2_distance_naive(const float* x, const float* y, size_t d) {\n    float sum = 0.0f;\n    for (size_t i = 0; i &lt; d; ++i) {\n        float diff = x[i] - y[i];\n        sum += diff * diff;\n    }\n    return sum;\n}\n</code></pre> <p>For SIMD-accelerated versions, see Chapter 11 \u2014 Hardware Acceleration.</p>","tags":["foundations","geometry","dimensionality"]},{"location":"part-1-foundations/high-dimensional-geometry/#13-curse-of-dimensionality","title":"1.3 Curse of Dimensionality","text":"","tags":["foundations","geometry","dimensionality"]},{"location":"part-1-foundations/high-dimensional-geometry/#the-problem","title":"The Problem","text":"<p>As the number of dimensions $d$ grows, several deeply counter-intuitive mathematical phenomena start taking place. This is collectively known as the Curse of Dimensionality, and it fundamentally breaks standard database indexing techniques.</p> <p>1. Distance concentration: As dimensions increase to the thousands, the mathematical difference between the \"farthest\" point in your dataset and the \"nearest\" point in your dataset vanishes.</p> $$ \\lim_{d \\to \\infty} \\frac{d_{\\max} - d_{\\min}}{d_{\\min}} \\to 0 $$ <p>ELI5: Imagine searching a massive library for a book on \"Cats\". In a 3-dimensional system, the cat book is 1 foot away, and a book on cars is 100 feet away. Easy. But in 1000-dimensional space, the cat book is 10.0 feet away, and the car book is 10.1 feet away. Everything is basically the same distance apart, making it incredibly hard to confidently say which book is the \"nearest\".</p> <p>2. Volume of hyperspheres vanishes: The volume of an N-dimensional sphere goes to almost zero as dimensions grow toward infinity. Almost all the volume of the space ends up pushed into a razor-thin mathematically dense shell near the surface. </p> <p>3. Orthogonality: If you pick two completely random vectors in high-dimensional space, they are almost guaranteed to be perfectly mathematically orthogonal (at a 90-degree angle to each other).</p> <p>Why does this matter?</p> <p>Traditional databases use \"Tree\" shapes (like B-Trees or KD-trees) to chop up space and quickly find records. Because high-dimensional space is mostly empty, and everything is roughly the exact same distance from everything else, Tree algorithms completely collapse. They end up having to scan every single point anyway (a brute-force $O(n \\cdot d)$ scan). This is why we absolutely need specialized approximate algorithms (Chapter 2).</p>","tags":["foundations","geometry","dimensionality"]},{"location":"part-1-foundations/high-dimensional-geometry/#empirical-visualization","title":"Empirical Visualization","text":"<pre><code>flowchart TD\n    %% Define the progression of the curse\n    subgraph Low Dim [\"Low Dimensions (2D / 3D)\"]\n        direction LR\n        L1(Data is spread out) --&gt; L2(Clear nearest neighbors)\n        L2 --&gt; L3(KD-Trees work effectively)\n    end\n\n    subgraph High Dim [\"High Dimensions (768D+)\"]\n        direction LR\n        H1(Distances cluster near median val) --&gt; H2(All points seem equidistant)\n        H2 --&gt; H3(Trees degrade to O/N.Brute Force)\n    end\n\n    Low Dim ==&gt;|Dimensionality increases| High Dim\n\n    High Dim --&gt; Solution[Solution: Approximate Nearest Neighbor Algorithms]\n\n    style Low Dim fill:#e1f5fe,stroke:#03a9f4,stroke-width:2px;\n    style High Dim fill:#ffebee,stroke:#f44336,stroke-width:2px;\n    style Solution fill:#e8f5e9,stroke:#4caf50,stroke-width:3px;</code></pre>","tags":["foundations","geometry","dimensionality"]},{"location":"part-1-foundations/high-dimensional-geometry/#14-dimensionality-reduction","title":"1.4 Dimensionality Reduction","text":"<p>If high dimensions break our math, can we just shrink the vectors back down to low dimensions before saving them? Yes, but it always comes with trade-offs.</p>","tags":["foundations","geometry","dimensionality"]},{"location":"part-1-foundations/high-dimensional-geometry/#principal-component-analysis-pca","title":"Principal Component Analysis (PCA)","text":"<p>PCA mathematically squeezes the data to preserve the directions holding the maximum variance (the most amount of distinct signal).</p> $$ \\mathbf{z} = W_k^T (\\mathbf{x} - \\boldsymbol{\\mu}) $$ Pros Cons Highly optimal linear reduction It only detects linear shapes, missing complex curved relationships Fast and mathematically proven Requires computing the covariance matrix of your entire dataset upfront","tags":["foundations","geometry","dimensionality"]},{"location":"part-1-foundations/high-dimensional-geometry/#johnson-lindenstrauss-lemma","title":"Johnson-Lindenstrauss Lemma","text":"<p>Theorem (JL Lemma)</p> <p>For any $\\epsilon \\in (0, 1)$ and any set of $n$ points in $\\mathbb{R}^d$, there exists a linear map $f: \\mathbb{R}^d \\to \\mathbb{R}^k$ with: $k = O\\left(\\frac{\\log n}{\\epsilon^2}\\right)$ such that for all pairs of vectors, the distances between them in the low dimensional space are mathematically guaranteed to be almost identical to their distances in the high dimensional space.</p> <p>ELI5: The JL Lemma proves a mathematical miracle \u2014 if you multiply your 1000-dimensional dataset by a completely random grid of numbers (a Gaussian matrix), the dataset will compress down to a few hundred dimensions, and the relative distance between every single point will stay essentially exactly the same. You don't even have to train a model to do this compression; random math does it for you.</p>","tags":["foundations","geometry","dimensionality"]},{"location":"part-1-foundations/high-dimensional-geometry/#umap-and-t-sne","title":"UMAP and t-SNE","text":"<p>These are non-linear methods used purely for visualization. If you want to view your 1000-dimensional embeddings as a 2D scatterplot graph on a computer screen, you use UMAP or t-SNE. </p> <p>Not for search</p> <p>UMAP and t-SNE deliberately warp and distort absolute mathematical distances to make the 2D visual clusters look pretty to humans. You should never run vector searches over UMAP-reduced vectors.</p>","tags":["foundations","geometry","dimensionality"]},{"location":"part-1-foundations/high-dimensional-geometry/#15-measure-concentration-and-its-implications","title":"1.5 Measure Concentration and Its Implications","text":"<p>Because of these mathematical quirks, our standard approaches to building indexes fail. The design of modern vector databases is a direct reaction to these phenomena:</p> Phenomenon Why it hurts How Vector DBs fix it Distance concentration Finding the absolute true closest point requires checking everything They accept finding an approximate closest point instead (Ch 2) Sphere volume goes to zero Grid-based and tree-based partitioning algorithms fail They build Navigable Proximity Graphs (HNSW) instead Data has redundant dimensions Storing floats is expensive for RAM They use Product Quantization (PQ) compression (Ch 3)","tags":["foundations","geometry","dimensionality"]},{"location":"part-1-foundations/high-dimensional-geometry/#references","title":"References","text":"<ol> <li>Aggarwal, C. C., Hinneburg, A., &amp; Keim, D. A. (2001). On the Surprising Behavior of Distance Metrics in High Dimensional Spaces. ICDT.</li> <li>Johnson, W. B., &amp; Lindenstrauss, J. (1984). Extensions of Lipschitz mappings into a Hilbert space. Contemporary Mathematics, 26, 189\u2013206.</li> <li>Blum, A., Hopcroft, J., &amp; Kannan, R. (2020). Foundations of Data Science. Cambridge University Press. Chapter 2: High-Dimensional Space.</li> <li>Dasgupta, S., &amp; Gupta, A. (2003). An elementary proof of a theorem of Johnson and Lindenstrauss. Random Structures &amp; Algorithms.</li> </ol>","tags":["foundations","geometry","dimensionality"]},{"location":"part-1-foundations/index-storage-tradeoffs/","title":"Chapter 3 \u2014 Index-Storage Trade-offs","text":"","tags":["foundations","storage","optimization","quantization"]},{"location":"part-1-foundations/index-storage-tradeoffs/#3-index-storage-trade-offs","title":"3. Index-Storage Trade-offs","text":"<p>A common misconception when building AI applications is that vector databases are just regular databases that happen to support a cosine distance function. In reality, the architecture of a vector database is almost entirely dictated by the harsh physical limitations of computer memory.</p> <p>In this chapter, we explore the fundamental tension between search speed, recall accuracy, and hardware costs, and examine how quantization techniques are used to aggressively compress vector data.</p>","tags":["foundations","storage","optimization","quantization"]},{"location":"part-1-foundations/index-storage-tradeoffs/#31-the-memory-math-of-vector-search","title":"3.1 The Memory Math of Vector Search","text":"","tags":["foundations","storage","optimization","quantization"]},{"location":"part-1-foundations/index-storage-tradeoffs/#calculating-raw-footprint","title":"Calculating Raw Footprint","text":"<p>Unlike standard relational database rows (which might be a few dozen bytes of integers and short strings), embeddings are massive arrays of floating-point numbers.</p> <p>Consider OpenAI's <code>text-embedding-3-small</code> model, which produces 1536-dimensional vectors. * A single standard 32-bit float (<code>f32</code>) consumes 4 bytes. * One vector: $1536 \\times 4 \\text{ bytes} = 6,144 \\text{ bytes (or } 6.1 \\text{ KB)}$.</p> <p>If you have a dataset of just 10 million vectors: $$10,000,000 \\times 6.1 \\text{ KB} = 61.4 \\text{ Gigabytes}$$</p> <p>That $61.4 \\text{ GB}$ is just the raw vector data. It does not include the HNSW graph metadata (which often takes more memory than the vectors themselves), nor does it include the scalar metadata (the JSON document containing the text, author, and date). </p> <p>A 10-million vector index running HNSW effectively requires a dedicated 128GB RAM server. At 1 billion vectors, you are looking at terabytes of RAM, costing tens of thousands of dollars per month to host.</p>","tags":["foundations","storage","optimization","quantization"]},{"location":"part-1-foundations/index-storage-tradeoffs/#the-storage-hierarchy-problem","title":"The Storage Hierarchy Problem","text":"<p>Why can't we just store the vectors on a cheap 1TB hard drive instead of RAM?</p> <p>As we learned in Chapter 2, graph-based algorithms like HNSW require making dozens or hundreds of \"hops\" per query. The algorithm looks at Node A, decides to jump to Node B, then Node X. These jumps are entirely unpredictable and non-sequential.</p> Storage Medium Random Access Latency Bandwidth Cost / TB L3 Cache ~10 ns 1000+ GB/s N/A DRAM (RAM) ~100 ns ~100 GB/s ~$3,000 NVMe SSD ~10,000 ns (10 \u00b5s) ~5 GB/s ~$100 <p>If a query requires 200 random node memory lookups: * In RAM: $200 \\times 100\\text{ns} = 0.02\\text{ms}$. Lightning fast. * On SSD: $200 \\times 10\\text{\u00b5s} = 2.0\\text{ms}$. Slow, but acceptable.</p> <p>However, if you have 1,000 users querying per second, the SSD Queue Depth explodes. The SSD cannot handle 200,000 random IOPS simultaneously without suffering massive latency spikes. To scale throughput, the hot index must live in RAM.</p>","tags":["foundations","storage","optimization","quantization"]},{"location":"part-1-foundations/index-storage-tradeoffs/#32-navigating-the-cap-like-theorem-of-vector-dbs","title":"3.2 Navigating the \"CAP-like\" Theorem of Vector DBs","text":"<p>In distributed systems, the CAP theorem states you can only choose two out of three: Consistency, Availability, Partition tolerance.</p> <p>Vector databases have a similar triangular trade-off rule governing their indexes:</p> <ol> <li>Query Latency (Speed): How fast does a search return? (e.g., &lt; 20ms).</li> <li>Recall (Accuracy): What percentage of the mathematically true top-$k$ results are successfully found?</li> <li>Memory Footprint (Cost): How much RAM does the index consume?</li> </ol> <p>You can mathematically only optimize for two at the expense of the third.</p> <ul> <li>Want high recall and fast queries? You must use uncompressed HNSW, which maximizes memory footprint and triples your AWS bill.</li> <li>Want low memory and fast queries? You must compress the vectors heavily (Quantization), which mathematically degrades your recall accuracy.</li> <li>Want high recall and low memory? You must pull the index off RAM and put it on SSD (DiskANN), which increases your query latency from 2ms to 20ms.</li> </ul>","tags":["foundations","storage","optimization","quantization"]},{"location":"part-1-foundations/index-storage-tradeoffs/#33-vector-compression-quantization","title":"3.3 Vector Compression: Quantization","text":"<p>To break the boundary of the trade-off triangle, engineers developed Quantization. Quantization is a lossy compression algorithm designed specifically to shrink high-dimensional vectors while retaining enough geometric \"shape\" to still execute accurate cosine distances.</p>","tags":["foundations","storage","optimization","quantization"]},{"location":"part-1-foundations/index-storage-tradeoffs/#scalar-quantization-sq","title":"Scalar Quantization (SQ)","text":"<p>The simplest form of compression. Standard vectors use 32-bit floats (<code>f32</code>), which offer incredible precision (7 decimal places). But do we really need that much precision to determine if a vector is generally pointing towards \"Cats\" or \"Dogs\"? No.</p> <p>Scalar Quantization (SQ8) simply maps the minimum and maximum values of the vector dataset into an 8-bit integer range (0 to 255). </p> $$ \\text{int8} \\approx \\text{round}\\left(255 \\times \\frac{x - x_{\\min}}{x_{\\max} - x_{\\min}}\\right) $$ <ul> <li>Impact: Immediately reduces memory usage by 4x (32 bits down to 8 bits).</li> <li>Trade-off: You lose extreme fine-grained distance differentiation, leading to a slight drop in recall (usually &lt; 2%).</li> </ul>","tags":["foundations","storage","optimization","quantization"]},{"location":"part-1-foundations/index-storage-tradeoffs/#product-quantization-pq","title":"Product Quantization (PQ)","text":"<p>When a 4x reduction isn't enough to fit a billion vectors in RAM, we use Product Quantization (PQ). It is significantly more complex, and provides massive compression ratios (up to 96x).</p> <p>Instead of compressing individual numbers, PQ discovers patterns inside the vectors using clustering.</p> <ol> <li>Subspace Splitting: Take a 768-D vector. Chop it into 32 separate \"chunks\" of 24 dimensions each.</li> <li>K-Means Dictionary Construction: For Chunk #1, look at all 1 million vectors. Run k-means to find 256 common \"shapes\" (centroids) that Chunk #1 tends to look like. Assign each of these 256 shapes an ID from 0 to 255. Do this for all 32 chunks.</li> <li>Encoding: Now, to store a new 768-D vector, we don't store floats. We just look at Chunk #1, find the ID of the centroid it most closely matches (say, ID 14), and store <code>14</code>. We do this for all 32 chunks.</li> </ol> <p>Using PQ, the entire 768-dimensional float array (3,072 bytes) is replaced by just an array of 32 bytes (the IDs).</p> <pre><code>flowchart LR\n    subgraph Original Vector [Original 768-D Vector]\n        V1[Chunk 1: 24 floats] --- V2[Chunk 2: 24 floats] --- V3[...] --- V32[Chunk 32: 24 floats]\n    end\n\n    subgraph Codebooks [Trained Dictionaries]\n        C1[\"Codebook 1&lt;br/&gt;(256 shapes)\"]\n        C2[\"Codebook 2&lt;br/&gt;(256 shapes)\"]\n        C32[\"Codebook 32&lt;br/&gt;(256 shapes)\"]\n    end\n\n    subgraph Compressed [Compressed PQ Vector]\n        ID1[\"ID: 14&lt;br/&gt;(1 byte)\"] --- ID2[\"ID: 251&lt;br/&gt;(1 byte)\"] --- ID3[\"...\"] --- ID32[\"ID: 12&lt;br/&gt;(1 byte)\"]\n    end\n\n    V1 -. \"Matches shape #14\" .-&gt; C1\n    V2 -. \"Matches shape #251\" .-&gt; C2\n    V32 -. \"Matches shape #12\" .-&gt; C32\n\n    C1 ==&gt; ID1\n    C2 ==&gt; ID2\n    C32 ==&gt; ID32</code></pre> <p>Asymmetric Distance Computation (ADC): When a user executes a query, tracking down distances against these tiny compressed byte IDs requires looking up the original float distances in a pre-computed math table. PQ searches are highly efficient for memory, but significantly mathematically complex compared to raw L2 distance. (See the C++ implementation in Chapter 2).</p>","tags":["foundations","storage","optimization","quantization"]},{"location":"part-1-foundations/index-storage-tradeoffs/#binary-quantization-bq","title":"Binary Quantization (BQ)","text":"<p>The most extreme form of compression takes a 32-bit float and crushes it down to a single mathematical bit (<code>1</code> or <code>0</code>). </p> <p>If a dimension in a vector is greater than <code>0.0</code>, BQ assigns it a <code>1</code>. If it is less than <code>0.0</code>, BQ assigns it a <code>0</code>. An entire 768-dimensional float vector (3072 bytes) becomes a string of just 768 bits (96 bytes). </p> <ul> <li>Impact: Phenomenal 32x memory compression. More importantly, computing the distance between two BQ vectors does not require floating-point math. The CPU uses a bitwise <code>XOR</code> followed by a <code>popcount</code> (counting the number of '1's), which executes effectively instantly on modern hardware.</li> <li>Trade-off: Enormous precision loss. BQ only works well with specific embedding models (like OpenAI's <code>text-embedding-3-*</code> or Cohere) that inherently distribute their vector dimensions evenly around the origin (0.0).</li> </ul>","tags":["foundations","storage","optimization","quantization"]},{"location":"part-1-foundations/index-storage-tradeoffs/#overfetching-and-rescoring","title":"Overfetching and Rescoring","text":"<p>Because quantization (SQ, PQ, BQ) introduces literal geometric distortion\u2014you are physically moving the vectors slightly to compress them\u2014the mathematical distance calculations will be slightly wrong. </p> <p>To maintain high Recall accuracy, modern vector databases use a two-phase query pipeline known as Overfetching and Rescoring:</p> <ol> <li>Phase 1: Overfetch (Fast). The database uses the heavily compressed vectors in RAM to rapidly find the \"Top 100\" candidates for the user's query.</li> <li>Phase 2: Rescore (Precise). The database takes the exact IDs of those 100 candidates, goes to the slow SSD, fetches the original uncompressed 32-bit float vectors just for those 100 items, recalculates the exact pristine L2/Cosine distances, and returns the true \"Top 10\" to the user.</li> </ol> <p>By overfetching 10x the needed results using compressed data during the heavy graph search, and only rescoring the final tiny handful using exact uncompressed data from disk, databases achieve the best of both worlds: extreme speed, low RAM usage, and near-perfect accuracy.</p>","tags":["foundations","storage","optimization","quantization"]},{"location":"part-1-foundations/index-storage-tradeoffs/#conclusion","title":"Conclusion","text":"<p>Understanding the Index-Storage trade-off is critical. As an architect, your primary task when designing a vector search feature is: 1. Estimate your final dataset size. (Calculated in GB of vectors). 2. Determine your hardware budget. 3. Apply SQ or PQ quantization aggressively until the dataset fits comfortably within 60% of your allocated RAM (leaving 40% for the OS, Graph metadata, and query buffers).</p>","tags":["foundations","storage","optimization","quantization"]},{"location":"part-1-foundations/index-storage-tradeoffs/#assignment-implement-scalar-quantization","title":"\ud83d\udee0 Assignment: Implement Scalar Quantization","text":"<p>Now that you understand the theory behind quantization, let's build a working Scalar Quantization (SQ8) engine in C++. This exercise teaches you how production databases achieve 4x memory savings.</p> <p>Your tasks: 1. Implement <code>quantize()</code> \u2014 map a <code>float32</code> vector to <code>uint8</code> (0\u2013255). 2. Implement <code>dequantize()</code> \u2014 recover approximate floats from <code>uint8</code>. 3. Implement <code>l2_distance_quantized()</code> \u2014 compute L2 distance directly on <code>uint8</code> arrays (fast integer math). 4. Compare recall of quantized search vs. exact float search.</p> Exercise: Implement Scalar Quantization<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;cstdint&gt;\n#include &lt;cmath&gt;\n#include &lt;algorithm&gt;\n#include &lt;random&gt;\n#include &lt;cassert&gt;\n\n// \u2500\u2500 Step 1: Quantization Parameters \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n// Find the global min/max across the dataset to define the mapping range.\nstruct SQParams {\n    float global_min;\n    float global_max;\n    float scale;      // (max - min) / 255\n    float inv_scale;  // 255 / (max - min)\n};\n\nSQParams compute_sq_params(const std::vector&lt;std::vector&lt;float&gt;&gt;&amp; dataset) {\n    float gmin = std::numeric_limits&lt;float&gt;::max();\n    float gmax = std::numeric_limits&lt;float&gt;::lowest();\n    for (const auto&amp; vec : dataset) {\n        for (float v : vec) {\n            gmin = std::min(gmin, v);\n            gmax = std::max(gmax, v);\n        }\n    }\n    float range = gmax - gmin;\n    if (range == 0.0f) range = 1.0f;\n    return {gmin, gmax, range / 255.0f, 255.0f / range};\n}\n\n// \u2500\u2500 Step 2: Quantize float32 \u2192 uint8 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nstd::vector&lt;uint8_t&gt; quantize(const std::vector&lt;float&gt;&amp; vec,\n                              const SQParams&amp; params) {\n    std::vector&lt;uint8_t&gt; qvec(vec.size());\n    for (size_t i = 0; i &lt; vec.size(); ++i) {\n        float normalized = (vec[i] - params.global_min) * params.inv_scale;\n        qvec[i] = static_cast&lt;uint8_t&gt;(\n            std::clamp(std::round(normalized), 0.0f, 255.0f));\n    }\n    return qvec;\n}\n\n// \u2500\u2500 Step 3: Dequantize uint8 \u2192 float32 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nstd::vector&lt;float&gt; dequantize(const std::vector&lt;uint8_t&gt;&amp; qvec,\n                              const SQParams&amp; params) {\n    std::vector&lt;float&gt; vec(qvec.size());\n    for (size_t i = 0; i &lt; qvec.size(); ++i) {\n        vec[i] = static_cast&lt;float&gt;(qvec[i]) * params.scale + params.global_min;\n    }\n    return vec;\n}\n\n// \u2500\u2500 Step 4: L2 Distance on uint8 (Integer Math) \u2500\u2500\u2500\u2500\u2500\n// This runs ~4x faster than float L2 because uint8 fits \n// 4x more values in the same cache line.\nuint32_t l2_distance_quantized(const std::vector&lt;uint8_t&gt;&amp; a,\n                               const std::vector&lt;uint8_t&gt;&amp; b) {\n    uint32_t sum = 0;\n    for (size_t i = 0; i &lt; a.size(); ++i) {\n        int32_t diff = static_cast&lt;int32_t&gt;(a[i]) - static_cast&lt;int32_t&gt;(b[i]);\n        sum += diff * diff;\n    }\n    return sum;\n}\n\n// \u2500\u2500 Step 5: Exact float L2 distance (for comparison) \u2500\nfloat l2_distance_float(const std::vector&lt;float&gt;&amp; a,\n                        const std::vector&lt;float&gt;&amp; b) {\n    float sum = 0.0f;\n    for (size_t i = 0; i &lt; a.size(); ++i) {\n        float diff = a[i] - b[i];\n        sum += diff * diff;\n    }\n    return sum;\n}\n\n// \u2500\u2500 Step 6: Brute-force k-NN using quantized vectors \u2500\nstd::vector&lt;size_t&gt; knn_quantized(const std::vector&lt;std::vector&lt;uint8_t&gt;&gt;&amp; db,\n                                  const std::vector&lt;uint8_t&gt;&amp; query, size_t k) {\n    std::vector&lt;std::pair&lt;uint32_t, size_t&gt;&gt; dists;\n    for (size_t i = 0; i &lt; db.size(); ++i) {\n        dists.push_back({l2_distance_quantized(db[i], query), i});\n    }\n    std::partial_sort(dists.begin(), dists.begin() + k, dists.end());\n    std::vector&lt;size_t&gt; result(k);\n    for (size_t i = 0; i &lt; k; ++i) result[i] = dists[i].second;\n    return result;\n}\n\n// \u2500\u2500 Main: Demonstrate compression ratio and recall \u2500\u2500\u2500\nint main() {\n    const size_t N = 10000, DIM = 128, K = 10;\n    std::mt19937 rng(42);\n    std::uniform_real_distribution&lt;float&gt; dist(-1.0f, 1.0f);\n\n    // Generate random dataset\n    std::vector&lt;std::vector&lt;float&gt;&gt; dataset(N);\n    for (auto&amp; v : dataset) {\n        v.resize(DIM);\n        for (auto&amp; x : v) x = dist(rng);\n    }\n\n    // Generate query\n    std::vector&lt;float&gt; query(DIM);\n    for (auto&amp; x : query) x = dist(rng);\n\n    // Compute exact ground truth (float32 brute force)\n    std::vector&lt;std::pair&lt;float, size_t&gt;&gt; exact_dists;\n    for (size_t i = 0; i &lt; N; ++i)\n        exact_dists.push_back({l2_distance_float(dataset[i], query), i});\n    std::partial_sort(exact_dists.begin(), exact_dists.begin() + K,\n                      exact_dists.end());\n\n    // Quantize the entire dataset\n    auto params = compute_sq_params(dataset);\n    std::vector&lt;std::vector&lt;uint8_t&gt;&gt; qdb(N);\n    for (size_t i = 0; i &lt; N; ++i)\n        qdb[i] = quantize(dataset[i], params);\n    auto qquery = quantize(query, params);\n\n    // Run quantized k-NN\n    auto qresults = knn_quantized(qdb, qquery, K);\n\n    // Compute recall@K\n    size_t hits = 0;\n    for (size_t i = 0; i &lt; K; ++i) {\n        for (size_t j = 0; j &lt; K; ++j) {\n            if (qresults[i] == exact_dists[j].second) { hits++; break; }\n        }\n    }\n    float recall = static_cast&lt;float&gt;(hits) / K;\n\n    // Print results\n    std::cout &lt;&lt; \"=== Scalar Quantization Exercise ===\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Dataset: \" &lt;&lt; N &lt;&lt; \" vectors \u00d7 \" &lt;&lt; DIM &lt;&lt; \"D\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Float32 size: \" &lt;&lt; (N * DIM * 4) / 1024 &lt;&lt; \" KB\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Uint8   size: \" &lt;&lt; (N * DIM * 1) / 1024 &lt;&lt; \" KB\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Compression:  4x\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Recall@\" &lt;&lt; K &lt;&lt; \":     \" &lt;&lt; recall * 100 &lt;&lt; \"%\" &lt;&lt; std::endl;\n\n    assert(recall &gt;= 0.8f &amp;&amp; \"Recall should be &gt;= 80% for SQ8\");\n    std::cout &lt;&lt; \"\u2705 Assertion passed!\" &lt;&lt; std::endl;\n    return 0;\n}\n</code></pre> <p>Compile and run: </p><pre><code>g++ -std=c++17 -O2 -o scalar_quantization scalar_quantization.cpp\n./scalar_quantization\n</code></pre><p></p>","tags":["foundations","storage","optimization","quantization"]},{"location":"part-1-foundations/index-storage-tradeoffs/#references","title":"References","text":"<ol> <li>Jegou, H., Douze, M., &amp; Schmid, C. (2011). Product Quantization for Nearest Neighbor Search. IEEE TPAMI.</li> <li>Pinecone Documentation. Memory and Storage Tradeoffs.</li> </ol>","tags":["foundations","storage","optimization","quantization"]},{"location":"part-1-foundations/query-semantics/","title":"Chapter 4 \u2014 Query Semantics & Vector Similarities","text":"","tags":["foundations","query","similarity"]},{"location":"part-1-foundations/query-semantics/#4-query-semantics-vector-similarities","title":"4. Query Semantics &amp; Vector Similarities","text":"<p>Beyond \"find the $k$ closest vectors,\" real applications demand hybrid queries that mix vector similarity with metadata filters, multi-vector representations, and cost-aware query planning.</p>","tags":["foundations","query","similarity"]},{"location":"part-1-foundations/query-semantics/#41-exact-vs-approximate-search","title":"4.1 Exact vs. Approximate Search","text":"","tags":["foundations","query","similarity"]},{"location":"part-1-foundations/query-semantics/#when-exact-search-is-feasible","title":"When Exact Search Is Feasible","text":"$$ \\text{Brute-force cost} = O(n \\cdot d) $$ <p>Rule of thumb: exact search is practical for $n \\cdot d &lt; 10^8$ (e.g., 100K vectors \u00d7 768-dim = 76.8M operations \u2192 ~1ms on modern CPUs).</p>","tags":["foundations","query","similarity"]},{"location":"part-1-foundations/query-semantics/#approximation-guarantees","title":"Approximation Guarantees","text":"<p>$\\varepsilon$-approximate NN: Find a point $p$ such that:</p> $$ d(q, p) \\leq (1 + \\varepsilon) \\cdot d(q, p^*) $$ <p>where $p^*$ is the true nearest neighbor. LSH provides this guarantee; HNSW does not (but achieves higher recall empirically).</p>","tags":["foundations","query","similarity"]},{"location":"part-1-foundations/query-semantics/#42-k-nn-vs-range-search","title":"4.2 k-NN vs. Range Search","text":"Query Type Semantics Use Case k-NN Return $k$ closest vectors \"Find 10 similar products\" Range ($\\varepsilon$-ball) Return all vectors within distance $r$ \"Find all near-duplicates\" Threshold Return vectors with similarity \u2265 $\\tau$ \"Find relevant documents (score &gt; 0.8)\" <p>Range queries are harder to optimize</p> <p>k-NN has a fixed result size; range queries can return 0 or millions of results. Most ANN indexes are optimized for k-NN.</p>","tags":["foundations","query","similarity"]},{"location":"part-1-foundations/query-semantics/#43-hybrid-predicates-vector-filter","title":"4.3 Hybrid Predicates (Vector + Filter)","text":"<p>Real queries combine vector similarity with scalar/text filters:</p> <pre><code>SELECT * FROM documents\nWHERE category = 'science' AND year &gt;= 2020\nORDER BY vector_distance(embedding, $query_vec)\nLIMIT 10\n</code></pre>","tags":["foundations","query","similarity"]},{"location":"part-1-foundations/query-semantics/#three-filtering-strategies","title":"Three Filtering Strategies","text":"<pre><code>flowchart LR\n    subgraph \"Pre-filter\"\n        A1[Apply filter] --&gt; A2[Search filtered subset]\n    end\n    subgraph \"Post-filter\"\n        B1[ANN search full index] --&gt; B2[Filter top-K results]\n    end\n    subgraph \"In-graph filter\"\n        C1[\"ANN search + skip&lt;br/&gt;non-matching nodes\"]\n    end</code></pre> Strategy Pros Cons Pre-filter Exact filter results May leave too few vectors for good ANN search Post-filter Uses full index quality May discard most results; need large over-fetch In-graph filter Best of both worlds Complex implementation; may break graph connectivity","tags":["foundations","query","similarity"]},{"location":"part-1-foundations/query-semantics/#over-fetching-formula-for-post-filter","title":"Over-fetching Formula for Post-filter","text":"<p>If filter selectivity is $s$ (fraction of vectors passing), fetch:</p> $$ k' = \\frac{k}{s} \\cdot \\alpha $$ <p>where $\\alpha \\approx 1.5\\text{\u2013}3$ is a safety factor to account for non-uniform distribution.</p>","tags":["foundations","query","similarity"]},{"location":"part-1-foundations/query-semantics/#44-multi-vector-queries","title":"4.4 Multi-Vector Queries","text":"","tags":["foundations","query","similarity"]},{"location":"part-1-foundations/query-semantics/#colbert-style-late-interaction","title":"ColBERT-Style Late Interaction","text":"<p>Instead of one vector per document, use multiple vectors (one per token):</p> $$ \\text{score}(q, d) = \\sum_{i=1}^{|q|} \\max_{j=1}^{|d|} \\; \\mathbf{q}_i \\cdot \\mathbf{d}_j $$ <p>This MaxSim operator captures fine-grained token-level interactions.</p>","tags":["foundations","query","similarity"]},{"location":"part-1-foundations/query-semantics/#implications-for-vector-databases","title":"Implications for Vector Databases","text":"<ul> <li>Storage: $|d| \\times$ more vectors per document (typically 128\u2013512)</li> <li>Indexing: Need efficient multi-vector aggregation</li> <li>Query: Sum of per-token max-sim queries</li> </ul>","tags":["foundations","query","similarity"]},{"location":"part-1-foundations/query-semantics/#45-query-planning-and-optimization","title":"4.5 Query Planning and Optimization","text":"","tags":["foundations","query","similarity"]},{"location":"part-1-foundations/query-semantics/#cost-based-planning","title":"Cost-Based Planning","text":"<p>Given a hybrid query, choose the cheapest execution plan:</p> $$ \\text{Cost}_{\\text{pre}} = c_{\\text{filter}}(s) + c_{\\text{ANN}}(s \\cdot n, k) $$ $$ \\text{Cost}_{\\text{post}} = c_{\\text{ANN}}(n, k') + c_{\\text{filter}}(k') $$ <p>Choose whichever is smaller. High selectivity ($s \\ll 1$) favours pre-filter; low selectivity favours post-filter.</p>","tags":["foundations","query","similarity"]},{"location":"part-1-foundations/query-semantics/#caching-strategies","title":"Caching Strategies","text":"Level What to Cache Hit Rate Result cache Full query results Low (queries are unique) Vector cache Hot vectors in memory High for skewed distributions Centroid cache IVF centroid distances Very high (few centroids)","tags":["foundations","query","similarity"]},{"location":"part-1-foundations/query-semantics/#references","title":"References","text":"<ol> <li>Khattab, O., &amp; Zaharia, M. (2020). ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction. SIGIR.</li> <li>Wei, J., et al. (2023). Filtered-DiskANN: Graph Algorithms for Approximate Nearest Neighbor Search with Filters. WWW.</li> </ol>","tags":["foundations","query","similarity"]},{"location":"part-1-foundations/quickstart/","title":"Chapter 0 \u2014 Build a Vector DB from Scratch","text":"","tags":["foundations","exercise","cpp"]},{"location":"part-1-foundations/quickstart/#0-build-a-vector-db-from-scratch-curated-exercise","title":"0. Build a Vector DB from Scratch (Curated Exercise)","text":"<p>Before diving into the high-dimensional math of Chapter 1, the best way to understand a vector database is to build one yourself. </p> <p>In this curated exercise, we will build a functional, in-memory Vector Database from scratch using C++. It will feature: 1. Dense vector storage 2. Brute-force Euclidean distance search 3. A basic metadata filtering system 4. A naive index to speed up the search</p>","tags":["foundations","exercise","cpp"]},{"location":"part-1-foundations/quickstart/#step-1-defining-the-data-structures","title":"Step 1: Defining the Data Structures","text":"<p>First, we need to define what a \"Record\" in our database looks like. A record consists of a unique ID, the high-dimensional float vector (embedding), and some basic metadata.</p> <p>Create a file named <code>VectorDB.hpp</code>:</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;string&gt;\n#include &lt;unordered_map&gt;\n#include &lt;cmath&gt;\n#include &lt;algorithm&gt;\n#include &lt;stdexcept&gt;\n\n// Let's assume we are working with 128-dimensional vectors\nconstexpr size_t DIMENSIONS = 128;\n\nstruct Record {\n    size_t id;\n    std::vector&lt;float&gt; vector;\n    std::string metadata_category; // e.g., \"science\", \"sports\"\n};\n\nclass MiniVectorDB {\nprivate:\n    // Core storage: Maps an ID to its full Record\n    std::unordered_map&lt;size_t, Record&gt; storage;\n    size_t next_id = 1;\n\npublic:\n    MiniVectorDB() = default;\n\n    // We will implement methods here\n};\n</code></pre>","tags":["foundations","exercise","cpp"]},{"location":"part-1-foundations/quickstart/#step-2-the-ingestion-pipeline","title":"Step 2: The Ingestion Pipeline","text":"<p>We need a method to insert vectors into our database. In a real database like Milvus, this involves Write-Ahead Logs (WAL) and memory buffers (see Chapter 6). For our mini-DB, we just insert it into our hash map.</p> <pre><code>    // Add inside MiniVectorDB class:\n\n    size_t insert(const std::vector&lt;float&gt;&amp; vec, const std::string&amp; category = \"\") {\n        if (vec.size() != DIMENSIONS) {\n            throw std::invalid_argument(\"Vector dimension mismatch\");\n        }\n\n        size_t current_id = next_id++;\n        storage[current_id] = {current_id, vec, category};\n\n        return current_id;\n    }\n</code></pre>","tags":["foundations","exercise","cpp"]},{"location":"part-1-foundations/quickstart/#step-3-exact-distance-math-l2","title":"Step 3: Exact Distance Math (L2)","text":"<p>To search, we need a mathematical way to compare two vectors. We will use the squared Euclidean (L2) distance. We use squared L2 because computing the square root (<code>std::sqrt</code>) is computationally expensive and unnecessary when we only care about rank ordering.</p> <pre><code>    // Add inside MiniVectorDB class:\n\n    static float calculate_l2_squared(const std::vector&lt;float&gt;&amp; a, const std::vector&lt;float&gt;&amp; b) {\n        float distance = 0.0f;\n        // Naive loop. In a production DB, this loop is replaced entirely \n        // with AVX2/AVX-512 SIMD instructions (See Chapter 11).\n        for (size_t i = 0; i &lt; DIMENSIONS; ++i) {\n            float diff = a[i] - b[i];\n            distance += diff * diff;\n        }\n        return distance;\n    }\n</code></pre>","tags":["foundations","exercise","cpp"]},{"location":"part-1-foundations/quickstart/#step-4-brute-force-exact-search","title":"Step 4: Brute-Force Exact Search","text":"<p>Now we build the simplest possible search engine: Flat Search (also known as k-Nearest Neighbors or k-NN). It literally loops through every single vector in the database, calculates the math, and returns the top <code>k</code> results.</p> <pre><code>    // Add inside MiniVectorDB class:\n\n    struct SearchResult {\n        size_t id;\n        float distance;\n        bool operator&lt;(const SearchResult&amp; other) const {\n            return distance &lt; other.distance; // We want minimum distance\n        }\n    };\n\n    std::vector&lt;SearchResult&gt; search(const std::vector&lt;float&gt;&amp; query, int k) {\n        std::vector&lt;SearchResult&gt; results;\n        results.reserve(storage.size());\n\n        // 1. Scan every vector in the DB (O(N * d) complexity)\n        for (const auto&amp; [id, record] : storage) {\n            float dist = calculate_l2_squared(query, record.vector);\n            results.push_back({id, dist});\n        }\n\n        // 2. Sort by distance\n        std::sort(results.begin(), results.end());\n\n        // 3. Keep only the Top-K\n        if (results.size() &gt; k) {\n            results.resize(k);\n        }\n\n        return results;\n    }\n</code></pre> <p>Why this is bad: If <code>storage</code> has 1 billion vectors, this single query performs 128 billion floating-point subtractions. It takes seconds or minutes. </p>","tags":["foundations","exercise","cpp"]},{"location":"part-1-foundations/quickstart/#step-5-implementing-hybrid-metadata-filtering","title":"Step 5: Implementing Hybrid Metadata Filtering","text":"<p>Users rarely just search for \"similar vectors\". They search for \"similar vectors WHERE category = 'science'\". Let's add Pre-Filtering to our brute-force search.</p> <pre><code>    std::vector&lt;SearchResult&gt; search_with_filter(\n        const std::vector&lt;float&gt;&amp; query, \n        int k, \n        const std::string&amp; filter_category) \n    {\n        std::vector&lt;SearchResult&gt; results;\n\n        for (const auto&amp; [id, record] : storage) {\n            // Pre-Filter step: skip vectors that don't match the metadata\n            if (record.metadata_category != filter_category) {\n                continue; \n            }\n\n            float dist = calculate_l2_squared(query, record.vector);\n            results.push_back({id, dist});\n        }\n\n        std::sort(results.begin(), results.end());\n        if (results.size() &gt; k) results.resize(k);\n\n        return results;\n    }\n</code></pre>","tags":["foundations","exercise","cpp"]},{"location":"part-1-foundations/quickstart/#step-6-upgrading-to-an-approximate-index-ivf-simulation","title":"Step 6: Upgrading to an Approximate Index (IVF Simulation)","text":"<p>Scanning everything is too slow. Let's implement a rudimentary Inverted File Index (IVF). (Covered extensively in Chapter 2).</p> <p>Instead of scanning all vectors, we will partition the vectors into two \"buckets\" based on their first dimension. If <code>vector[0] &gt; 0</code>, they go to Bucket 1. Otherwise, Bucket 2. When searching, we only scan the bucket that the query vector belongs to.</p> <p>Note: Real databases use k-means clustering to define buckets, but this logic is identical.</p> <pre><code>class FastMiniVectorDB {\nprivate:\n    std::unordered_map&lt;size_t, Record&gt; storage;\n    size_t next_id = 1;\n\n    // Our naive index: Two buckets (Lists of IDs)\n    std::vector&lt;size_t&gt; bucket_positive;\n    std::vector&lt;size_t&gt; bucket_negative;\n\npublic:\n    size_t insert(const std::vector&lt;float&gt;&amp; vec) {\n        size_t id = next_id++;\n        storage[id] = {id, vec, \"\"};\n\n        // Update the Index during ingestion\n        if (vec[0] &gt; 0.0f) {\n            bucket_positive.push_back(id);\n        } else {\n            bucket_negative.push_back(id);\n        }\n        return id;\n    }\n\n    std::vector&lt;SearchResult&gt; fast_search(const std::vector&lt;float&gt;&amp; query, int k) {\n        std::vector&lt;SearchResult&gt; results;\n\n        // 1. Ask the index which bucket to search (Routing)\n        const std::vector&lt;size_t&gt;* target_bucket = &amp;bucket_negative;\n        if (query[0] &gt; 0.0f) {\n            target_bucket = &amp;bucket_positive;\n        }\n\n        // 2. Only compute distance for vectors inside this specific bucket\n        // We have successfully skipped ~50% of the database math!\n        for (size_t id : *target_bucket) {\n            const auto&amp; record = storage[id];\n            float dist = MiniVectorDB::calculate_l2_squared(query, record.vector);\n            results.push_back({id, dist});\n        }\n\n        std::sort(results.begin(), results.end());\n        if (results.size() &gt; k) results.resize(k);\n        return results;\n    }\n};\n</code></pre>","tags":["foundations","exercise","cpp"]},{"location":"part-1-foundations/quickstart/#the-concept-of-recall","title":"The Concept of Recall","text":"<p>Because <code>fast_search</code> didn't check the other bucket, it's possible the true mathematically closest vector was sitting right on the boundary line in the other bucket. The database missed it. This introduces the concept of Approximate Nearest Neighbors (ANN) and the metric of Recall. Our query was 2x faster, but mathematically imperfect. </p>","tags":["foundations","exercise","cpp"]},{"location":"part-1-foundations/quickstart/#conclusion","title":"Conclusion","text":"<p>You have successfully written a vector database. You implemented: 1. Ingestion (<code>insert</code>) 2. Vector Math (<code>calculate_l2_squared</code>) 3. Flat Search (<code>search</code>) 4. Hybrid Search (<code>search_with_filter</code>) 5. Partitioned Indexing (<code>fast_search</code>)</p> <p>Every production vector database works on exactly these principles, just scaled up: * <code>calculate_l2_squared</code> is replaced with <code>AVX-512 FMA SIMD</code> instructions. * The 2-bucket index is replaced with an <code>HNSW</code> multi-layer connection graph. * The <code>unordered_map</code> storage is replaced with <code>Memory-Mapped Columnar</code> files.</p> <p>Read on to Chapter 1 to understand the geometry that necessitates these massive scale-ups.</p>","tags":["foundations","exercise","cpp"]},{"location":"part-2-architecture/","title":"Part II \u2014 System Architecture","text":""},{"location":"part-2-architecture/#part-ii-system-architecture","title":"Part II \u2014 System Architecture","text":"<p>This section takes you inside the architecture of production vector databases. You'll understand how the core components fit together, how data is stored and replicated, and how hybrid search combines vector similarity with traditional filtering.</p>"},{"location":"part-2-architecture/#chapters","title":"Chapters","text":"# Chapter Key Topics 6 Core Components Ingest, index builder, query engine, storage, scheduler, WAL 7 Storage Engines LSM trees, columnar layouts, delta-merge for mutable vectors 8 Distributed Vector Stores Sharding, consistency, replication, cloud-native DB comparison 9 Real-Time Update Handling Dynamic indexes, HNSW layer fan-out, graph-merge 10 Hybrid Search Score fusion, BM25 + ANN rerank, metadata filtering 11 Hardware Acceleration SIMD, GPU, FPGA, NUMA pinning, RDMA 12 Observability &amp; Operations Latency histograms, index health, auto-tuning"},{"location":"part-2-architecture/core-components/","title":"Chapter 6 \u2014 Core Components","text":"","tags":["architecture","components"]},{"location":"part-2-architecture/core-components/#6-core-components","title":"6. Core Components","text":"<p>Whether you are using Milvus, Qdrant, Weaviate, or Pinecone, all modern vector databases share a fundamentally similar internal architecture. Unlike traditional relational databases which are primarily concerned with row-based transactions, vector databases are entirely optimized around feeding massive tensors of floats into specialized graph or tree structures.  This chapter maps out these sub-systems in plain English.</p>","tags":["architecture","components"]},{"location":"part-2-architecture/core-components/#61-system-overview","title":"6.1 System Overview","text":"<p>The fastest way to understand a vector database is to follow the lifecycle of a request as it passes through the system.</p> <p>When a client sends an embedding vector to be stored, it doesn't just go straight into a search index. It passes through API layers, buffering systems, and durability logs before it is finally constructed into an HNSW graph or IVF cluster.</p> <pre><code>flowchart TD\n    subgraph ClientLayer [\"Client Application\"]\n        Client[\"Client Requests&lt;br/&gt;REST / gRPC\"]\n    end\n\n    subgraph API Gateway\n        API[\"API Router&lt;br/&gt;Auth &amp; Rate Limiting\"]\n    end\n\n    subgraph Write Path [\"Ingestion Pipeline (Asynchronous)\"]\n        direction TB\n        IL[\"Ingest Node&lt;br/&gt;Validation &amp; Buffering\"]\n        WAL[(\"Write-Ahead Log&lt;br/&gt;Disk Persistence\")]\n        IB[\"Index Builder&lt;br/&gt;Background Workers\"]\n\n        IL --&gt;|Write| WAL\n        WAL --&gt;|Acknowledge| IL\n        WAL -.-&gt;|Async Replay| IB\n    end\n\n    subgraph Read Path [\"Query Pipeline (Synchronous)\"]\n        direction TB\n        QE[\"Query Engine&lt;br/&gt;Execution Planner\"]\n    end\n\n    subgraph Storage Layer [\"Data Storage\"]\n        direction LR\n        SI[(\"Search Index&lt;br/&gt;HNSW / IVF-PQ\")]\n        VS[(\"Vector Storage&lt;br/&gt;Raw Float Data\")]\n    end\n\n    Client --&gt; API\n    API --&gt;|Insert/Upsert| IL\n    API --&gt;|Search/k-NN| QE\n\n    IB --&gt;|Build Graph| SI\n    IL --&gt;|Store Raw| VS\n\n    QE --&gt;|Find Neighbors| SI\n    QE --&gt;|Fetch Payloads| VS\n\n    style Write Path fill:#fff3e0,stroke:#f57c00\n    style Read Path fill:#e8f5e9,stroke:#4caf50\n    style Storage Layer fill:#e3f2fd,stroke:#1e88e5</code></pre>","tags":["architecture","components"]},{"location":"part-2-architecture/core-components/#62-the-ingest-layer","title":"6.2 The Ingest Layer","text":"<p>The ingest layer handles your <code>insert</code> and <code>upsert</code> API payloads. Its job is simply to get data safely accepted as fast as possible so the client isn't waiting.</p> <p>Because inserting a node into a complex mathematical graph (like HNSW) is mathematically heavy and requires scanning memory, databases almost never do this \"synchronously\" while the client waits. </p> <p>Instead, they use Buffered Writes. The database immediately dumps the vectors into a fast, temporary memory buffer. It acknowledges the successful write to the user, and then a background worker quietly handles the intense math required to plug those vectors into the HNSW graph over the next few seconds. This is why a vector database can process 100,000 requests a second, but it might take 2-3 seconds for your new document to appear in search results.</p>","tags":["architecture","components"]},{"location":"part-2-architecture/core-components/#63-the-write-ahead-log-wal","title":"6.3 The Write-Ahead Log (WAL)","text":"<p>If write requests are sitting around in temporary memory buffers waiting to be calculated into the graph, what happens if the server loses power? All those vectors disappear.</p> <p>To guarantee durability (the 'D' in ACID databases), the database uses a Write-Ahead Log.</p> <ol> <li>The client sends a vector insert.</li> <li>The database appends the raw vector to a simple <code>.log</code> file on the hard drive. </li> <li>Only now does it tell the client \"Success\".</li> <li>If the server crashes, on reboot it simply reads the <code>.log</code> file and reconstructs the memory buffer.</li> </ol> <p>Writing a single line to a <code>.log</code> file is lightning fast. Calculating an HNSW node connection is slow. The WAL decouples the two.</p>","tags":["architecture","components"]},{"location":"part-2-architecture/core-components/#64-the-index-builder","title":"6.4 The Index Builder","text":"<p>The index builder is the core engine room of the database. These are heavy background threads that drain the WAL and execute the complex algorithms described in Chapter 2. </p> <p>Because graph construction is intense, index builders operate on a segment architecture. They don't try to build one gigantic monolithic index. They build tiny HNSW indexes containing, for instance, 100,000 vectors at a time. Once a tiny segment is \"full\", they seal it. </p>","tags":["architecture","components"]},{"location":"part-2-architecture/core-components/#warm-up-delays","title":"Warm-up Delays","text":"<p>If you restart a vector database containing 200 million vectors, it will take significant time (often 1-2 full minutes) merely to read the massive multi-gigabyte HNSW index off the NVMe drive and load it into RAM before it can answer a single search query.</p>","tags":["architecture","components"]},{"location":"part-2-architecture/core-components/#65-the-query-engine","title":"6.5 The Query Engine","text":"<p>When you search for <code>\"How to train an AI\"</code>, the query engine takes control:</p> <ol> <li>Parse: Understand if this is just a vector search, or if there are metadata filters (e.g., <code>author=\"Google\"</code>).</li> <li>Plan: Decide whether to filter the metadata before checking the vector index, or after. (See Chapter 10).</li> <li>Execute: It queries every single sealed Segment concurrently across multiple CPU threads.</li> <li>Merge: By finding the \"Top 10\" from Segment A, Segment B, and Segment C, it mathematically calculates the overall true Top 10 across the entire database.</li> <li>Enrich: It takes the Top 10 internal database IDs and goes to the raw Vector Storage to fetch the actual JSON payload, original text, and original float array to return to the user.</li> </ol>","tags":["architecture","components"]},{"location":"part-2-architecture/core-components/#assignment-implement-a-write-ahead-log-wal","title":"Assignment: Implement a Write-Ahead Log (WAL)","text":"<p>To make your <code>MiniVectorDB</code> from Chapter 0 durable against crashes, you must implement a Write-Ahead Log. Before modifying the in-memory <code>unordered_map</code>, the server must write the command to an append-only file on disk.</p>","tags":["architecture","components"]},{"location":"part-2-architecture/core-components/#goal","title":"Goal","text":"<p>Implement an <code>append_to_wal</code> function that writes raw vector floats to a <code>.log</code> file during <code>insert()</code>. Write a <code>recover_from_wal</code> function that runs when the database boots up, reading the <code>.log</code> file and rebuilding the in-memory hash map.</p> Exercise: Implement the WAL<pre><code>#include &lt;fstream&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nclass DurableVectorDB {\nprivate:\n    std::unordered_map&lt;size_t, Record&gt; storage;\n    size_t next_id = 1;\n    std::ofstream wal_file;\n\npublic:\n    DurableVectorDB() {\n        // Open log file in append &amp; binary mode\n        wal_file.open(\"vectors.log\", std::ios::app | std::ios::binary);\n\n        // EXERCISE 2: Call recovery on boot\n        recover_from_wal();\n    }\n\n    ~DurableVectorDB() {\n        wal_file.close();\n    }\n\n    size_t insert(const std::vector&lt;float&gt;&amp; vec) {\n        size_t id = next_id++;\n\n        // 1. Durability: Write to disk *first*\n        append_to_wal(id, vec);\n\n        // 2. State update: Update fast memory *second*\n        storage[id] = {id, vec, \"\"};\n        return id;\n    }\n\nprivate:\n    void append_to_wal(size_t id, const std::vector&lt;float&gt;&amp; vec) {\n        // Write the ID\n        wal_file.write(reinterpret_cast&lt;const char*&gt;(&amp;id), sizeof(id));\n\n        // Write the size of the vector\n        size_t vec_size = vec.size();\n        wal_file.write(reinterpret_cast&lt;const char*&gt;(&amp;vec_size), sizeof(vec_size));\n\n        // EXERCISE 1: Write the actual float array payload to the file stream\n\n        /* Write your serialization code here */\n\n        // Force OS to physically write to SSD\n        wal_file.flush(); \n    }\n\n    void recover_from_wal() {\n        std::ifstream in_file(\"vectors.log\", std::ios::binary);\n        if (!in_file.is_open()) return;\n\n        std::cout &lt;&lt; \"Recovering DB from WAL...\" &lt;&lt; std::endl;\n\n        // EXERCISE 2: Read the file sequentially until EOF, \n        // parsing out `id` and `vec`, and injecting them straight into `storage`.\n        // Don't forget to update `next_id` so new inserts don't overwrite recovered ones!\n\n        /* Write your deserialization loop here */\n    }\n};\n</code></pre>","tags":["architecture","components"]},{"location":"part-2-architecture/core-components/#references","title":"References","text":"<ol> <li>Wang, J., et al. (2021). Milvus: A Purpose-Built Vector Data Management System. SIGMOD.</li> <li>Qdrant Documentation. Architecture Overview. https://qdrant.tech/documentation/</li> </ol>","tags":["architecture","components"]},{"location":"part-2-architecture/distributed-stores/","title":"Chapter 8 \u2014 Distributed Vector Stores","text":"","tags":["architecture","distributed","sharding"]},{"location":"part-2-architecture/distributed-stores/#8-distributed-vector-stores","title":"8. Distributed Vector Stores","text":"<p>A single powerful physical server with 256GB of RAM can typically hold about 50 to 100 million high-dimensional dense vectors in an HNSW graph. But production workloads at companies like Spotify, Meta, or OpenAI deal with billions of vectors representing images, audio clips, and chunks of massive codebases.</p> <p>When data exceeds the RAM of a single machine, we must distribute our database across a cluster. Splitting a standard database (like Postgres) by User ID is easy. Splitting high-dimensional geometric spaces is deeply complicated.</p>","tags":["architecture","distributed","sharding"]},{"location":"part-2-architecture/distributed-stores/#81-sharding-strategies","title":"8.1 Sharding Strategies","text":"<p>If you have 1 billion vectors, you might split them into four \"Shards\" of 250 million vectors each, hosted on four separate servers. But when a search query comes in, how do we know which server holds the closest match? </p>","tags":["architecture","distributed","sharding"]},{"location":"part-2-architecture/distributed-stores/#data-parallel-sharding-the-scatter-gather-method","title":"Data-Parallel Sharding (The Scatter-Gather Method)","text":"<p>The simplest and most robust approach used by almost all commercial vector databases: search everywhere at once.</p> <p>Because we don't know mathematically where the nearest neighbour is, the central router simply broadcasts the query vector to all Shards simultaneously. Every Shard computes its own local Top $K$ closest results. The router then collects these independent lists, merges them, sorts them by distance, and returns the absolute global Top $K$.</p> <pre><code>flowchart TD\n    Q[\"User Client&lt;br/&gt;Query Vector\"] --&gt; R{Central Vector Router}\n\n    subgraph Cluster [\"Distributed Cluster Environment\"]\n        S1[\"Shard Node 1&lt;br/&gt;Vectors 0 to 250M\"]\n        S2[\"Shard Node 2&lt;br/&gt;Vectors 250M to 500M\"]\n        S3[\"Shard Node 3&lt;br/&gt;Vectors 500M to 750M\"]\n        S4[\"Shard Node 4&lt;br/&gt;Vectors 750M to 1B\"]\n    end\n\n    R -- \"Scatter Query\" --&gt; S1\n    R -- \"Scatter Query\" --&gt; S2\n    R -- \"Scatter Query\" --&gt; S3\n    R -- \"Scatter Query\" --&gt; S4\n\n    S1 -- \"Return Local Top-10\" --&gt; Merge\n    S2 -- \"Return Local Top-10\" --&gt; Merge\n    S3 -- \"Return Local Top-10\" --&gt; Merge\n    S4 -- \"Return Local Top-10\" --&gt; Merge\n\n    Merge[\"Aggregator Node&lt;br/&gt;Merge-Sort All 40 Results\"] --&gt; Result[Global Top-10]\n\n    style R fill:#fff59d,stroke:#fbc02d\n    style Merge fill:#ce93d8,stroke:#ab47bc\n    style Result fill:#a5d6a7,stroke:#388e3c</code></pre> <p>The Catch: Your overall query is only as fast as your slowest individual shard.</p>","tags":["architecture","distributed","sharding"]},{"location":"part-2-architecture/distributed-stores/#82-replication-and-high-availability","title":"8.2 Replication and High Availability","text":"","tags":["architecture","distributed","sharding"]},{"location":"part-2-architecture/distributed-stores/#read-replicas-for-traffic","title":"Read Replicas for Traffic","text":"<p>Sharding solves the problem of \"Too much data to fit in RAM\". Replication solves the problem of \"Too many users querying at the same time\".</p> <p>If you copy Shard 1 onto three identical servers, the system routes incoming questions in a round-robin style across those three servers.</p> $$ \\text{QPS}_{\\text{total}} = \\text{Replicas} \\times \\text{QPS}_{\\text{per-machine}} $$","tags":["architecture","distributed","sharding"]},{"location":"part-2-architecture/distributed-stores/#consistency-semantics-in-vector-dbs","title":"Consistency Semantics in Vector DBs","text":"<p>When you insert a new vector into a distributed system, it takes a few milliseconds or seconds for that update to physically sync across all replicas over the network.</p> <p>Traditional databases panic about this (if a bank balance is out of sync, the bank collapses). Vector databases operate differently. </p> <p>Vector databases almost universally prioritize \"Eventual Consistency\" or \"Bounded Staleness\". If a user uploads a new PDF and asks a question about it 200 milliseconds later, there is a tiny chance the query hits a replica that hasn't seen the PDF yet. For semantic similarity search, missing one vector out of a billion temporarily is practically unnoticeable to human users. The trade-off is massive, hyper-fast read availability.</p>","tags":["architecture","distributed","sharding"]},{"location":"part-2-architecture/distributed-stores/#83-consensus-and-orchestration","title":"8.3 Consensus and Orchestration","text":"<p>If a single shard catches fire and the server dies, the cluster needs to reroute traffic to a backup replica within milliseconds. </p> <p>Databases handle this via consensus protocols: * Raft: Qdrant compiles the Raft protocol directly into the database binary. Nodes constantly ping each other natively. * etcd / Zookeeper: Milvus relies on dedicated external coordination clustered services to monitor the health of worker nodes. </p>","tags":["architecture","distributed","sharding"]},{"location":"part-2-architecture/distributed-stores/#assignment-simulate-scatter-gather-distributed-search","title":"\ud83d\udee0 Assignment: Simulate Scatter-Gather Distributed Search","text":"<p>Let's build a working simulation of the Scatter-Gather pattern described in Section 8.1. You will split a dataset across multiple shard nodes, broadcast a query to all shards, and merge-sort the local results into a globally correct Top-K answer.</p> <p>Your tasks: 1. Implement a <code>ShardNode</code> that stores vectors and performs local brute-force k-NN. 2. Implement <code>scatter_query()</code> to broadcast the query to all shards. 3. Implement <code>gather_results()</code> to merge-sort local top-K lists into a global top-K. 4. Verify that the distributed result matches a monolithic (single-node) search.</p> Exercise: Scatter-Gather Sharding<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;algorithm&gt;\n#include &lt;random&gt;\n#include &lt;cassert&gt;\n#include &lt;cmath&gt;\n\n// \u2500\u2500 L2 Distance \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nfloat l2_dist(const std::vector&lt;float&gt;&amp; a, const std::vector&lt;float&gt;&amp; b) {\n    float sum = 0;\n    for (size_t i = 0; i &lt; a.size(); ++i) {\n        float d = a[i] - b[i];\n        sum += d * d;\n    }\n    return sum;\n}\n\nstruct SearchResult {\n    size_t global_id;\n    float distance;\n    bool operator&lt;(const SearchResult&amp; o) const { return distance &lt; o.distance; }\n};\n\n// \u2500\u2500 Step 1: A single Shard Node \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n// Each shard holds a subset of vectors and can answer local k-NN queries.\nclass ShardNode {\npublic:\n    void add(size_t global_id, const std::vector&lt;float&gt;&amp; vec) {\n        ids_.push_back(global_id);\n        data_.push_back(vec);\n    }\n\n    // Local brute-force search returning the shard's top-K\n    std::vector&lt;SearchResult&gt; local_search(const std::vector&lt;float&gt;&amp; query,\n                                           size_t k) const {\n        std::vector&lt;SearchResult&gt; results;\n        for (size_t i = 0; i &lt; data_.size(); ++i) {\n            results.push_back({ids_[i], l2_dist(data_[i], query)});\n        }\n        size_t n = std::min(k, results.size());\n        std::partial_sort(results.begin(), results.begin() + n, results.end());\n        results.resize(n);\n        return results;\n    }\n\n    size_t size() const { return data_.size(); }\n\nprivate:\n    std::vector&lt;size_t&gt; ids_;\n    std::vector&lt;std::vector&lt;float&gt;&gt; data_;\n};\n\n// \u2500\u2500 Step 2: Scatter \u2014 broadcast query to all shards \u2500\u2500\nstd::vector&lt;std::vector&lt;SearchResult&gt;&gt; scatter_query(\n    const std::vector&lt;ShardNode&gt;&amp; shards,\n    const std::vector&lt;float&gt;&amp; query, size_t k)\n{\n    std::vector&lt;std::vector&lt;SearchResult&gt;&gt; all_local;\n    for (const auto&amp; shard : shards) {\n        all_local.push_back(shard.local_search(query, k));\n    }\n    return all_local;\n}\n\n// \u2500\u2500 Step 3: Gather \u2014 merge-sort into global Top-K \u2500\u2500\u2500\u2500\nstd::vector&lt;SearchResult&gt; gather_results(\n    const std::vector&lt;std::vector&lt;SearchResult&gt;&gt;&amp; local_results,\n    size_t k)\n{\n    std::vector&lt;SearchResult&gt; merged;\n    for (const auto&amp; local : local_results) {\n        merged.insert(merged.end(), local.begin(), local.end());\n    }\n    size_t n = std::min(k, merged.size());\n    std::partial_sort(merged.begin(), merged.begin() + n, merged.end());\n    merged.resize(n);\n    return merged;\n}\n\n// \u2500\u2500 Main: Verify distributed == monolithic \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nint main() {\n    const size_t N = 5000, DIM = 64, K = 10, NUM_SHARDS = 4;\n    std::mt19937 rng(42);\n    std::uniform_real_distribution&lt;float&gt; dist(-1.0f, 1.0f);\n\n    // Generate dataset\n    std::vector&lt;std::vector&lt;float&gt;&gt; dataset(N);\n    for (auto&amp; v : dataset) {\n        v.resize(DIM);\n        for (auto&amp; x : v) x = dist(rng);\n    }\n\n    // Distribute across shards using hash-based assignment\n    std::vector&lt;ShardNode&gt; shards(NUM_SHARDS);\n    for (size_t i = 0; i &lt; N; ++i) {\n        shards[i % NUM_SHARDS].add(i, dataset[i]);\n    }\n\n    // Generate query\n    std::vector&lt;float&gt; query(DIM);\n    for (auto&amp; x : query) x = dist(rng);\n\n    // Distributed search: scatter + gather\n    auto local_results = scatter_query(shards, query, K);\n    auto distributed_topk = gather_results(local_results, K);\n\n    // Monolithic ground truth\n    std::vector&lt;SearchResult&gt; mono;\n    for (size_t i = 0; i &lt; N; ++i)\n        mono.push_back({i, l2_dist(dataset[i], query)});\n    std::partial_sort(mono.begin(), mono.begin() + K, mono.end());\n\n    // Verify exact match\n    bool match = true;\n    for (size_t i = 0; i &lt; K; ++i) {\n        if (distributed_topk[i].global_id != mono[i].global_id) {\n            match = false;\n            break;\n        }\n    }\n\n    std::cout &lt;&lt; \"=== Scatter-Gather Sharding Exercise ===\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Dataset: \" &lt;&lt; N &lt;&lt; \" vectors across \"\n              &lt;&lt; NUM_SHARDS &lt;&lt; \" shards\" &lt;&lt; std::endl;\n    for (size_t i = 0; i &lt; NUM_SHARDS; ++i)\n        std::cout &lt;&lt; \"  Shard \" &lt;&lt; i &lt;&lt; \": \" &lt;&lt; shards[i].size()\n                  &lt;&lt; \" vectors\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Distributed Top-\" &lt;&lt; K &lt;&lt; \" matches monolithic: \"\n              &lt;&lt; (match ? \"YES\" : \"NO\") &lt;&lt; std::endl;\n\n    assert(match &amp;&amp; \"Distributed search must match monolithic search!\");\n    std::cout &lt;&lt; \"\u2705 Assertion passed!\" &lt;&lt; std::endl;\n    return 0;\n}\n</code></pre> <p>Compile and run: </p><pre><code>g++ -std=c++17 -O2 -o scatter_gather scatter_gather.cpp\n./scatter_gather\n</code></pre><p></p>","tags":["architecture","distributed","sharding"]},{"location":"part-2-architecture/distributed-stores/#references","title":"References","text":"<ol> <li>Wang, J., et al. (2021). Milvus: A Purpose-Built Vector Data Management System. SIGMOD.</li> <li>Qdrant. Distributed Deployment Architecture. https://qdrant.tech/documentation/guides/distributed_deployment/</li> </ol>","tags":["architecture","distributed","sharding"]},{"location":"part-2-architecture/hardware-acceleration/","title":"Chapter 11 \u2014 Hardware Acceleration","text":"","tags":["architecture","hardware","simd","gpu"]},{"location":"part-2-architecture/hardware-acceleration/#11-hardware-acceleration","title":"11. Hardware Acceleration","text":"<p>The inner loop of vector search \u2014 distance computation \u2014 runs billions of times per second. This chapter covers how hardware features can accelerate it by 10\u2013100\u00d7.</p>","tags":["architecture","hardware","simd","gpu"]},{"location":"part-2-architecture/hardware-acceleration/#111-simd-single-instruction-multiple-data","title":"11.1 SIMD (Single Instruction, Multiple Data)","text":"","tags":["architecture","hardware","simd","gpu"]},{"location":"part-2-architecture/hardware-acceleration/#avx2-process-8-floats-simultaneously","title":"AVX2: Process 8 Floats Simultaneously","text":"<p>A single AVX2 instruction operates on 256-bit registers = 8 \u00d7 float32:</p> C++ AVX2-Optimized L2 Distance (click to expand) <pre><code>#ifdef __AVX2__\n#include &lt;immintrin.h&gt;\n\n/**\n * AVX2-optimized L2 squared distance.\n *\n * Processes 8 floats per iteration using 256-bit SIMD registers.\n * ~4-8x faster than scalar on modern CPUs.\n */\nfloat l2_distance_avx2(const float* x, const float* y, size_t d) {\n    __m256 sum = _mm256_setzero_ps();\n    size_t i = 0;\n\n    // Process 8 floats at a time\n    for (; i + 8 &lt;= d; i += 8) {\n        __m256 vx = _mm256_loadu_ps(x + i);\n        __m256 vy = _mm256_loadu_ps(y + i);\n        __m256 diff = _mm256_sub_ps(vx, vy);\n        sum = _mm256_fmadd_ps(diff, diff, sum);  // FMA: sum += diff * diff\n    }\n\n    // Horizontal sum of 8 floats in sum register\n    __m128 hi = _mm256_extractf128_ps(sum, 1);\n    __m128 lo = _mm256_castps256_ps128(sum);\n    __m128 sum128 = _mm_add_ps(lo, hi);\n    sum128 = _mm_hadd_ps(sum128, sum128);\n    sum128 = _mm_hadd_ps(sum128, sum128);\n    float result = _mm_cvtss_f32(sum128);\n\n    // Handle remaining elements\n    for (; i &lt; d; ++i) {\n        float diff = x[i] - y[i];\n        result += diff * diff;\n    }\n\n    return result;\n}\n#endif\n</code></pre>","tags":["architecture","hardware","simd","gpu"]},{"location":"part-2-architecture/hardware-acceleration/#performance-impact","title":"Performance Impact","text":"Implementation Throughput (768-dim) Speedup Scalar loop ~50M dist/sec 1\u00d7 AVX2 ~350M dist/sec 7\u00d7 AVX-512 (where available) ~600M dist/sec 12\u00d7","tags":["architecture","hardware","simd","gpu"]},{"location":"part-2-architecture/hardware-acceleration/#key-simd-instructions-for-vector-search","title":"Key SIMD Instructions for Vector Search","text":"Instruction Width Operation Use <code>_mm256_sub_ps</code> 8 \u00d7 f32 Subtraction diff = x - y <code>_mm256_fmadd_ps</code> 8 \u00d7 f32 Fused multiply-add sum += diff * diff <code>_mm256_dp_ps</code> 8 \u00d7 f32 Dot product Inner product <code>_mm_popcnt_u64</code> 64-bit Population count Hamming distance","tags":["architecture","hardware","simd","gpu"]},{"location":"part-2-architecture/hardware-acceleration/#112-gpu-acceleration","title":"11.2 GPU Acceleration","text":"","tags":["architecture","hardware","simd","gpu"]},{"location":"part-2-architecture/hardware-acceleration/#when-gpus-help","title":"When GPUs Help","text":"<p>GPUs excel at batch queries over large datasets:</p> $$ \\text{GPU speedup} \\propto \\frac{\\text{parallelizable work}}{\\text{data transfer cost}} $$ <p>FAISS GPU can process 10K+ queries/sec at 1M vectors \u2014 but data must fit in GPU memory (24\u201380 GB).</p>","tags":["architecture","hardware","simd","gpu"]},{"location":"part-2-architecture/hardware-acceleration/#gpu-architecture-for-vector-search","title":"GPU Architecture for Vector Search","text":"<pre><code>flowchart LR\n    subgraph GPU\n        SM1[SM 0: 32 queries] --&gt; L2[Shared L2 Cache]\n        SM2[SM 1: 32 queries] --&gt; L2\n        L2 --&gt; HBM[HBM: Vectors + Index]\n    end\n    CPU --&gt; PCIe --&gt; GPU</code></pre>","tags":["architecture","hardware","simd","gpu"]},{"location":"part-2-architecture/hardware-acceleration/#cpu-vs-gpu-decision-matrix","title":"CPU vs. GPU Decision Matrix","text":"Factor Prefer CPU Prefer GPU Query volume &lt; 100 QPS &gt; 1000 QPS Batch size 1 (single query) 100+ (batch) Index updates Frequent Rare (batch rebuild) Memory capacity &gt; 80 GB \u2264 GPU memory Latency requirement &lt; 1ms &lt; 10ms acceptable","tags":["architecture","hardware","simd","gpu"]},{"location":"part-2-architecture/hardware-acceleration/#113-fpga","title":"11.3 FPGA","text":"<p>Field-Programmable Gate Arrays offer deterministic latency \u2014 no OS jitter, no garbage collection:</p> Aspect GPU FPGA Throughput Very high High Latency Variable (\u03bcs\u2013ms) Deterministic (ns\u2013\u03bcs) Power 300\u2013700W 20\u201375W Programming CUDA (easy) Verilog/HLS (hard) Flexibility High Low (post-synthesis) <p>Microsoft's Catapult project used FPGAs for Bing search acceleration.</p>","tags":["architecture","hardware","simd","gpu"]},{"location":"part-2-architecture/hardware-acceleration/#114-numa-aware-design","title":"11.4 NUMA-Aware Design","text":"<p>On multi-socket servers, accessing remote NUMA memory costs 2\u20133\u00d7 more than local:</p> $$ \\text{Remote access latency} \\approx 2\\text{\u2013}3 \\times \\text{local access latency} $$ <p>NUMA trap</p> <p>A na\u00efve HNSW implementation that allocates vectors across NUMA nodes will see ~40% latency regression vs. NUMA-aware placement.</p>","tags":["architecture","hardware","simd","gpu"]},{"location":"part-2-architecture/hardware-acceleration/#numa-aware-strategies","title":"NUMA-Aware Strategies","text":"<ol> <li>Pin threads to NUMA nodes; keep their data local</li> <li>Shard by NUMA node \u2014 each node has its own index partition</li> <li>Interleave for read-heavy workloads where all threads access all data</li> </ol>","tags":["architecture","hardware","simd","gpu"]},{"location":"part-2-architecture/hardware-acceleration/#115-rdma-remote-direct-memory-access","title":"11.5 RDMA (Remote Direct Memory Access)","text":"<p>For distributed vector databases, RDMA enables direct memory-to-memory data transfer between nodes, bypassing the OS kernel:</p> TCP/IP RDMA CPU involvement Both sides Zero-copy Latency 50\u2013100 \u03bcs 1\u20133 \u03bcs Throughput 10\u201325 Gbps 100+ Gbps <p>Used in high-performance vector search clusters where shard-to-shard communication is the bottleneck.</p>","tags":["architecture","hardware","simd","gpu"]},{"location":"part-2-architecture/hardware-acceleration/#references","title":"References","text":"<ol> <li>Johnson, J., Douze, M., &amp; J\u00e9gou, H. (2019). Billion-scale similarity search with GPUs (FAISS). IEEE TBD.</li> <li>Intel. Intel Intrinsics Guide. https://www.intel.com/content/www/us/en/docs/intrinsics-guide/</li> <li>Putnam, A., et al. (2014). A Reconfigurable Fabric for Accelerating Large-Scale Datacenter Services (Catapult). ISCA.</li> </ol>","tags":["architecture","hardware","simd","gpu"]},{"location":"part-2-architecture/hybrid-search/","title":"Chapter 10 \u2014 Hybrid Search","text":"","tags":["architecture","hybrid","bm25"]},{"location":"part-2-architecture/hybrid-search/#10-hybrid-search","title":"10. Hybrid Search","text":"<p>For the first few years of the AI boom, developers believed that Semantic Vector Search would completely replace traditional keyword search (like Elasticsearch or SQL <code>LIKE</code> queries). </p> <p>We quickly learned this was false. </p> <p>If a user searches for \"How do computers talk?\", a vector search brilliantly understands the semantics, maps it to concepts like networking and TCP/IP, and retrieves fantastic documents perfectly. However, if an engineer searches for the exact string \"RFC 9110 HTTP\", a pure vector search often fails miserably, prioritizing text about \"internet regulations\" instead of the exact technical document string.</p> <p>Hybrid Search solves this by running both algorithms simultaneously and blending the results.</p>","tags":["architecture","hybrid","bm25"]},{"location":"part-2-architecture/hybrid-search/#101-score-fusion-combining-results","title":"10.1 Score Fusion (Combining Results)","text":"<p>If BM25 Keyword Search gives a document a score of <code>15.4</code>, and Vector Search gives that same document a Cosine Distance score of <code>0.85</code> \u2014 how do you mathematically combine them to rank the final Top-10? You can't just add them, because they are on completely different scales.</p>","tags":["architecture","hybrid","bm25"]},{"location":"part-2-architecture/hybrid-search/#reciprocal-rank-fusion-rrf","title":"Reciprocal Rank Fusion (RRF)","text":"<p>RRF is the standard, brilliant trick to bypass the scale problem. It completely ignores the raw mathematical scores, and only looks at their rank positions. </p> <p>If Document A is the #1 result in Vector Search, but #15 in Keyword search, it gets points based on the fraction $1/\\text{rank}$.</p> $$ \\text{RRF}(d) = \\sum_{r \\in \\mathcal{R}} \\frac{1}{k + \\text{rank}_r(d)} $$ <p>Note: $k$ is usually set as an arbitrary smoothing constant like 60 to prevent hyper-penalizing rank 2 vs rank 1.</p> <p>Why RRF?</p> <p>RRF is \"parameter-free\". You don't have to fiddle with weights (e.g., \"Make vector search 80% important and keyword 20% important\"). It organically surfaces documents that perform moderately well in both search algorithms.</p>","tags":["architecture","hybrid","bm25"]},{"location":"part-2-architecture/hybrid-search/#cross-encoder-re-ranking","title":"Cross-Encoder Re-Ranking","text":"<p>For absolute state-of-the-art results, production pipelines extract the Top 100 merged results from RRF, and feed them into a heavy, neural Cross-Encoder model. A cross-encoder reads both the user's query and the document simultaneously in real-time to output an incredibly accurate relevance score. Because it's too slow to run on a billion documents, we only run it on the top 100 candidates surfaced by Hybrid Search.</p>","tags":["architecture","hybrid","bm25"]},{"location":"part-2-architecture/hybrid-search/#102-the-metadata-filtering-flow","title":"10.2 The Metadata Filtering Flow","text":"<p>Hybrid search doesn't just mean combining keywords with vectors. It also implies combining vectors with hard database filters (<code>WHERE category = 'finance' AND year = 2024</code>).</p> <p>Executing an approximate math search over a graph structure while simultaneously enforcing absolute boolean rules is one of the hardest challenges in vector database engineering.</p> <pre><code>flowchart TD\n    Q[\"User Query&lt;br/&gt;'AI Startups'\"] --&gt; Filter{\"WHERE sector='Tech'&lt;br/&gt;Selectivity Check\"}\n\n    Filter -- \"High Selectivity&lt;br/&gt;(&amp;lt; 1% of DB matches)\" --&gt; PreFilter[Pre-Filtering]\n    Filter -- \"Low Selectivity&lt;br/&gt;(&amp;gt; 80% of DB matches)\" --&gt; PostFilter[Post-Filtering]\n    Filter -- \"Medium/Unknown\" --&gt; InGraph[In-Graph Filtering]\n\n    subgraph PreFilterPath [\"Pre-Filter Strategy\"]\n        direction TB\n        P1[Strictly extract matching row IDs] --&gt; P2[\"Run Brute-Force Vector Math&lt;br/&gt;on small subset\"]\n    end\n\n    subgraph PostFilterPath [\"Post-Filter Strategy\"]\n        direction TB\n        PO1[Run HNSW Vector Search] --&gt; PO2[Fetch Top 10,000 hits]\n        PO2 --&gt; PO3[Discard those without 'Tech']\n    end\n\n    subgraph InGraphPath [\"In-Graph (Single-Pass) Strategy\"]\n        direction TB\n        IG1[Traverse HNSW Graph] --&gt; IG2[\"At each hop, skip nodes&lt;br/&gt;that lack 'Tech' metadata\"]\n    end\n\n    PreFilter --&gt; PreFilterPath\n    PostFilter --&gt; PostFilterPath\n    InGraph --&gt; InGraphPath\n\n    style Filter fill:#ffe0b2,stroke:#f57c00\n    style InGraphPath fill:#c8e6c9,stroke:#388e3c</code></pre>","tags":["architecture","hybrid","bm25"]},{"location":"part-2-architecture/hybrid-search/#1-pre-filtering-and-the-small-subset-problem","title":"1. Pre-Filtering and The Small Subset Problem","text":"<p>In Pre-Filtering, the database evaluates the hard <code>WHERE</code> clauses first to generate a \"allow list\" of valid IDs, and then limits the vector search to only consider those IDs.</p> <p>However, if your filter is extremely restrictive (e.g. <code>WHERE user_id = 'alice' AND status = 'active'</code>), it might eliminate 99.9% of the database. At this point, navigating the massive HNSW graph is mathematically useless. The database skips the graph entirely, does a traditional DB scalar lookup to grab Alice's active records, and calculates the vector distance via simple brute force.</p>","tags":["architecture","hybrid","bm25"]},{"location":"part-2-architecture/hybrid-search/#2-post-filtering-and-the-over-fetch-problem","title":"2. Post-Filtering and The Over-Fetch Problem","text":"<p>If your filter is extremely broad (e.g. <code>WHERE is_deleted = False</code>), the DB runs a lightning fast HNSW graph search first, grabbing the Top 100 items from the graph. It then looks at the metadata for those 100 items and simply throws out the 2 or 3 deleted results. </p> <p>The danger here is if you fetch 100 items, and all 100 happen to be deleted objects. You return 0 results to the user, even though valid matches existed deeper in the graph.</p>","tags":["architecture","hybrid","bm25"]},{"location":"part-2-architecture/hybrid-search/#3-in-graph-filtering-the-percolation-problem","title":"3. In-Graph Filtering: The Percolation Problem","text":"<p>The holy grail of hybrid search is In-Graph Filtering (also known as Custom or Single-Pass filtering). As the algorithm hops from neighbor to neighbor inside the HNSW graph, it dynamically checks the metadata of each node and simply ignores neighbors that violate the <code>WHERE</code> clause.</p> <p>However, this introduces the Percolation Problem.  HNSW graphs are built assuming all nodes are connected. If a user applies a rigid filter (e.g., <code>WHERE color = 'Blue'</code>), the search algorithm is suddenly \"blind\" to all red, green, and yellow nodes. If there are no immediate blue neighbors, the algorithm hits a dead end. The graph shatters into disconnected islands, and the search fails to find the true nearest neighbor because it physically cannot traverse the broken graph space.</p>","tags":["architecture","hybrid","bm25"]},{"location":"part-2-architecture/hybrid-search/#enterprise-solutions-to-percolation","title":"Enterprise Solutions to Percolation","text":"<p>To solve the Percolation Problem, modern vector databases have engineered highly specialized filtering engines:</p> <ul> <li>In-Place Filtering (Qdrant): During ingest, Qdrant analyzes the payload/metadata structure. If it detects distinct categories (like <code>color: Blue</code>), it preemptively builds additional graph links connecting Blue nodes directly to other Blue nodes, bypassing the Red nodes entirely. When a filtered query arrives, the graph remains perfectly connected regardless of the filter's strictness.</li> <li>Roaring Bitmaps (Weaviate / Milvus): Instead of relying purely on graph traversal, these databases build specialized inverted indexes running on Roaring Bitmaps (a heavily compressed binary array perfect for fast <code>AND/OR</code> intersections). The engine intersects the bitmaps to instantly find all valid <code>Blue</code> items in microseconds, and then orchestrates a custom HNSW search that is geometrically restricted only to the IDs present in that final bitmap.</li> </ul>","tags":["architecture","hybrid","bm25"]},{"location":"part-2-architecture/hybrid-search/#assignment-implement-hybrid-search-with-bitmap-filtering","title":"\ud83d\udee0 Assignment: Implement Hybrid Search with Bitmap Filtering","text":"<p>Now let's build the three filtering strategies described above in working C++. You will implement bitmap-based pre-filtering, post-filtering, and compare their accuracy at different filter selectivities.</p> <p>Your tasks: 1. Build a simple <code>BitmapIndex</code> for categorical metadata. 2. Implement <code>pre_filter_search()</code> \u2014 resolve bitmap first, brute-force on valid IDs. 3. Implement <code>post_filter_search()</code> \u2014 vector search first, discard non-matching. 4. Compare result quality at varying filter selectivities.</p> Exercise: Hybrid Search with Bitmap Filtering<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;algorithm&gt;\n#include &lt;random&gt;\n#include &lt;cassert&gt;\n#include &lt;unordered_map&gt;\n#include &lt;unordered_set&gt;\n#include &lt;string&gt;\n#include &lt;bitset&gt;\n#include &lt;cmath&gt;\n\nfloat l2_dist(const std::vector&lt;float&gt;&amp; a, const std::vector&lt;float&gt;&amp; b) {\n    float sum = 0;\n    for (size_t i = 0; i &lt; a.size(); ++i) {\n        float d = a[i] - b[i]; sum += d * d;\n    }\n    return sum;\n}\n\nstruct Result {\n    size_t id;\n    float distance;\n    bool operator&lt;(const Result&amp; o) const { return distance &lt; o.distance; }\n};\n\n// \u2500\u2500 Step 1: Bitmap Index for categorical metadata \u2500\u2500\u2500\u2500\n// Simulates a Roaring Bitmap. For each category value,\n// stores a set of vector IDs that have that value.\nclass BitmapIndex {\npublic:\n    void add(size_t id, const std::string&amp; category) {\n        index_[category].insert(id);\n    }\n\n    // Return all IDs matching a category (the \"bitmap\")\n    std::unordered_set&lt;size_t&gt; resolve(const std::string&amp; category) const {\n        auto it = index_.find(category);\n        if (it != index_.end()) return it-&gt;second;\n        return {};\n    }\n\n    size_t category_count() const { return index_.size(); }\n\nprivate:\n    std::unordered_map&lt;std::string, std::unordered_set&lt;size_t&gt;&gt; index_;\n};\n\n// \u2500\u2500 Step 2: Pre-Filter Search \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n// Resolve the bitmap FIRST, then brute-force ONLY on valid IDs.\n// Best for highly selective filters (&lt; 1% of DB matches).\nstd::vector&lt;Result&gt; pre_filter_search(\n    const std::vector&lt;std::vector&lt;float&gt;&gt;&amp; data,\n    const std::vector&lt;float&gt;&amp; query,\n    const BitmapIndex&amp; bitmap,\n    const std::string&amp; filter_value,\n    size_t k)\n{\n    auto valid_ids = bitmap.resolve(filter_value);\n    std::vector&lt;Result&gt; results;\n    for (size_t id : valid_ids) {\n        results.push_back({id, l2_dist(data[id], query)});\n    }\n    size_t n = std::min(k, results.size());\n    std::partial_sort(results.begin(), results.begin() + n, results.end());\n    results.resize(n);\n    return results;\n}\n\n// \u2500\u2500 Step 3: Post-Filter Search \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n// Run brute-force vector search FIRST, then discard non-matching.\n// Best for broad filters (&gt; 80% of DB matches).\nstd::vector&lt;Result&gt; post_filter_search(\n    const std::vector&lt;std::vector&lt;float&gt;&gt;&amp; data,\n    const std::vector&lt;float&gt;&amp; query,\n    const BitmapIndex&amp; bitmap,\n    const std::string&amp; filter_value,\n    size_t k,\n    size_t overfetch_factor = 10)\n{\n    // Overfetch: get more candidates than needed\n    size_t fetch_k = k * overfetch_factor;\n    std::vector&lt;Result&gt; all;\n    for (size_t i = 0; i &lt; data.size(); ++i) {\n        all.push_back({i, l2_dist(data[i], query)});\n    }\n    std::partial_sort(all.begin(), all.begin() + fetch_k, all.end());\n\n    // Post-filter: keep only matching IDs\n    auto valid_ids = bitmap.resolve(filter_value);\n    std::vector&lt;Result&gt; filtered;\n    for (size_t i = 0; i &lt; fetch_k &amp;&amp; filtered.size() &lt; k; ++i) {\n        if (valid_ids.count(all[i].id)) {\n            filtered.push_back(all[i]);\n        }\n    }\n    return filtered;\n}\n\n// \u2500\u2500 Ground Truth: exact filtered k-NN \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nstd::vector&lt;Result&gt; exact_filtered_knn(\n    const std::vector&lt;std::vector&lt;float&gt;&gt;&amp; data,\n    const std::vector&lt;float&gt;&amp; query,\n    const BitmapIndex&amp; bitmap,\n    const std::string&amp; filter_value,\n    size_t k)\n{\n    auto valid_ids = bitmap.resolve(filter_value);\n    std::vector&lt;Result&gt; results;\n    for (size_t id : valid_ids) {\n        results.push_back({id, l2_dist(data[id], query)});\n    }\n    size_t n = std::min(k, results.size());\n    std::partial_sort(results.begin(), results.begin() + n, results.end());\n    results.resize(n);\n    return results;\n}\n\nfloat compute_recall(const std::vector&lt;Result&gt;&amp; results,\n                     const std::vector&lt;Result&gt;&amp; truth, size_t k) {\n    size_t hits = 0;\n    for (size_t i = 0; i &lt; std::min(k, results.size()); ++i) {\n        for (size_t j = 0; j &lt; std::min(k, truth.size()); ++j) {\n            if (results[i].id == truth[j].id) { hits++; break; }\n        }\n    }\n    return static_cast&lt;float&gt;(hits) / k;\n}\n\nint main() {\n    const size_t N = 5000, DIM = 32, K = 5;\n    std::mt19937 rng(42);\n    std::uniform_real_distribution&lt;float&gt; fdist(-1.0f, 1.0f);\n\n    // Generate dataset with categorical metadata\n    std::vector&lt;std::vector&lt;float&gt;&gt; data(N);\n    std::vector&lt;std::string&gt; categories = {\"Red\", \"Blue\", \"Green\", \"Yellow\"};\n    BitmapIndex bitmap;\n\n    for (size_t i = 0; i &lt; N; ++i) {\n        data[i].resize(DIM);\n        for (auto&amp; x : data[i]) x = fdist(rng);\n        bitmap.add(i, categories[i % categories.size()]);\n    }\n\n    std::vector&lt;float&gt; query(DIM);\n    for (auto&amp; x : query) x = fdist(rng);\n\n    std::string filter = \"Blue\";  // 25% selectivity\n\n    // Run all strategies\n    auto truth   = exact_filtered_knn(data, query, bitmap, filter, K);\n    auto pre_res = pre_filter_search(data, query, bitmap, filter, K);\n    auto post_res = post_filter_search(data, query, bitmap, filter, K);\n\n    float pre_recall  = compute_recall(pre_res, truth, K);\n    float post_recall = compute_recall(post_res, truth, K);\n\n    std::cout &lt;&lt; \"=== Hybrid Search Bitmap Filtering ===\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Dataset: \" &lt;&lt; N &lt;&lt; \" vectors, Filter: color='\"\n              &lt;&lt; filter &lt;&lt; \"' (25% selectivity)\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Pre-Filter  Recall@\" &lt;&lt; K &lt;&lt; \": \"\n              &lt;&lt; pre_recall * 100 &lt;&lt; \"%\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Post-Filter Recall@\" &lt;&lt; K &lt;&lt; \": \"\n              &lt;&lt; post_recall * 100 &lt;&lt; \"%\" &lt;&lt; std::endl;\n\n    assert(pre_recall == 1.0f &amp;&amp; \"Pre-filter should be exact for brute-force\");\n    assert(post_recall &gt;= 0.8f &amp;&amp; \"Post-filter should have high recall\");\n    std::cout &lt;&lt; \"\u2705 All assertions passed!\" &lt;&lt; std::endl;\n    return 0;\n}\n</code></pre> <p>Compile and run: </p><pre><code>g++ -std=c++17 -O2 -o hybrid_bitmap hybrid_bitmap.cpp\n./hybrid_bitmap\n</code></pre><p></p>","tags":["architecture","hybrid","bm25"]},{"location":"part-2-architecture/hybrid-search/#references","title":"References","text":"<ol> <li>Cormack, G. V., Clarke, C. L., &amp; Buettcher, S. (2009). Reciprocal Rank Fusion Outperforms Condorcet and Individual Rank Learning Methods. SIGIR.</li> <li>Nogueira, R., &amp; Cho, K. (2020). Passage Re-ranking with BERT. arXiv.</li> </ol>","tags":["architecture","hybrid","bm25"]},{"location":"part-2-architecture/observability-operations/","title":"Chapter 12 \u2014 Observability & Operations","text":"","tags":["architecture","observability","operations"]},{"location":"part-2-architecture/observability-operations/#12-observability-operations","title":"12. Observability &amp; Operations","text":"<p>Running a vector database in production requires monitoring, alerting, and capacity planning tools tailored to ANN workloads.</p>","tags":["architecture","observability","operations"]},{"location":"part-2-architecture/observability-operations/#121-key-metrics","title":"12.1 Key Metrics","text":"","tags":["architecture","observability","operations"]},{"location":"part-2-architecture/observability-operations/#the-four-golden-signals-for-vector-search","title":"The Four Golden Signals for Vector Search","text":"Signal Metric Alert Threshold Latency p50, p95, p99 query latency p99 &gt; 100ms Traffic Queries/sec, inserts/sec Spike &gt; 3\u00d7 baseline Errors Failed queries, timeouts Error rate &gt; 0.1% Saturation Memory usage, CPU, disk I/O Memory &gt; 85%","tags":["architecture","observability","operations"]},{"location":"part-2-architecture/observability-operations/#vector-specific-metrics","title":"Vector-Specific Metrics","text":"Metric Description Why It Matters Recall@k Fraction of true k-NN found Quality regression detection Distance ratio $d_{\\text{approx}} / d_{\\text{exact}}$ ANN quality per-query Candidates scanned Vectors evaluated per query Early termination indicator Segment count Number of active segments Compaction needed? Tombstone ratio Deleted / total vectors Index degradation Write amplification Bytes written / bytes inserted Storage efficiency","tags":["architecture","observability","operations"]},{"location":"part-2-architecture/observability-operations/#122-recall-monitoring","title":"12.2 Recall Monitoring","text":"","tags":["architecture","observability","operations"]},{"location":"part-2-architecture/observability-operations/#synthetic-ground-truth-testing","title":"Synthetic Ground-Truth Testing","text":"<p>Periodically run exact brute-force search on a sample and compare with ANN results:</p> $$ \\text{Online recall} = \\frac{1}{|Q|} \\sum_{q \\in Q} \\frac{|\\text{ANN}(q, k) \\cap \\text{BF}(q, k)|}{k} $$ <p>Recall can silently degrade</p> <p>As data distribution shifts (new embedding model, different content), index quality may drop without any error signals. Automated recall monitoring is essential.</p>","tags":["architecture","observability","operations"]},{"location":"part-2-architecture/observability-operations/#123-capacity-planning","title":"12.3 Capacity Planning","text":"","tags":["architecture","observability","operations"]},{"location":"part-2-architecture/observability-operations/#memory-estimation","title":"Memory Estimation","text":"$$ \\text{Required RAM} = n \\cdot \\left( d \\cdot b + M_{\\text{avg}} \\cdot 8 + \\text{meta}_{\\text{avg}} \\right) \\cdot (1 + \\text{overhead}) $$ <p>where: - $n$ = number of vectors - $b$ = bytes per dimension (4 for FP32, 1 for INT8) - $M_{\\text{avg}}$ = average edges per node - $\\text{overhead}$ \u2248 10\u201320%</p>","tags":["architecture","observability","operations"]},{"location":"part-2-architecture/observability-operations/#qps-estimation","title":"QPS Estimation","text":"$$ \\text{QPS}_{\\text{max}} = \\frac{\\text{threads} \\times \\text{IPC}}{\\text{dist\\_computations\\_per\\_query} \\times \\text{cycles\\_per\\_dist}} $$ <p>Rule of thumb: 1 core \u2248 500\u20132000 QPS for 1M vectors at 768 dimensions (HNSW, ef_search=50).</p>","tags":["architecture","observability","operations"]},{"location":"part-2-architecture/observability-operations/#124-auto-tuning","title":"12.4 Auto-Tuning","text":"","tags":["architecture","observability","operations"]},{"location":"part-2-architecture/observability-operations/#adaptive-ef_search","title":"Adaptive ef_search","text":"<p>Monitor recall and latency, automatically adjust $\\texttt{ef\\_search}$:</p> <pre><code>if recall &lt; target:\n    ef_search += 10\nelif p99_latency &gt; budget:\n    ef_search -= 5\n</code></pre>","tags":["architecture","observability","operations"]},{"location":"part-2-architecture/observability-operations/#adaptive-nprobe-ivf","title":"Adaptive nprobe (IVF)","text":"<p>Similar for IVF indexes: increase $n_{\\text{probe}}$ when recall drops, decrease when latency is too high.</p>","tags":["architecture","observability","operations"]},{"location":"part-2-architecture/observability-operations/#125-production-operations","title":"12.5 Production Operations","text":"","tags":["architecture","observability","operations"]},{"location":"part-2-architecture/observability-operations/#common-runbook-items","title":"Common Runbook Items","text":"Scenario Action p99 latency spike Check segment count, compaction status, memory pressure Recall dropped Check data distribution shift, run synthetic recall test Memory growing Check tombstone ratio, trigger compaction Cold start slow Pre-warm critical segments, increase boot parallelism Disk space full Compact, archive old segments, promote SQ8","tags":["architecture","observability","operations"]},{"location":"part-2-architecture/observability-operations/#references","title":"References","text":"<ol> <li>Google SRE Book. Monitoring Distributed Systems. https://sre.google/sre-book/monitoring-distributed-systems/</li> </ol>","tags":["architecture","observability","operations"]},{"location":"part-2-architecture/realtime-updates/","title":"Chapter 9 \u2014 Real-Time Update Handling","text":"","tags":["architecture","updates","deletion"]},{"location":"part-2-architecture/realtime-updates/#9-real-time-update-handling","title":"9. Real-Time Update Handling","text":"<p>In traditional relational databases (like MySQL), updating a record is mathematically trivial. The engine navigates a B-Tree, finds the specific hard-drive sector where the row lives, and overwrites the text.</p> <p>In an Approximate Nearest Neighbor vector database, data structures are deeply interconnected geometric graphs or mathematical clusters. If you physically delete \"Node X\" from an HNSW graph, you might unintentionally sever the only bridging connection between the left side of the graph and the right side of the graph. If that happens, queries will \"get stuck\" and completely fail to find results on the other side.</p> <p>Because of this fragility, vector databases handle modifications fundamentally differently than relational databases do.</p>","tags":["architecture","updates","deletion"]},{"location":"part-2-architecture/realtime-updates/#91-the-immutable-segment-paradigm","title":"9.1 The \"Immutable\" Segment Paradigm","text":"<p>As discussed in the Storage Engines chapter, to achieve high performance, modern databases write data tightly packed into Segments. Once a segment is \"Sealed\" (e.g., it reaches 100,000 vectors), no process is ever allowed to physically alter the bytes inside that segment file again. It is strictly immutable.</p> <p>So, how do you handle <code>DELETE</code> or <code>UPDATE</code> API calls from a user if the storage files are immutable?</p>","tags":["architecture","updates","deletion"]},{"location":"part-2-architecture/realtime-updates/#updates-as-delete-insert","title":"Updates as \"Delete + Insert\"","text":"<p>An <code>UPDATE</code> to an embedding is almost never an \"update-in-place\". If the user updates an embedding, the vector database translates this completely transparently into two independent actions: 1. Issue a <code>DELETE</code> command for the old vector ID. 2. Issue an <code>INSERT</code> command for the new vector payload (which goes cleanly into the fast, fresh in-memory buffer).</p> <p>The challenge, therefore, strictly boils down to how to safely execute deletions without breaking the HNSW graph search paths.</p>","tags":["architecture","updates","deletion"]},{"location":"part-2-architecture/realtime-updates/#92-soft-deletions-and-tombstones","title":"9.2 Soft Deletions and Tombstones","text":"<p>Because we cannot physically rip nodes out of the immutable segment file, we use a concept known as Soft Deletion via Tombstoning.</p> <p>A tombstone is simply a mathematical marker. The database maintains a fast, in-memory <code>Bitset</code> (an array of billions of <code>1</code>s and <code>0</code>s), tracking the status of every vector ID. </p>","tags":["architecture","updates","deletion"]},{"location":"part-2-architecture/realtime-updates/#the-deletion-process","title":"The Deletion Process","text":"<p>When a user deletes ID #4002: 1. The database flips the bit for index 4002 in the deletion bitset to <code>1</code>. 2. The vector remains physically inside the HNSW segment on the hard drive. All graph mathematical connections to and from #4002 remain perfectly intact. </p>","tags":["architecture","updates","deletion"]},{"location":"part-2-architecture/realtime-updates/#the-search-process-filtering-tombstones","title":"The Search Process (Filtering Tombstones)","text":"<p>During an incoming query, the HNSW search algorithm navigates the graph exactly as it normally would. It happily hops onto Node #4002 to travel across the graph. </p> <p>The only difference occurs at the very end of the search. Once the algorithm collects its \"Top 10 Closest Neighbors\", it rapidly checks those 10 final IDs against the in-memory Tombstone bitset. If it sees that ID #4002 is flagged as deleted, it simply throws it out of the final results array and pulls in the #11 closest result instead.</p> <p>It is mathematically elegant, doesn't break graph connectivity, and requires zero complex disk I/O.</p>","tags":["architecture","updates","deletion"]},{"location":"part-2-architecture/realtime-updates/#93-hard-deletion-and-garbage-collection","title":"9.3 Hard Deletion and Garbage Collection","text":"<p>Over time, if an application deletes 40% of its vectors, the segments become heavily populated with \"ghost nodes\". The search algorithm wastes precious millisecond CPU cycles navigating through nodes that are ultimately tossed out. This degrades query performance and wastes expensive RAM.</p>","tags":["architecture","updates","deletion"]},{"location":"part-2-architecture/realtime-updates/#compaction-graph-repair","title":"Compaction (Graph Repair)","text":"<p>Physical deletion (Hard Deletion) only happens during the background Compaction cycle. </p> <pre><code>flowchart LR\n    subgraph S1 [Segment 1]\n        A((Vector A)) --- B((\"Vector B (Deleted)\"))\n        B --- C((Vector C))\n        D((\"Vector D (Deleted)\"))\n    end\n\n    subgraph S2 [Segment 2]\n        E((Vector E)) --- F((Vector F))\n    end\n\n    Compaction[\"Background Compaction Thread&lt;br/&gt;Takes Lock\"]\n\n    S1 -.-&gt; Compaction\n    S2 -.-&gt; Compaction\n\n    subgraph S3 [New Merged Segment 3]\n        A2((Vector A)) --- C2((Vector C))\n        C2 --- E2((Vector E))\n        E2 --- F2((Vector F))\n    end\n\n    Compaction ==&gt;|\"Rebuild New Graph&lt;br/&gt;Excluding Tombstones\"| S3\n\n    style B fill:#ffebee,stroke:#f44336\n    style D fill:#ffebee,stroke:#f44336\n    style S3 fill:#e8f5e9,stroke:#4caf50</code></pre> <ol> <li>A background thread identifies that Segment 1 consists of 40% tombstones.</li> <li>It allocates a brand new memory space.</li> <li>It takes all the valid vectors from Segment 1 (and potentially a few other segments).</li> <li>It rebuilds a brand new HNSW graph structure from scratch using only the valid vectors.</li> <li>It writes this new pristine graph out to SSD as \"Segment 3\".</li> <li>It then violently deletes the old Segment 1 and Segment 2 files from the OS entirely.</li> </ol> <p>This ensures the database remains fast and self-maintaining over months of uptime, without impacting the real-time queries.</p>","tags":["architecture","updates","deletion"]},{"location":"part-2-architecture/realtime-updates/#assignment-implement-tombstone-deletions","title":"Assignment: Implement Tombstone Deletions","text":"<p>In this assignment, you will modify the search algorithm from the Chapter 0 Quickstart to smoothly handle Soft Deletions without physically modifying the storage array.</p>","tags":["architecture","updates","deletion"]},{"location":"part-2-architecture/realtime-updates/#goal","title":"Goal","text":"<p>Implement a highly efficient <code>std::vector&lt;bool&gt;</code> bitset to track deletions. Modify the <code>search</code> function to skip any vectors that have been marked as deleted (a Tombstone). </p> Exercise: Implement Tombstones<pre><code>#include &lt;vector&gt;\n#include &lt;iostream&gt;\n\nclass TombstoneVectorDB {\nprivate:\n    std::vector&lt;Record&gt; storage; // Raw storage\n\n    // The Bitset: true implies the record at that index is DELETED.\n    std::vector&lt;bool&gt; delete_flags; \n\npublic:\n    void delete_vector(size_t index) {\n        if (index &gt;= delete_flags.size()) return;\n\n        // EXERCISE: Mark the specific index as deleted\n        delete_flags[index] = true;\n    }\n\n    std::vector&lt;SearchResult&gt; search(const std::vector&lt;float&gt;&amp; query, int k) {\n        std::vector&lt;SearchResult&gt; results;\n\n        for (size_t i = 0; i &lt; storage.size(); ++i) {\n            // EXERCISE 1: Check the `delete_flags` bitset.\n            // If the flag is set to true, `continue` the loop and \n            // completely skip math execution for this ghost node.\n\n            /* Write skip logic here */\n\n            // If not deleted, compute distance\n            float dist = calculate_l2(query, storage[i].vector);\n            results.push_back({i, dist});\n        }\n\n        std::sort(results.begin(), results.end());\n        if (results.size() &gt; k) results.resize(k);\n        return results;\n    }\n};\n</code></pre>","tags":["architecture","updates","deletion"]},{"location":"part-2-architecture/realtime-updates/#references","title":"References","text":"<ol> <li>Wang, J., et al. (2021). Milvus: A Purpose-Built Vector Data Management System. SIGMOD.</li> <li>Qdrant Documentation. Storage and Data Management.</li> </ol>","tags":["architecture","updates","deletion"]},{"location":"part-2-architecture/storage-engines/","title":"Chapter 7 \u2014 Storage Engines","text":"","tags":["architecture","storage","IO"]},{"location":"part-2-architecture/storage-engines/#7-storage-engines","title":"7. Storage Engines","text":"<p>In a vector database, the HNSW graph acts as the brain (the index routing map), but the Storage Engine is the muscle. It manages how the actual multi-gigabyte files of floats and metadata are written to and fetched from physical NVMe Solid State Drives (SSDs). </p> <p>Operating systems are incredibly complex when it comes to disk I/O. If a storage engine performs 100,000 tiny microscopic reads from random sectors of a hard drive every second, the OS kernel will lock up. This chapter explains how vector databases design their internal file structures to bypass these bottlenecks.</p>","tags":["architecture","storage","IO"]},{"location":"part-2-architecture/storage-engines/#71-memory-mapping-mmap","title":"7.1 Memory-Mapping (mmap)","text":"<p>The vast majority of modern vector databases (including Qdrant and early Milvus) heavily utilize <code>mmap</code>, a POSIX system call that maps the bytes of a file sitting on an SSD directly into the memory space of the application.</p>","tags":["architecture","storage","IO"]},{"location":"part-2-architecture/storage-engines/#how-it-works","title":"How it works","text":"<p>Normally, if a database wants to read vector ID #500 from a file, it asks the OS to read <code>file.bin</code>, the OS pulls the data from disk into Kernel RAM, and then copies it into the Database RAM.  With <code>mmap</code>, the database completely bypasses manual reads. It just treats the <code>file.bin</code> on the hard drive as if it were a massive C++ array in RAM. When the software asks for <code>array[500]</code>, the OS silently intercepts the request, runs to the hard drive, pulls the block of data into a cache (Page Cache), and serves it.</p> <p>Why <code>mmap</code> is dominant in Vector DBs: 1. Zero manual memory management: The OS decides what parts of the HNSW graph belong in fast RAM and what parts can be evicted to slow SSD based on exactly what vectors users have been querying recently. 2. Crash resilience: If the database process crashes, the data isn't corrupted; the OS just stops mapping it.</p>","tags":["architecture","storage","IO"]},{"location":"part-2-architecture/storage-engines/#the-limits-of-mmap","title":"The Limits of mmap","text":"<p><code>mmap</code> is highly optimized for read-heavy workloads. However, if the database is constantly being written to (millions of inserts a second), <code>mmap</code> suffers severe performance degradation. For heavy ingest, we need specialized write architectures.</p>","tags":["architecture","storage","IO"]},{"location":"part-2-architecture/storage-engines/#72-log-structured-merge-lsm-trees","title":"7.2 Log-Structured Merge (LSM) Trees","text":"<p>Relational databases traditionally use B-Trees (where you overwrite data exactly where it lives on disk). Because SSDs physically degrade when you overwrite the exact same sectors repeatedly, and random writes are slow, modern NoSQL and Vector databases (like Milvus and Pinecone) adapt LSM-Trees (Log-Structured Merge-Trees) for their scalar data and segment logistics.</p>","tags":["architecture","storage","IO"]},{"location":"part-2-architecture/storage-engines/#the-write-path-append-only","title":"The Write Path (Append-Only)","text":"<p>In an LSM architecture, data is never updated in place. When a new vector is inserted, it is simply appended to the very end of an active file. Appending to the end of a file is the absolute fastest operation a hard drive can perform. </p> <pre><code>flowchart TD\n    subgraph RAM [Fast Memory]\n        MemTable[\"MemTable&lt;br/&gt;Active In-Memory Segment\"]\n    end\n\n    subgraph SSD [NVMe Disk Storage]\n        direction TB\n        L0[\"Level 0 Files&lt;br/&gt;Small, Fresh Flushes\"]\n        L1[\"Level 1 Files&lt;br/&gt;Medium Merged Segments\"]\n        L2[\"Level 2 Files&lt;br/&gt;Massive Historical Segments\"]\n    end\n\n    Client[Client Insert] --&gt; |Append to| MemTable\n    MemTable -. \"When Full (e.g., 64MB)\" .-&gt; |Flush to Disk| L0\n    L0 -. \"Background Compaction thread\" .-&gt; L1\n    L1 -. \"Background Compaction thread\" .-&gt; L2\n\n    style RAM fill:#e8f5e9,stroke:#4caf50\n    style SSD fill:#eceff1,stroke:#607d8b</code></pre>","tags":["architecture","storage","IO"]},{"location":"part-2-architecture/storage-engines/#compaction-the-necessary-evil","title":"Compaction: The Necessary Evil","text":"<p>If you just kept appending vectors forever, you'd end up with 100,000 tiny files. Your read latency would skyrocket because you'd have to search every single file. To fix this, a background thread constantly runs Compaction. It grabs ten small 60MB segments (Level 0 files), sorts them, merges them together, mathematically rebuilds a new HNSW graph for the combined dataset, and saves it as a brand new 600MB Level 1 segment. This uses heavy CPU, but keeps the disk organized for fast reads.</p>","tags":["architecture","storage","IO"]},{"location":"part-2-architecture/storage-engines/#73-columnar-layouts-for-vector-math","title":"7.3 Columnar Layouts for Vector Math","text":"<p>If you read an entire record (Vector + Metadata) from disk sequentially:</p> <p></p><pre><code>{\n  \"id\": 1, \n  \"vector\": [0.1, 0.4, ...], \n  \"author\": \"Alice\", \n  \"date\": \"2024-01-01\"\n}\n</code></pre> This is a Row-based storage format. <p></p> <p>If your query engine needs to execute math on the vectors, it has to load the <code>author</code> and <code>date</code> strings into the CPU cache alongside the floats. This pollutes the microscopic incredibly fast L1 CPU caches with garbage text data that the math engine doesn't need, slowing down AVX operations.</p> <p>Databases like LanceDB use Columnar Storage. They physically store all vectors clustered together in one file block, all authors in another block, and all dates in another. During a pure math search, the CPU simply blasts through the tightly-packed block of contiguous vectors with zero cache pollution.</p>","tags":["architecture","storage","IO"]},{"location":"part-2-architecture/storage-engines/#assignment-build-a-segmented-file-store-layer","title":"Assignment: Build a Segmented File Store Layer","text":"<p>In Chapter 6, you built a WAL to protect an isolated, in-memory hash map. In reality, memory maps cannot grow forever. In this assignment, you will implement an LSM-style <code>flush</code> mechanism that \"Seals\" a segment and writes it to an immutable binary file.</p>","tags":["architecture","storage","IO"]},{"location":"part-2-architecture/storage-engines/#goal","title":"Goal","text":"<p>Modify your <code>MiniVectorDB</code> to flush vectors from active memory into a <code>.segment</code> binary file when the RAM reaches a certain target threshold.</p> Exercise: Implement Segment Flushing<pre><code>#include &lt;fstream&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nconstexpr size_t THRESHOLD = 1000; // Vectors per segment\n\nclass SegmentManager {\nprivate:\n    std::unordered_map&lt;size_t, Record&gt; active_memory;\n    int segment_counter = 0;\n\npublic:\n    void insert(size_t id, const Record&amp; r) {\n        active_memory[id] = r;\n\n        // 1. Check if we breached the RAM threshold\n        if (active_memory.size() &gt;= THRESHOLD) {\n            flush_to_disk();\n        }\n    }\n\n    // YOUR EXERCISE: Implement this function!\n    void flush_to_disk() {\n        std::string filename = \"segment_\" + std::to_string(segment_counter++) + \".bin\";\n        std::ofstream outfile(filename, std::ios::binary);\n\n        // 2. Iterate through `active_memory`\n        // 3. Serialize the `id` and `vector` bytes into the binary file\n        // 4. Clear `active_memory` so RAM usage drops back to 0.\n\n        /* Write your serialization code here */\n\n        outfile.close();\n        std::cout &lt;&lt; \"Sealed Segment: \" &lt;&lt; filename &lt;&lt; std::endl;\n    }\n\n    // Further thinking: Now that data is on disk, how does your `search()`\n    // function need to change? (Hint: mmap or file streams).\n};\n</code></pre>","tags":["architecture","storage","IO"]},{"location":"part-2-architecture/storage-engines/#references","title":"References","text":"<ol> <li>O'Neil, P., et al. (1996). The Log-Structured Merge-Tree (LSM-Tree). Acta Informatica.</li> <li>LanceDB. Lance Columnar Format Overview.</li> </ol>","tags":["architecture","storage","IO"]},{"location":"part-3-implementation/","title":"Part III \u2014 Implementation Deep-Dive","text":""},{"location":"part-3-implementation/#part-iii-implementation-deep-dive","title":"Part III \u2014 Implementation Deep-Dive","text":"<p>Roll up your sleeves. This section provides hands-on implementation walkthroughs of real vector database components, from a complete HNSW store in Rust to GPU-accelerated quantized search.</p>"},{"location":"part-3-implementation/#chapters","title":"Chapters","text":"# Chapter Key Topics 13 HNSW Store in Rust Memory-mapped adjacency lists, unsafe optimizations 14 PQ-IVF on GPUs CUDA kernels, fused distance computation 15 Transactional Schemes MVCC adaptations, compaction scheduling 16 Elastic Scaling Split/merge rebalancing, hotspot mitigation 17 Benchmark Harness ANN-Benchmarks, synthetic data, latency suites <p>Prerequisites</p> <p>Chapters 13\u201314 assume familiarity with Rust and CUDA respectively. Chapter 15 assumes database transaction fundamentals.</p>"},{"location":"part-3-implementation/benchmark-harness/","title":"Chapter 17 \u2014 Benchmark Harness","text":"","tags":["implementation","benchmarks","evaluation"]},{"location":"part-3-implementation/benchmark-harness/#17-benchmark-harness","title":"17. Benchmark Harness","text":"<p>How do you know which algorithm is best for your data? This chapter covers benchmark methodology, standard datasets, and how to build a fair evaluation harness.</p>","tags":["implementation","benchmarks","evaluation"]},{"location":"part-3-implementation/benchmark-harness/#171-the-ann-benchmarks-framework","title":"17.1 The ANN-Benchmarks Framework","text":"<p>ANN-Benchmarks is the standard evaluation framework. It measures the recall vs. QPS Pareto frontier.</p>","tags":["implementation","benchmarks","evaluation"]},{"location":"part-3-implementation/benchmark-harness/#key-metrics","title":"Key Metrics","text":"Metric Definition Interpretation Recall@k $\\frac{\\|\\text{ANN}(q,k) \\cap \\text{BF}(q,k)\\|}{k}$ Search quality QPS Queries per second Throughput Build time Wall-clock index construction One-time cost Index size Memory footprint (bytes) Resource cost p99 latency 99<sup>th</sup> percentile query time Tail performance","tags":["implementation","benchmarks","evaluation"]},{"location":"part-3-implementation/benchmark-harness/#the-pareto-frontier","title":"The Pareto Frontier","text":"<p>The most informative view is Recall vs. QPS at fixed $k$:</p> <pre><code>flowchart LR\n    A[\"Low ef \u2192 High QPS, Low Recall\"] --&gt; B[\"High ef \u2192 Low QPS, High Recall\"]\n    style A fill:#ff6b6b\n    style B fill:#51cf66</code></pre> <p>An algorithm dominates another if it achieves higher recall at the same QPS (or higher QPS at the same recall).</p>","tags":["implementation","benchmarks","evaluation"]},{"location":"part-3-implementation/benchmark-harness/#172-standard-datasets","title":"17.2 Standard Datasets","text":"Dataset Vectors Dimensions Metric Size Use Case SIFT1M 1M 128 L2 512 MB Quick smoke test SIFT1B 1B 128 L2 512 GB Billion-scale GloVe-200 1.2M 200 Cosine 960 MB NLP embeddings MNIST 60K 784 L2 188 MB High-dimensional Deep1B 1B 96 L2 384 GB CNN features LAION-5B 5B 768 Cosine 15 TB CLIP embeddings","tags":["implementation","benchmarks","evaluation"]},{"location":"part-3-implementation/benchmark-harness/#sift1m-format","title":"SIFT1M Format","text":"<pre><code># Binary format: 4-byte int (dim), then dim \u00d7 4-byte floats per vector\n# File: sift_base.fvecs (128-dim \u00d7 1M = 512 MB)\n</code></pre>","tags":["implementation","benchmarks","evaluation"]},{"location":"part-3-implementation/benchmark-harness/#173-fair-evaluation-methodology","title":"17.3 Fair Evaluation Methodology","text":"","tags":["implementation","benchmarks","evaluation"]},{"location":"part-3-implementation/benchmark-harness/#common-pitfalls","title":"Common Pitfalls","text":"<p>Unfair comparisons to avoid</p> <ol> <li>Tuning one algorithm but not the other \u2014 give each the same parameter search budget</li> <li>Including build time in QPS \u2014 deceptive for slow-build, fast-query algorithms</li> <li>Measuring on the training set \u2014 always use separate query vectors</li> <li>Ignoring memory \u2014 an algorithm using 100\u00d7 more RAM isn't a fair comparison</li> <li>Single-threaded vs. multi-threaded \u2014 report both, or fix thread count</li> </ol>","tags":["implementation","benchmarks","evaluation"]},{"location":"part-3-implementation/benchmark-harness/#recommended-protocol","title":"Recommended Protocol","text":"<ol> <li>Fix hardware: Same machine, same CPU, same memory</li> <li>Fix dataset: Standard benchmark set (SIFT1M, GloVe)</li> <li>Parameter sweep: For each algorithm, try 10+ configurations</li> <li>Report Pareto: Plot recall vs. QPS across all configurations</li> <li>Report memory: Alongside QPS, report peak RSS</li> <li>Multiple runs: Average over 3+ runs to reduce variance</li> </ol>","tags":["implementation","benchmarks","evaluation"]},{"location":"part-3-implementation/benchmark-harness/#174-building-your-own-harness","title":"17.4 Building Your Own Harness","text":"","tags":["implementation","benchmarks","evaluation"]},{"location":"part-3-implementation/benchmark-harness/#c-benchmark-structure","title":"C++ Benchmark Structure","text":"<pre><code>#include &lt;chrono&gt;\n#include &lt;vector&gt;\n\nstruct BenchmarkResult {\n    float recall;\n    float qps;\n    size_t memory_bytes;\n    float build_time_sec;\n    float p99_latency_ms;\n};\n\nBenchmarkResult run_benchmark(\n    /* index */,\n    const std::vector&lt;std::vector&lt;float&gt;&gt;&amp; queries,\n    const std::vector&lt;std::vector&lt;size_t&gt;&gt;&amp; ground_truth,\n    size_t k\n) {\n    BenchmarkResult result;\n\n    // Measure QPS\n    auto start = std::chrono::high_resolution_clock::now();\n    size_t total_queries = queries.size();\n    size_t correct = 0;\n\n    for (size_t i = 0; i &lt; total_queries; ++i) {\n        auto results = /* index.search(queries[i], k) */;\n\n        // Compute recall for this query\n        std::set&lt;size_t&gt; gt_set(ground_truth[i].begin(),\n                                ground_truth[i].begin() + k);\n        for (auto&amp; r : results) {\n            if (gt_set.count(r.id)) correct++;\n        }\n    }\n\n    auto end = std::chrono::high_resolution_clock::now();\n    double elapsed = std::chrono::duration&lt;double&gt;(end - start).count();\n\n    result.qps = total_queries / elapsed;\n    result.recall = static_cast&lt;float&gt;(correct) / (total_queries * k);\n    return result;\n}\n</code></pre>","tags":["implementation","benchmarks","evaluation"]},{"location":"part-3-implementation/benchmark-harness/#what-to-vary","title":"What to Vary","text":"Parameter HNSW IVF-PQ LSH Build-time M, ef_construction nlist, PQ M num_tables, num_hashes Query-time ef_search nprobe \u2014","tags":["implementation","benchmarks","evaluation"]},{"location":"part-3-implementation/benchmark-harness/#175-industry-benchmarks-and-leaderboards","title":"17.5 Industry Benchmarks and Leaderboards","text":"Benchmark Focus Notable ANN-Benchmarks Algorithm comparison Standard reference Big-ANN-Benchmarks Billion-scale NeurIPS competition VectorDBBench Full database comparison Includes filtering","tags":["implementation","benchmarks","evaluation"]},{"location":"part-3-implementation/benchmark-harness/#assignment-build-a-recall-vs-qps-benchmark-harness","title":"\ud83d\udee0 Assignment: Build a Recall-vs-QPS Benchmark Harness","text":"<p>Now let's turn the pseudo-code from Section 17.4 into a fully working benchmark that uses the HNSW index from the book's <code>src/cpp/</code> directory. You will sweep the <code>ef_search</code> parameter and print a table showing how recall and throughput trade off.</p> <p>Your tasks: 1. Implement <code>brute_force_ground_truth()</code> to compute exact k-NN. 2. Implement <code>measure_recall()</code> comparing HNSW results to ground truth. 3. Implement <code>measure_qps()</code> timing batched queries. 4. Sweep <code>ef_search</code> and print a Recall vs QPS table.</p> Exercise: Recall-vs-QPS Benchmark Harness<pre><code>// Compile from src/cpp/:\n//   g++ -std=c++17 -O2 -o benchmark benchmark_harness.cpp\n\n#include \"hnsw.hpp\"   // The HNSW index from the book\n\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;algorithm&gt;\n#include &lt;random&gt;\n#include &lt;chrono&gt;\n#include &lt;set&gt;\n#include &lt;iomanip&gt;\n#include &lt;cassert&gt;\n\n// \u2500\u2500 Step 1: Brute-force ground truth \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nfloat l2_dist(const std::vector&lt;float&gt;&amp; a, const std::vector&lt;float&gt;&amp; b) {\n    float sum = 0;\n    for (size_t i = 0; i &lt; a.size(); ++i) {\n        float d = a[i] - b[i]; sum += d * d;\n    }\n    return sum;\n}\n\nstd::vector&lt;size_t&gt; brute_force_knn(\n    const std::vector&lt;std::vector&lt;float&gt;&gt;&amp; dataset,\n    const std::vector&lt;float&gt;&amp; query, size_t k)\n{\n    std::vector&lt;std::pair&lt;float, size_t&gt;&gt; dists;\n    for (size_t i = 0; i &lt; dataset.size(); ++i)\n        dists.push_back({l2_dist(dataset[i], query), i});\n    std::partial_sort(dists.begin(), dists.begin() + k, dists.end());\n    std::vector&lt;size_t&gt; result(k);\n    for (size_t i = 0; i &lt; k; ++i) result[i] = dists[i].second;\n    return result;\n}\n\n// \u2500\u2500 Step 2: Measure recall@K \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nfloat measure_recall(\n    HNSWIndex&amp; index,\n    const std::vector&lt;std::vector&lt;float&gt;&gt;&amp; queries,\n    const std::vector&lt;std::vector&lt;size_t&gt;&gt;&amp; ground_truth,\n    size_t k)\n{\n    size_t total_hits = 0;\n    for (size_t i = 0; i &lt; queries.size(); ++i) {\n        auto results = index.search(queries[i], k);\n        std::set&lt;size_t&gt; gt_set(ground_truth[i].begin(),\n                                ground_truth[i].end());\n        for (const auto&amp; r : results) {\n            if (gt_set.count(r.id)) total_hits++;\n        }\n    }\n    return static_cast&lt;float&gt;(total_hits) / (queries.size() * k);\n}\n\n// \u2500\u2500 Step 3: Measure QPS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nfloat measure_qps(\n    HNSWIndex&amp; index,\n    const std::vector&lt;std::vector&lt;float&gt;&gt;&amp; queries,\n    size_t k)\n{\n    auto start = std::chrono::high_resolution_clock::now();\n    for (const auto&amp; q : queries) {\n        index.search(q, k);\n    }\n    auto end = std::chrono::high_resolution_clock::now();\n    double elapsed = std::chrono::duration&lt;double&gt;(end - start).count();\n    return static_cast&lt;float&gt;(queries.size()) / elapsed;\n}\n\nint main() {\n    const size_t N = 10000, DIM = 64, K = 10;\n    const size_t NUM_QUERIES = 200;\n    std::mt19937 rng(42);\n    std::uniform_real_distribution&lt;float&gt; dist(-1.0f, 1.0f);\n\n    // Generate dataset\n    std::vector&lt;std::vector&lt;float&gt;&gt; dataset(N);\n    for (auto&amp; v : dataset) {\n        v.resize(DIM);\n        for (auto&amp; x : v) x = dist(rng);\n    }\n\n    // Generate queries\n    std::vector&lt;std::vector&lt;float&gt;&gt; queries(NUM_QUERIES);\n    for (auto&amp; q : queries) {\n        q.resize(DIM);\n        for (auto&amp; x : q) x = dist(rng);\n    }\n\n    // Compute ground truth via brute force\n    std::vector&lt;std::vector&lt;size_t&gt;&gt; ground_truth(NUM_QUERIES);\n    for (size_t i = 0; i &lt; NUM_QUERIES; ++i) {\n        ground_truth[i] = brute_force_knn(dataset, queries[i], K);\n    }\n\n    // Build HNSW index (M=16, ef_construction=200)\n    HNSWIndex index(DIM, /*M=*/16, /*ef_construction=*/200, /*ef_search=*/10);\n    index.build(dataset);\n\n    // \u2500\u2500 Step 4: Sweep ef_search and print table \u2500\u2500\u2500\u2500\u2500\u2500\n    std::vector&lt;size_t&gt; ef_values = {10, 20, 50, 100, 200, 500};\n\n    std::cout &lt;&lt; \"=== HNSW Benchmark: Recall vs QPS ===\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Dataset: \" &lt;&lt; N &lt;&lt; \" vectors \u00d7 \" &lt;&lt; DIM &lt;&lt; \"D, \"\n              &lt;&lt; NUM_QUERIES &lt;&lt; \" queries, K=\" &lt;&lt; K &lt;&lt; std::endl;\n    std::cout &lt;&lt; std::endl;\n    std::cout &lt;&lt; std::setw(12) &lt;&lt; \"ef_search\"\n              &lt;&lt; std::setw(12) &lt;&lt; \"Recall@K\"\n              &lt;&lt; std::setw(12) &lt;&lt; \"QPS\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; std::string(36, '-') &lt;&lt; std::endl;\n\n    for (size_t ef : ef_values) {\n        index.set_ef_search(ef);\n        float recall = measure_recall(index, queries, ground_truth, K);\n        float qps    = measure_qps(index, queries, K);\n\n        std::cout &lt;&lt; std::setw(12) &lt;&lt; ef\n                  &lt;&lt; std::setw(11) &lt;&lt; std::fixed &lt;&lt; std::setprecision(1)\n                  &lt;&lt; recall * 100 &lt;&lt; \"%\"\n                  &lt;&lt; std::setw(12) &lt;&lt; std::setprecision(0)\n                  &lt;&lt; qps &lt;&lt; std::endl;\n    }\n\n    // Verify that high ef_search achieves near-perfect recall\n    index.set_ef_search(500);\n    float high_recall = measure_recall(index, queries, ground_truth, K);\n    assert(high_recall &gt;= 0.95f &amp;&amp; \"ef_search=500 should achieve &gt;= 95% recall\");\n    std::cout &lt;&lt; \"\\n\u2705 Assertion passed: high ef_search recall = \"\n              &lt;&lt; high_recall * 100 &lt;&lt; \"%\" &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre> <p>Compile and run (from <code>src/cpp/</code>): </p><pre><code>g++ -std=c++17 -O2 -o benchmark benchmark_harness.cpp\n./benchmark\n</code></pre><p></p>","tags":["implementation","benchmarks","evaluation"]},{"location":"part-3-implementation/benchmark-harness/#references","title":"References","text":"<ol> <li>Aum\u00fcller, M., Bernhardsson, E., &amp; Faithfull, A. (2020). ANN-Benchmarks: A Benchmarking Tool for Approximate Nearest Neighbor Algorithms. Information Systems.</li> <li>Simhadri, H., et al. (2022). Results of the NeurIPS'21 Challenge on Billion-Scale ANN Search. NeurIPS.</li> </ol>","tags":["implementation","benchmarks","evaluation"]},{"location":"part-3-implementation/elastic-scaling/","title":"Chapter 16 \u2014 Elastic Scaling","text":"","tags":["implementation","scaling","sharding"]},{"location":"part-3-implementation/elastic-scaling/#16-elastic-scaling","title":"16. Elastic Scaling","text":"<p>As data grows or traffic spikes, a vector database must scale out (add nodes) and scale in (remove nodes) without downtime.</p>","tags":["implementation","scaling","sharding"]},{"location":"part-3-implementation/elastic-scaling/#161-scaling-dimensions","title":"16.1 Scaling Dimensions","text":"Dimension Scale out by Bottleneck Data volume Add shards Memory / disk per node Query throughput Add read replicas CPU per node Write throughput Add ingest workers WAL bandwidth Index build Parallel build across cores CPU / memory","tags":["implementation","scaling","sharding"]},{"location":"part-3-implementation/elastic-scaling/#162-shard-split","title":"16.2 Shard Split","text":"<p>When a shard exceeds its capacity threshold (e.g., 50M vectors or 80% memory):</p> <pre><code>sequenceDiagram\n    participant C as Controller\n    participant S1 as Shard A (100M vecs)\n    participant S2 as New Shard B\n    C-&gt;&gt;S1: freeze writes\n    C-&gt;&gt;S1: snapshot segment files\n    C-&gt;&gt;S2: copy lower-half vectors\n    C-&gt;&gt;S1: retain upper-half vectors\n    C-&gt;&gt;S1: rebuild index\n    C-&gt;&gt;S2: build index\n    C-&gt;&gt;C: update routing table\n    C-&gt;&gt;S1: unfreeze writes</code></pre>","tags":["implementation","scaling","sharding"]},{"location":"part-3-implementation/elastic-scaling/#split-strategies","title":"Split Strategies","text":"Strategy Method Pros Cons Hash-based Split hash range in half Even distribution No locality Cluster-based k-means on moved vectors Better search quality Uneven sizes Range-based Split by ID range Simple Skew-prone","tags":["implementation","scaling","sharding"]},{"location":"part-3-implementation/elastic-scaling/#163-live-migration","title":"16.3 Live Migration","text":"<p>Move a shard from node A to node B without downtime:</p> <ol> <li>Snapshot the segment on node A</li> <li>Stream the snapshot to node B</li> <li>Replay WAL entries accumulated during transfer</li> <li>Atomic switch \u2014 update routing, promote B, demote A</li> </ol> $$ \\text{Migration time} \\approx \\frac{\\text{shard size}}{\\text{network bandwidth}} + \\text{WAL catchup} $$ <p>For a 10 GB shard on 10 Gbps network: ~8 seconds + catchup.</p>","tags":["implementation","scaling","sharding"]},{"location":"part-3-implementation/elastic-scaling/#164-auto-scaling-policies","title":"16.4 Auto-Scaling Policies","text":"","tags":["implementation","scaling","sharding"]},{"location":"part-3-implementation/elastic-scaling/#reactive-scaling","title":"Reactive Scaling","text":"<pre><code>if avg_cpu &gt; 80% for 5 minutes:\n    add_replica()\nif avg_memory &gt; 85%:\n    split_largest_shard()\nif avg_cpu &lt; 30% for 15 minutes:\n    remove_replica()\n</code></pre>","tags":["implementation","scaling","sharding"]},{"location":"part-3-implementation/elastic-scaling/#predictive-scaling","title":"Predictive Scaling","text":"<p>Use historical traffic patterns (e.g., 3\u00d7 spike at 9 AM every weekday) to pre-provision capacity:</p> $$ \\text{target\\_replicas}(t) = \\left\\lceil \\frac{\\text{predicted\\_QPS}(t)}{\\text{QPS\\_per\\_replica}} \\right\\rceil $$","tags":["implementation","scaling","sharding"]},{"location":"part-3-implementation/elastic-scaling/#165-zero-downtime-index-rebuild","title":"16.5 Zero-Downtime Index Rebuild","text":"<p>When index parameters change (e.g., increase $M$ from 16 to 32):</p> <ol> <li>Build new index in background on each shard</li> <li>Warm up new index (load into memory, run test queries)</li> <li>Atomic swap: replace old index with new index</li> <li>Delete old index files</li> </ol> $$ \\text{Double memory period} = \\text{build time} + \\text{warmup time} $$","tags":["implementation","scaling","sharding"]},{"location":"part-3-implementation/elastic-scaling/#assignment-simulate-a-shard-split","title":"\ud83d\udee0 Assignment: Simulate a Shard Split","text":"<p>Let's implement the shard split algorithm from Section 16.2. You will build a <code>ShardManager</code> that detects when a shard exceeds its capacity, splits it using a hash-based strategy, and verifies that search still works correctly after the split.</p> <p>Your tasks: 1. Implement <code>ShardManager</code> that holds multiple shard nodes. 2. Implement <code>detect_overload()</code> \u2014 check if any shard exceeds the threshold. 3. Implement <code>split_shard()</code> \u2014 redistribute vectors using hash-based splitting. 4. Verify that search results are identical before and after splitting.</p> Exercise: Shard Split Simulation<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;algorithm&gt;\n#include &lt;random&gt;\n#include &lt;cassert&gt;\n#include &lt;cmath&gt;\n#include &lt;functional&gt;\n\nfloat l2_dist(const std::vector&lt;float&gt;&amp; a, const std::vector&lt;float&gt;&amp; b) {\n    float sum = 0;\n    for (size_t i = 0; i &lt; a.size(); ++i) {\n        float d = a[i] - b[i]; sum += d * d;\n    }\n    return sum;\n}\n\nstruct SearchResult {\n    size_t global_id;\n    float distance;\n    bool operator&lt;(const SearchResult&amp; o) const { return distance &lt; o.distance; }\n};\n\n// \u2500\u2500 Shard Node (reused from Ch 8 exercise) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nclass ShardNode {\npublic:\n    void add(size_t global_id, const std::vector&lt;float&gt;&amp; vec) {\n        ids_.push_back(global_id);\n        data_.push_back(vec);\n    }\n\n    std::vector&lt;SearchResult&gt; local_search(\n        const std::vector&lt;float&gt;&amp; query, size_t k) const {\n        std::vector&lt;SearchResult&gt; results;\n        for (size_t i = 0; i &lt; data_.size(); ++i)\n            results.push_back({ids_[i], l2_dist(data_[i], query)});\n        size_t n = std::min(k, results.size());\n        std::partial_sort(results.begin(), results.begin() + n, results.end());\n        results.resize(n);\n        return results;\n    }\n\n    size_t size() const { return data_.size(); }\n\n    // Expose internals for splitting\n    const std::vector&lt;size_t&gt;&amp; ids() const { return ids_; }\n    const std::vector&lt;std::vector&lt;float&gt;&gt;&amp; data() const { return data_; }\n\nprivate:\n    std::vector&lt;size_t&gt; ids_;\n    std::vector&lt;std::vector&lt;float&gt;&gt; data_;\n};\n\n// \u2500\u2500 Shard Manager \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nclass ShardManager {\npublic:\n    explicit ShardManager(size_t capacity_threshold)\n        : threshold_(capacity_threshold) {}\n\n    void add_shard(ShardNode shard) {\n        shards_.push_back(std::move(shard));\n    }\n\n    // Step 1: Detect if any shard exceeds the capacity limit\n    int detect_overload() const {\n        for (size_t i = 0; i &lt; shards_.size(); ++i) {\n            if (shards_[i].size() &gt; threshold_) return static_cast&lt;int&gt;(i);\n        }\n        return -1;  // All shards healthy\n    }\n\n    // Step 2: Split the overloaded shard using hash-based strategy\n    void split_shard(size_t shard_idx) {\n        const auto&amp; old = shards_[shard_idx];\n        ShardNode left, right;\n\n        // Hash-based split: even hash \u2192 left, odd hash \u2192 right\n        for (size_t i = 0; i &lt; old.size(); ++i) {\n            size_t id = old.ids()[i];\n            size_t hash = std::hash&lt;size_t&gt;{}(id);\n            if (hash % 2 == 0) {\n                left.add(id, old.data()[i]);\n            } else {\n                right.add(id, old.data()[i]);\n            }\n        }\n\n        // Replace the old shard with two new ones\n        shards_.erase(shards_.begin() + shard_idx);\n        shards_.push_back(std::move(left));\n        shards_.push_back(std::move(right));\n    }\n\n    // Scatter-Gather search across all shards\n    std::vector&lt;SearchResult&gt; search(const std::vector&lt;float&gt;&amp; query,\n                                     size_t k) const {\n        std::vector&lt;SearchResult&gt; merged;\n        for (const auto&amp; shard : shards_) {\n            auto local = shard.local_search(query, k);\n            merged.insert(merged.end(), local.begin(), local.end());\n        }\n        size_t n = std::min(k, merged.size());\n        std::partial_sort(merged.begin(), merged.begin() + n, merged.end());\n        merged.resize(n);\n        return merged;\n    }\n\n    size_t num_shards() const { return shards_.size(); }\n    size_t shard_size(size_t i) const { return shards_[i].size(); }\n\nprivate:\n    std::vector&lt;ShardNode&gt; shards_;\n    size_t threshold_;\n};\n\nint main() {\n    const size_t N = 2000, DIM = 32, K = 5;\n    const size_t SHARD_CAPACITY = 600;\n    std::mt19937 rng(42);\n    std::uniform_real_distribution&lt;float&gt; dist(-1.0f, 1.0f);\n\n    // Start with a single shard holding everything\n    ShardNode initial_shard;\n    std::vector&lt;std::vector&lt;float&gt;&gt; all_data(N);\n    for (size_t i = 0; i &lt; N; ++i) {\n        all_data[i].resize(DIM);\n        for (auto&amp; x : all_data[i]) x = dist(rng);\n        initial_shard.add(i, all_data[i]);\n    }\n\n    ShardManager mgr(SHARD_CAPACITY);\n    mgr.add_shard(std::move(initial_shard));\n\n    // Query BEFORE split\n    std::vector&lt;float&gt; query(DIM);\n    for (auto&amp; x : query) x = dist(rng);\n    auto before_results = mgr.search(query, K);\n\n    std::cout &lt;&lt; \"=== Shard Split Exercise ===\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Before split: \" &lt;&lt; mgr.num_shards()\n              &lt;&lt; \" shard(s), \" &lt;&lt; mgr.shard_size(0) &lt;&lt; \" vectors\" &lt;&lt; std::endl;\n\n    // Detect and split overloaded shards\n    int overloaded;\n    while ((overloaded = mgr.detect_overload()) &gt;= 0) {\n        std::cout &lt;&lt; \"  Splitting shard \" &lt;&lt; overloaded\n                  &lt;&lt; \" (size=\" &lt;&lt; mgr.shard_size(overloaded) &lt;&lt; \")\" &lt;&lt; std::endl;\n        mgr.split_shard(overloaded);\n    }\n\n    std::cout &lt;&lt; \"After split: \" &lt;&lt; mgr.num_shards() &lt;&lt; \" shards\" &lt;&lt; std::endl;\n    for (size_t i = 0; i &lt; mgr.num_shards(); ++i)\n        std::cout &lt;&lt; \"  Shard \" &lt;&lt; i &lt;&lt; \": \" &lt;&lt; mgr.shard_size(i)\n                  &lt;&lt; \" vectors\" &lt;&lt; std::endl;\n\n    // Query AFTER split \u2014 results must be identical\n    auto after_results = mgr.search(query, K);\n\n    bool match = true;\n    for (size_t i = 0; i &lt; K; ++i) {\n        if (before_results[i].global_id != after_results[i].global_id) {\n            match = false; break;\n        }\n    }\n\n    std::cout &lt;&lt; \"Search results match: \" &lt;&lt; (match ? \"YES\" : \"NO\") &lt;&lt; std::endl;\n    assert(match &amp;&amp; \"Search must return identical results after shard split!\");\n    std::cout &lt;&lt; \"\u2705 Assertion passed!\" &lt;&lt; std::endl;\n    return 0;\n}\n</code></pre> <p>Compile and run: </p><pre><code>g++ -std=c++17 -O2 -o shard_split shard_split.cpp\n./shard_split\n</code></pre><p></p>","tags":["implementation","scaling","sharding"]},{"location":"part-3-implementation/elastic-scaling/#references","title":"References","text":"<ol> <li>Corbett, J. C., et al. (2013). Spanner: Google's Globally Distributed Database. ACM TOCS.</li> <li>Huang, Q., et al. (2020). AnalyticDB-V: A Hybrid Analytical Engine Towards Query Fusion for Structured and Unstructured Data. VLDB.</li> </ol>","tags":["implementation","scaling","sharding"]},{"location":"part-3-implementation/hnsw-rust/","title":"Chapter 13 \u2014 Building an HNSW Store in Rust","text":"","tags":["implementation","rust","hnsw"]},{"location":"part-3-implementation/hnsw-rust/#13-building-an-hnsw-store-in-rust","title":"13. Building an HNSW Store in Rust","text":"<p>This chapter walks through the design of a production-quality HNSW index in Rust, focusing on memory layout, safety trade-offs, and performance engineering.</p>","tags":["implementation","rust","hnsw"]},{"location":"part-3-implementation/hnsw-rust/#131-why-rust-for-vector-indexes","title":"13.1 Why Rust for Vector Indexes?","text":"Feature C++ Rust Go/Java Memory safety Manual Compile-time guaranteed GC Performance Fastest ~Same as C++ 2\u20135\u00d7 slower Concurrency Threads + locks Ownership + <code>Send</code>/<code>Sync</code> Goroutines GC pauses None None Unpredictable latency spikes Ecosystem Mature Growing rapidly Large <p>GC is the enemy of p99 latency</p> <p>A 50ms GC pause in a Go/Java vector database can violate SLAs. Rust and C++ avoid this entirely.</p>","tags":["implementation","rust","hnsw"]},{"location":"part-3-implementation/hnsw-rust/#132-memory-layout-design","title":"13.2 Memory Layout Design","text":"","tags":["implementation","rust","hnsw"]},{"location":"part-3-implementation/hnsw-rust/#flat-vector-storage","title":"Flat Vector Storage","text":"<p>Store all vectors in a contiguous, memory-mapped <code>Vec&lt;f32&gt;</code>:</p> <pre><code>/// Contiguous vector storage \u2014 cache-friendly, mmap-able.\npub struct VectorStorage {\n    data: memmap2::MmapMut,  // memory-mapped file\n    dim: usize,\n    count: usize,\n}\n\nimpl VectorStorage {\n    /// Get vector by ID \u2014 zero-copy from mmap.\n    #[inline]\n    pub fn get(&amp;self, id: usize) -&gt; &amp;[f32] {\n        let offset = id * self.dim * std::mem::size_of::&lt;f32&gt;();\n        let bytes = &amp;self.data[offset..offset + self.dim * 4];\n        // SAFETY: data is aligned and initialized during build\n        unsafe { std::slice::from_raw_parts(bytes.as_ptr() as *const f32, self.dim) }\n    }\n}\n</code></pre>","tags":["implementation","rust","hnsw"]},{"location":"part-3-implementation/hnsw-rust/#graph-adjacency-storage","title":"Graph Adjacency Storage","text":"<p>Store neighbor lists in a flat array with fixed-width entries (no heap allocation per node):</p> <pre><code>/// Fixed-width adjacency list for one layer.\n/// Layout: [count, n0, n1, ..., n_{M-1}] per node, each u32.\npub struct GraphLayer {\n    data: Vec&lt;u32&gt;,\n    max_neighbors: usize,\n    entry_width: usize,  // = 1 + max_neighbors\n}\n\nimpl GraphLayer {\n    pub fn neighbors(&amp;self, node: u32) -&gt; &amp;[u32] {\n        let offset = node as usize * self.entry_width;\n        let count = self.data[offset] as usize;\n        &amp;self.data[offset + 1..offset + 1 + count]\n    }\n\n    pub fn add_neighbor(&amp;mut self, node: u32, neighbor: u32) {\n        let offset = node as usize * self.entry_width;\n        let count = self.data[offset] as usize;\n        if count &lt; self.max_neighbors {\n            self.data[offset + 1 + count] = neighbor;\n            self.data[offset] += 1;\n        }\n    }\n}\n</code></pre> <p>This layout has zero heap fragmentation and is trivially serializable to disk.</p>","tags":["implementation","rust","hnsw"]},{"location":"part-3-implementation/hnsw-rust/#133-simd-distance-kernels-in-rust","title":"13.3 SIMD Distance Kernels in Rust","text":"<p>Use the <code>std::arch</code> intrinsics for platform-specific SIMD:</p> <pre><code>#[cfg(target_arch = \"x86_64\")]\nuse std::arch::x86_64::*;\n\n/// AVX2-accelerated L2 squared distance.\n#[cfg(target_arch = \"x86_64\")]\n#[target_feature(enable = \"avx2\", enable = \"fma\")]\nunsafe fn l2_squared_avx2(a: &amp;[f32], b: &amp;[f32]) -&gt; f32 {\n    let mut sum = _mm256_setzero_ps();\n    let chunks = a.len() / 8;\n    for i in 0..chunks {\n        let va = _mm256_loadu_ps(a.as_ptr().add(i * 8));\n        let vb = _mm256_loadu_ps(b.as_ptr().add(i * 8));\n        let diff = _mm256_sub_ps(va, vb);\n        sum = _mm256_fmadd_ps(diff, diff, sum);\n    }\n    // Horizontal sum\n    let hi = _mm256_extractf128_ps(sum, 1);\n    let lo = _mm256_castps256_ps128(sum);\n    let sum128 = _mm_add_ps(lo, hi);\n    let sum128 = _mm_hadd_ps(sum128, sum128);\n    let sum128 = _mm_hadd_ps(sum128, sum128);\n    let mut result = _mm_cvtss_f32(sum128);\n    // Remainder\n    for i in (chunks * 8)..a.len() {\n        let d = a[i] - b[i];\n        result += d * d;\n    }\n    result\n}\n</code></pre>","tags":["implementation","rust","hnsw"]},{"location":"part-3-implementation/hnsw-rust/#134-concurrent-search-with-rwlock","title":"13.4 Concurrent Search with <code>RwLock</code>","text":"<p>Multiple readers can search simultaneously; writers take an exclusive lock:</p> <pre><code>use std::sync::RwLock;\n\npub struct ConcurrentHNSW {\n    graph: RwLock&lt;Vec&lt;GraphLayer&gt;&gt;,\n    vectors: VectorStorage,\n}\n\nimpl ConcurrentHNSW {\n    pub fn search(&amp;self, query: &amp;[f32], k: usize) -&gt; Vec&lt;(f32, u32)&gt; {\n        let graph = self.graph.read().unwrap();  // shared lock\n        // ... beam search using graph ...\n        todo!()\n    }\n\n    pub fn insert(&amp;self, vector: &amp;[f32]) -&gt; u32 {\n        let mut graph = self.graph.write().unwrap();  // exclusive lock\n        // ... insert into graph ...\n        todo!()\n    }\n}\n</code></pre> <p>Write starvation</p> <p>Under heavy read load, writers may starve. Use a <code>parking_lot::RwLock</code> which provides writer-preferring fairness.</p>","tags":["implementation","rust","hnsw"]},{"location":"part-3-implementation/hnsw-rust/#135-persistence-and-recovery","title":"13.5 Persistence and Recovery","text":"","tags":["implementation","rust","hnsw"]},{"location":"part-3-implementation/hnsw-rust/#on-disk-format","title":"On-Disk Format","text":"<pre><code>index.hnsw\n\u251c\u2500\u2500 header (8 bytes: magic, version)\n\u251c\u2500\u2500 metadata (dim, M, ef, entry_point, max_layer)\n\u251c\u2500\u2500 vectors.bin (n \u00d7 dim \u00d7 4 bytes, mmap'd)\n\u251c\u2500\u2500 graph_layer_0.bin (n \u00d7 entry_width \u00d7 4 bytes)\n\u251c\u2500\u2500 graph_layer_1.bin (...)\n\u2514\u2500\u2500 ...\n</code></pre>","tags":["implementation","rust","hnsw"]},{"location":"part-3-implementation/hnsw-rust/#wal-for-crash-recovery","title":"WAL for Crash Recovery","text":"<ol> <li>Append <code>(INSERT, id, vector)</code> to WAL</li> <li>Insert into in-memory graph</li> <li>On flush, write graph layers to disk</li> <li>On startup, replay WAL entries after last checkpoint</li> </ol>","tags":["implementation","rust","hnsw"]},{"location":"part-3-implementation/hnsw-rust/#136-optimization-checklist","title":"13.6 Optimization Checklist","text":"Optimization Impact Complexity SIMD distance kernels 5\u20138\u00d7 throughput Medium Memory-mapped vectors Zero-copy, OS-managed paging Low Flat adjacency arrays Cache-friendly, no allocator overhead Medium <code>RwLock</code> for concurrency Linear read scaling Low Prefetch neighbor vectors 10\u201330% latency reduction Medium PQ re-ranking 10\u201350\u00d7 memory reduction High","tags":["implementation","rust","hnsw"]},{"location":"part-3-implementation/hnsw-rust/#references","title":"References","text":"<ol> <li>Malkov, Y. A., &amp; Yashunin, D. A. (2020). HNSW. IEEE TPAMI.</li> <li>Qdrant source code (Rust HNSW implementation). https://github.com/qdrant/qdrant</li> </ol>","tags":["implementation","rust","hnsw"]},{"location":"part-3-implementation/pq-ivf-gpu/","title":"Chapter 14 \u2014 PQ-IVF on GPUs","text":"","tags":["implementation","gpu","cuda","pq"]},{"location":"part-3-implementation/pq-ivf-gpu/#14-pq-ivf-on-gpus","title":"14. PQ-IVF on GPUs","text":"<p>GPU-accelerated IVF-PQ is the workhorse of billion-scale vector search. This chapter shows how FAISS-style GPU kernels achieve 10,000+ QPS on a single GPU.</p>","tags":["implementation","gpu","cuda","pq"]},{"location":"part-3-implementation/pq-ivf-gpu/#141-gpu-memory-hierarchy-review","title":"14.1 GPU Memory Hierarchy Review","text":"<pre><code>flowchart TD\n    REG[\"Registers&lt;br/&gt;~256KB per SM&lt;br/&gt;~0.5 cycle\"] --&gt; SMEM[\"Shared Memory&lt;br/&gt;64-228KB per SM&lt;br/&gt;~5 cycles\"]\n    SMEM --&gt; L2[\"L2 Cache&lt;br/&gt;4-40MB&lt;br/&gt;~30 cycles\"]\n    L2 --&gt; HBM[\"HBM/GDDR&lt;br/&gt;16-80GB&lt;br/&gt;~500 cycles\"]</code></pre> <p>Design principle</p> <p>Keep the distance lookup table in shared memory (fits easily: $M \\times K \\times 4 = 8 \\times 256 \\times 4 = 8$ KB). Scan PQ codes from HBM \u2014 they're compact ($M$ bytes per vector).</p>","tags":["implementation","gpu","cuda","pq"]},{"location":"part-3-implementation/pq-ivf-gpu/#142-ivf-pq-on-gpu-execution-model","title":"14.2 IVF-PQ on GPU: Execution Model","text":"","tags":["implementation","gpu","cuda","pq"]},{"location":"part-3-implementation/pq-ivf-gpu/#step-1-coarse-quantizer-find-nearest-centroids","title":"Step 1: Coarse Quantizer (Find Nearest Centroids)","text":"<pre><code>// Each thread block processes one query\n// Find nprobe nearest centroids from nlist candidates\n__global__ void find_nearest_centroids(\n    const float* queries,     // [nq \u00d7 d]\n    const float* centroids,   // [nlist \u00d7 d]\n    int* nearest_cells,       // [nq \u00d7 nprobe]\n    float* centroid_dists,    // [nq \u00d7 nprobe]\n    int nq, int nlist, int d, int nprobe\n);\n</code></pre>","tags":["implementation","gpu","cuda","pq"]},{"location":"part-3-implementation/pq-ivf-gpu/#step-2-build-distance-tables","title":"Step 2: Build Distance Tables","text":"<p>For each query, precompute the $(M \\times K)$ distance table:</p> $$ \\text{dt}[m][k] = \\|q^{(m)} - c_k^{(m)}\\|^2, \\quad m \\in [0, M), \\; k \\in [0, 256) $$ <pre><code>// Kernel: one thread block per query\n// Each thread computes distances for a subset of (m, k) pairs\n// Store result in shared memory for reuse\n__global__ void compute_distance_tables(\n    const float* queries,       // [nq \u00d7 d]\n    const float* codebooks,     // [M \u00d7 K \u00d7 ds]\n    float* distance_tables,     // [nq \u00d7 M \u00d7 K]\n    int nq, int M, int K, int ds\n) {\n    extern __shared__ float shared_dt[];  // M \u00d7 K floats\n\n    int qid = blockIdx.x;\n    int tid = threadIdx.x;\n\n    // Each thread handles ceil(M*K / blockDim) entries\n    for (int idx = tid; idx &lt; M * K; idx += blockDim.x) {\n        int m = idx / K;\n        int k = idx % K;\n        float dist = 0.0f;\n        for (int dd = 0; dd &lt; ds; ++dd) {\n            float diff = queries[qid * (M * ds) + m * ds + dd]\n                       - codebooks[m * K * ds + k * ds + dd];\n            dist += diff * diff;\n        }\n        shared_dt[idx] = dist;\n    }\n    __syncthreads();\n\n    // Copy to global memory\n    for (int idx = tid; idx &lt; M * K; idx += blockDim.x) {\n        distance_tables[qid * M * K + idx] = shared_dt[idx];\n    }\n}\n</code></pre>","tags":["implementation","gpu","cuda","pq"]},{"location":"part-3-implementation/pq-ivf-gpu/#step-3-scan-pq-codes","title":"Step 3: Scan PQ Codes","text":"<p>The inner loop \u2014 scan all codes in selected Voronoi cells:</p> <pre><code>// Each thread block handles one query \u00d7 one cell\n// Threads cooperatively scan PQ codes\n__global__ void scan_pq_codes(\n    const uint8_t* pq_codes,    // [n \u00d7 M]\n    const float* dist_tables,   // [nq \u00d7 M \u00d7 K]\n    const int* cell_starts,     // inverted list offsets\n    const int* cell_sizes,\n    float* top_k_dists,         // [nq \u00d7 k]\n    int* top_k_ids,             // [nq \u00d7 k]\n    int M, int K, int k\n) {\n    int qid = blockIdx.x;\n    int cell = blockIdx.y;\n\n    // Load distance table into shared memory\n    extern __shared__ float sdt[];\n    for (int i = threadIdx.x; i &lt; M * K; i += blockDim.x)\n        sdt[i] = dist_tables[qid * M * K + i];\n    __syncthreads();\n\n    // Each thread scans a subset of vectors in this cell\n    int start = cell_starts[cell];\n    int size = cell_sizes[cell];\n    for (int v = threadIdx.x; v &lt; size; v += blockDim.x) {\n        float dist = 0.0f;\n        const uint8_t* code = &amp;pq_codes[(start + v) * M];\n        for (int m = 0; m &lt; M; ++m) {\n            dist += sdt[m * K + code[m]];  // Table lookup!\n        }\n        // Thread-local top-k insertion (heap)\n        // ... merge across threads using warp shuffle ...\n    }\n}\n</code></pre>","tags":["implementation","gpu","cuda","pq"]},{"location":"part-3-implementation/pq-ivf-gpu/#143-performance-analysis","title":"14.3 Performance Analysis","text":"","tags":["implementation","gpu","cuda","pq"]},{"location":"part-3-implementation/pq-ivf-gpu/#arithmetic-intensity","title":"Arithmetic Intensity","text":"<p>For PQ code scanning, each vector requires: - $M$ byte loads (PQ codes) - $M$ float loads (table lookups) - $M$ float additions</p> $$ \\text{Arithmetic intensity} = \\frac{M \\text{ FLOPs}}{M + M \\times 4 \\text{ bytes}} = \\frac{1}{5} \\text{ FLOP/byte} $$ <p>This is memory-bandwidth bound \u2014 GPU HBM bandwidth (900+ GB/s on A100) is the limiting factor.</p>","tags":["implementation","gpu","cuda","pq"]},{"location":"part-3-implementation/pq-ivf-gpu/#throughput-model","title":"Throughput Model","text":"$$ \\text{QPS} = \\frac{\\text{HBM bandwidth}}{n_{\\text{probe}} \\cdot \\frac{n}{n_{\\text{list}}} \\cdot M \\text{ bytes/query}} $$ <p>For A100 (2 TB/s), $n = 10^9$, $n_{\\text{list}} = 65536$, $n_{\\text{probe}} = 64$, $M = 8$:</p> $$ \\text{QPS} \\approx \\frac{2 \\times 10^{12}}{64 \\times 15259 \\times 8} \\approx 256{,}000 \\text{ QPS} $$ <p>In practice: ~10K\u201350K QPS per GPU</p> <p>Overhead from coarse quantizer, kernel launch, and host-device transfer reduces theoretical throughput.</p>","tags":["implementation","gpu","cuda","pq"]},{"location":"part-3-implementation/pq-ivf-gpu/#144-multi-gpu-strategies","title":"14.4 Multi-GPU Strategies","text":"Strategy Description Scaling Replicated Full index on each GPU Linear QPS Sharded Partition across GPUs Linear capacity Hybrid Shard data, replicate codebooks Best for large datasets","tags":["implementation","gpu","cuda","pq"]},{"location":"part-3-implementation/pq-ivf-gpu/#references","title":"References","text":"<ol> <li>Johnson, J., Douze, M., &amp; J\u00e9gou, H. (2019). Billion-scale similarity search with GPUs. IEEE TBD.</li> <li>FAISS Wiki. GPU FAQ. https://github.com/facebookresearch/faiss/wiki/</li> </ol>","tags":["implementation","gpu","cuda","pq"]},{"location":"part-3-implementation/transactional-schemes/","title":"Chapter 15 \u2014 Transactional Schemes for Vector Data","text":"","tags":["implementation","transactions","mvcc"]},{"location":"part-3-implementation/transactional-schemes/#15-transactional-schemes-for-vector-data","title":"15. Transactional Schemes for Vector Data","text":"<p>Traditional databases provide ACID transactions. Vector databases must support consistent reads during concurrent writes without degrading search performance.</p>","tags":["implementation","transactions","mvcc"]},{"location":"part-3-implementation/transactional-schemes/#151-why-transactions-matter-for-vectors","title":"15.1 Why Transactions Matter for Vectors","text":"Scenario Without transactions With transactions Update embedding model Partial old + new vectors visible Atomic switch Delete + re-insert Ghost results (deleted but findable) Consistent view Batch ingestion Partial batches visible to queries All-or-nothing","tags":["implementation","transactions","mvcc"]},{"location":"part-3-implementation/transactional-schemes/#152-mvcc-multi-version-concurrency-control","title":"15.2 MVCC (Multi-Version Concurrency Control)","text":"","tags":["implementation","transactions","mvcc"]},{"location":"part-3-implementation/transactional-schemes/#concept","title":"Concept","text":"<p>Each vector version has a visibility range $[\\text{create\\_ts}, \\text{delete\\_ts})$:</p> $$ \\text{visible}(v, t) = v.\\text{create\\_ts} \\leq t &lt; v.\\text{delete\\_ts} $$ <p>Queries execute at a snapshot timestamp $t_{\\text{snap}}$ and only see vectors visible at that timestamp.</p>","tags":["implementation","transactions","mvcc"]},{"location":"part-3-implementation/transactional-schemes/#implementation","title":"Implementation","text":"<pre><code>struct VersionedVector {\n    uint64_t id;\n    uint64_t create_ts;       // Timestamp when inserted\n    uint64_t delete_ts;       // UINT64_MAX if live\n    std::vector&lt;float&gt; data;  // The actual embedding\n\n    bool visible_at(uint64_t snapshot_ts) const {\n        return create_ts &lt;= snapshot_ts &amp;&amp; snapshot_ts &lt; delete_ts;\n    }\n};\n</code></pre>","tags":["implementation","transactions","mvcc"]},{"location":"part-3-implementation/transactional-schemes/#during-search","title":"During Search","text":"<pre><code>// In HNSW beam search, skip invisible vectors:\nfor (size_t neighbor : graph[layer][current]) {\n    if (!vectors[neighbor].visible_at(snapshot_ts))\n        continue;  // Skip: not visible in this snapshot\n    float dist = distance(query, vectors[neighbor].data);\n    // ... process candidate ...\n}\n</code></pre>","tags":["implementation","transactions","mvcc"]},{"location":"part-3-implementation/transactional-schemes/#153-snapshot-isolation-for-vector-search","title":"15.3 Snapshot Isolation for Vector Search","text":"<p>Snapshot isolation guarantees:</p> <ol> <li>Read consistency: A query sees a consistent state \u2014 no torn writes</li> <li>Non-blocking reads: Queries don't block insertions (and vice versa)</li> <li>Write conflicts: Concurrent updates to the same vector ID are detected</li> </ol> <pre><code>sequenceDiagram\n    participant W as Writer\n    participant DB as Vector DB\n    participant R as Reader\n    W-&gt;&gt;DB: begin_txn(ts=100)\n    W-&gt;&gt;DB: insert(vec_A, ts=100)\n    R-&gt;&gt;DB: search(snapshot=99)\n    Note over DB: vec_A NOT visible (99 &lt; 100)\n    W-&gt;&gt;DB: commit(ts=100)\n    R-&gt;&gt;DB: search(snapshot=101)\n    Note over DB: vec_A IS visible (100 \u2264 101)</code></pre>","tags":["implementation","transactions","mvcc"]},{"location":"part-3-implementation/transactional-schemes/#154-compaction-and-garbage-collection","title":"15.4 Compaction and Garbage Collection","text":"","tags":["implementation","transactions","mvcc"]},{"location":"part-3-implementation/transactional-schemes/#when-to-compact","title":"When to Compact","text":"<p>Old versions accumulate. Compact when:</p> $$ \\frac{\\text{dead vectors}}{\\text{total vectors}} &gt; \\theta \\quad \\text{(typically } \\theta = 0.2\\text{)} $$","tags":["implementation","transactions","mvcc"]},{"location":"part-3-implementation/transactional-schemes/#safe-garbage-collection","title":"Safe Garbage Collection","text":"<p>Only delete old versions when no active snapshot references them:</p> $$ \\text{safe\\_to\\_gc}(v) = v.\\text{delete\\_ts} &lt; \\min_{s \\in \\text{active\\_snapshots}} s $$ <p>Long-running queries block GC</p> <p>A query snapshot from 10 minutes ago prevents GC of all versions created since. Use snapshot timeout to force-close old snapshots.</p>","tags":["implementation","transactions","mvcc"]},{"location":"part-3-implementation/transactional-schemes/#155-comparison-with-traditional-dbs","title":"15.5 Comparison with Traditional DBs","text":"Feature PostgreSQL (pgvector) Native Vector DB This design ACID Full Limited Snapshot isolation Isolation level Serializable Best-effort Snapshot WAL Built-in Custom Custom Concurrent search + insert Yes (via MVCC) Yes (via segments) Yes (via MVCC) Performance overhead ~10% ~0% ~5% (visibility check)","tags":["implementation","transactions","mvcc"]},{"location":"part-3-implementation/transactional-schemes/#references","title":"References","text":"<ol> <li>Berenson, H., et al. (1995). A Critique of ANSI SQL Isolation Levels. SIGMOD.</li> <li>Tu, S., et al. (2013). Speedy Transactions in Multicore In-Memory Databases (Silo). SOSP.</li> </ol>","tags":["implementation","transactions","mvcc"]},{"location":"part-4-advanced/","title":"Part IV \u2014 Advanced Topics & Research Frontiers","text":""},{"location":"part-4-advanced/#part-iv-advanced-topics-research-frontiers","title":"Part IV \u2014 Advanced Topics &amp; Research Frontiers","text":"<p>This section explores the cutting edge \u2014 where vector databases intersect with privacy, continual learning, LLM agents, and emerging hardware paradigms.</p>"},{"location":"part-4-advanced/#chapters","title":"Chapters","text":"# Chapter Key Topics 18 Privacy-Preserving Search Homomorphic encryption, MPC, differential privacy 19 Continual &amp; Online Learning Embedding updates without re-indexing, forgetting mitigation 20 Vector DBs for Gen-AI Agents RAG pipelines, agentic memory, prompt-time reranking 21 Future Directions Learned indexing, vector SQL, neuromorphic accelerators 22 Advanced Open Source DBs LanceDB, Vespa, Vald, USearch, pgvector internals 23 Real-World Case Studies Search architectures at Spotify, Pinterest, and OpenAI 24 In-Database ML &amp; Feature Stores PostgresML, Featureform, virtualization"},{"location":"part-4-advanced/advanced-open-source-dbs/","title":"Chapter 22 \u2014 Advanced Open Source Vector Databases","text":"","tags":["advanced","databases","opensource"]},{"location":"part-4-advanced/advanced-open-source-dbs/#22-advanced-open-source-vector-databases","title":"22. Advanced Open Source Vector Databases","text":"<p>While the foundational chapters covered the universal architecture behind systems like Milvus, Qdrant, and Pinecone, the open-source community continues to innovate rapidly. This chapter explores several advanced and highly specialized open-source vector databases that challenge the standard HNSW/IVF paradigms.</p>","tags":["advanced","databases","opensource"]},{"location":"part-4-advanced/advanced-open-source-dbs/#221-faiss-the-grandfather-of-ai-search","title":"22.1 FAISS (The Grandfather of AI Search)","text":"<p>Originally open-sourced by Facebook AI Research (now Meta) in 2017, FAISS (Facebook AI Similarity Search) is the foundational C++ library that popularized dense vector search. While not a standalone \"database\" with a REST API or distributed clustering, it remains the gold standard engine embedded inside many other tools.</p>","tags":["advanced","databases","opensource"]},{"location":"part-4-advanced/advanced-open-source-dbs/#key-innovations","title":"Key Innovations","text":"<ol> <li>IVF-PQ Dominance: FAISS popularized the combination of Inverted File Indexes (IVF) with Product Quantization (PQ), proving that billion-scale search could be done entirely in RAM with high mathematical recall.</li> <li>GPU Acceleration: It remains one of the few libraries with truly world-class, multi-GPU CUDA implementations for exact k-NN and IVF-PQ search, capable of evaluating tens of billions of distances per second on a single machine.</li> <li>Index Composability: FAISS provides a brilliant factory string syntax (e.g., <code>PCA64,IVF16384,PQ16</code>) that lets developers snap together dimensionality reduction, clustering, and quantization strategies like Lego bricks.</li> </ol> <p>Use Case: Offline batch processing, massive machine learning pipelines, or backend algorithms where you need absolute maximum GPU speed and don't require database features like multi-tenant isolation or distributed consensus.</p>","tags":["advanced","databases","opensource"]},{"location":"part-4-advanced/advanced-open-source-dbs/#222-lancedb-columnar-serverless-vector-db","title":"22.2 LanceDB (Columnar Serverless Vector DB)","text":"<p>Most traditional vector databases store embeddings in separate files or memory structures from the scalar metadata. LanceDB upends this by building directly on top of the Lance format, an open-source columnar data format designed as a modern successor to Apache Parquet.</p>","tags":["advanced","databases","opensource"]},{"location":"part-4-advanced/advanced-open-source-dbs/#key-innovations_1","title":"Key Innovations","text":"<ol> <li>Zero-Copy Reads: Because the data is stored in a sophisticated memory-mapped columnar format, querying billions of vectors requires almost zero RAM overhead. The OS pages the disk directly into the query engine.</li> <li>Serverless Architecture: LanceDB can be embedded directly into a Python or Rust application like SQLite. There is no heavy database server to manage. The data simply sits in Amazon S3 or a local disk, and the LanceDB library queries it directly.</li> <li>Multi-Modal Native: It natively stores huge images, text, and tensors in the same columnar file as the embeddings.</li> <li>Late Materialization: If your table contains a heavy 2MB image blob and a 1KB metadata column, traditional formats like Parquet require scanning across massive chunks of those blobs during a <code>WHERE</code> filter pass. Lance avoids this entirely via Late Materialization. It strictly scans the lightweight predicate/metadata columns first, identifies the exact matching row IDs, and only executes computationally expensive random-access fetches for the heavy image blobs at the very end of the query execution pipeline.</li> </ol> <p>Use Case: Massive, multi-modal datasets where you don't want to pay $2,000/month for an always-on Milvus cluster, and complex data science queries combining pandas/Polars directly with vector searches.</p>","tags":["advanced","databases","opensource"]},{"location":"part-4-advanced/advanced-open-source-dbs/#223-vespaai-the-real-time-engine","title":"22.3 Vespa.ai (The Real-Time Engine)","text":"<p>Originally developed by Yahoo, Vespa is arguably the most battle-tested large-scale search engine on the planet, powering search and recommendations for Spotify, OkCupid, and Yahoo. It is an extremely heavy, Java/C++ enterprise system.</p>","tags":["advanced","databases","opensource"]},{"location":"part-4-advanced/advanced-open-source-dbs/#key-innovations_2","title":"Key Innovations","text":"<ol> <li>State-of-the-Art Hybrid Search: While other databases are just now bolting BM25 (keyword search) onto HNSW, Vespa has been the king of lexical full-text search and tensor evaluation for a decade. It handles complex multi-phase ranking natively.</li> <li>True Streaming Updates: Vespa allows you to update metadata or embeddings with sub-second latency visible across the entire distributed cluster globally. It doesn't rely on slow batch-compaction cycles like standard LSM trees.</li> <li>On-Node Machine Learning: Instead of just running an HNSW search, Vespa allows you to upload custom TensorFlow, ONNX, or XGBoost models directly into the database. It runs these heavy machine learning models on the storage nodes themselves to re-rank the top 1000 vector results instantly.</li> </ol> <p>Use Case: Massive e-commerce recommendation feeds (e.g., TikTok, Spotify) where user behavior changes every 3 seconds, requiring immediate, real-time index updates and custom neural network re-ranking.</p>","tags":["advanced","databases","opensource"]},{"location":"part-4-advanced/advanced-open-source-dbs/#224-vald-highly-distributed-cloud-native","title":"22.4 Vald (Highly Distributed Cloud-Native)","text":"<p>Vald is a highly distributed vector search engine built entirely around Kubernetes. It differs from the typical HNSW crowd by using NGT (Neighborhood Graph and Tree) developed by Yahoo Japan.</p>","tags":["advanced","databases","opensource"]},{"location":"part-4-advanced/advanced-open-source-dbs/#key-innovations_3","title":"Key Innovations","text":"<ol> <li>Microservice Native: Vald doesn't have a massive single binary. It splits the Ingest gateway, the Indexing workers, the Agent nodes, and the Backup managers into tiny, independent Kubernetes pods. You can scale the indexing pods infinitely during a heavy bulk upload, and scale them to zero afterwards.</li> <li>NGT Algorithm: NGT builds a graph similarly to HNSW but focuses heavily on high dimensional stability and incredibly fast index construction times, often beating HNSW under specific high-dimension benchmarks.</li> <li>Auto-Rebalancing: Vald continuously monitors query volume and automatically rebalances the NGT graph representations across hundreds of Kubernetes pods to eliminate hot-spots.</li> </ol> <p>Use Case: Enterprise Kubernetes environments needing to run multi-tenant billions-scale vector search with highly dynamic elastic scaling of specific database components.</p>","tags":["advanced","databases","opensource"]},{"location":"part-4-advanced/advanced-open-source-dbs/#225-usearch-header-only-c-speed","title":"22.5 USearch (Header-Only C++ Speed)","text":"<p>While Milvus and Qdrant are giant applications, USearch by Unum is a single, tiny, header-only C++ library. It is designed to be the absolute fastest HNSW implementation on earth.</p>","tags":["advanced","databases","opensource"]},{"location":"part-4-advanced/advanced-open-source-dbs/#key-innovations_4","title":"Key Innovations","text":"<ol> <li>Hardware Specificity: USearch has native bindings for x86 AVX-512 and ARM Neon instructions, pushing raw SIMD distance calculation to the physical limit of the silicon.</li> <li>Extreme Portability: Because it has zero external dependencies, it compiles instantly into Python, Java, Rust, Go, Swift, SQLite, and WebAssembly.</li> <li>Custom Metrics: It allows developers to define incredibly complex, proprietary distance metrics (like Jaccard or custom AI similarities) using JIT (Just-In-Time) compilation.</li> </ol> <p>Use Case: Edge computing, mobile applications (iOS/Android), or situations where you need to embed an HNSW index directly inside another pre-existing C++ database architecture.</p>","tags":["advanced","databases","opensource"]},{"location":"part-4-advanced/advanced-open-source-dbs/#226-pgvector-the-incumbent-giant","title":"22.6 pgvector (The Incumbent Giant)","text":"<p>The most popular vector database in the world is not a vector database at all. It is PostgreSQL, running the <code>pgvector</code> open-source C extension. </p>","tags":["advanced","databases","opensource"]},{"location":"part-4-advanced/advanced-open-source-dbs/#key-innovations_5","title":"Key Innovations","text":"<ol> <li>Absolute ACID Compliance: Native vector databases use soft-deletes and eventual consistency. If you insert a vector into PostgreSQL, it is absolutely, transactionally guaranteed to be there for the next query.</li> <li>Relational Joins: You can filter an embedding search based on a 4-table deep relational <code>JOIN</code> query using standard SQL (<code>SELECT * FROM docs JOIN users ... ORDER BY embedding &lt;-&gt; '[...]' LIMIT 10</code>).</li> <li>HNSW + IVFFlat: <code>pgvector</code> supports both major index types entirely within the PostgreSQL shared buffer system.</li> </ol> <p>Use Case: Any generic business application under 50 million vectors where you already use PostgreSQL. The operational simplicity of not running a dedicated vector database outweighs the slight high-end performance penalties 95% of the time.</p>","tags":["advanced","databases","opensource"]},{"location":"part-4-advanced/advanced-open-source-dbs/#summary-comparison","title":"Summary comparison","text":"System Primary Language Indexing Engine Superpower Best For FAISS C++ IVF-PQ / HNSW GPU Acceleration Offline batch, ML pipelines LanceDB Rust HNSW / IVF Columnar zero-copy Serverless / S3 storage Vespa Java / C++ HNSW / Tensor RT Streaming + ONNX Real-time personalization Vald Go / C++ NGT Kubernetes-native True elastic microservices USearch C++ HNSW Embeddable speed Edge, mobile, or plugin pgvector C HNSW / IVFFlat ACID + SQL Joins Existing Postgres stacks","tags":["advanced","databases","opensource"]},{"location":"part-4-advanced/continual-online-learning/","title":"Chapter 19 \u2014 Continual & Online Learning","text":"","tags":["advanced","embeddings","drift"]},{"location":"part-4-advanced/continual-online-learning/#19-continual-online-learning","title":"19. Continual &amp; Online Learning","text":"<p>Embedding models evolve \u2014 new versions offer better quality but produce vectors incompatible with existing indexes. This chapter covers strategies for managing embedding updates without rebuilding everything.</p>","tags":["advanced","embeddings","drift"]},{"location":"part-4-advanced/continual-online-learning/#191-the-embedding-versioning-problem","title":"19.1 The Embedding Versioning Problem","text":"<p>When you upgrade from model $v_1$ to $v_2$:</p> $$ \\text{cos}(f_{v_1}(\\text{doc}), f_{v_2}(\\text{query})) \\neq \\text{cos}(f_{v_1}(\\text{doc}), f_{v_1}(\\text{query})) $$ <p>Old and new embeddings live in different vector spaces \u2014 distances between them are meaningless.</p>","tags":["advanced","embeddings","drift"]},{"location":"part-4-advanced/continual-online-learning/#migration-strategies","title":"Migration Strategies","text":"Strategy Downtime Cost Quality Full re-embed None (dual-index) High (re-compute all) Best Lazy re-embed None Gradual Mixed quality during transition Compatible training None Training cost Model may be constrained Adapter None One-time training Good but imperfect alignment","tags":["advanced","embeddings","drift"]},{"location":"part-4-advanced/continual-online-learning/#192-compatibility-aware-training","title":"19.2 Compatibility-Aware Training","text":"<p>Train $v_2$ to produce embeddings aligned with $v_1$:</p> $$ \\mathcal{L}_{\\text{compat}} = \\mathcal{L}_{\\text{task}} + \\lambda \\sum_{i} \\|f_{v_2}(x_i) - f_{v_1}(x_i)\\|^2 $$ <p>This backward-compatible training lets new queries work against old embeddings.</p> <p>Matryoshka embeddings help</p> <p>Models trained with Matryoshka Representation Learning produce embeddings where the first $k$ dimensions form a valid $k$-dimensional embedding. This enables dimension-adaptive search and gradual migration.</p>","tags":["advanced","embeddings","drift"]},{"location":"part-4-advanced/continual-online-learning/#193-concept-drift-detection","title":"19.3 Concept Drift Detection","text":"","tags":["advanced","embeddings","drift"]},{"location":"part-4-advanced/continual-online-learning/#monitoring-distribution-shift","title":"Monitoring Distribution Shift","text":"$$ \\text{MMD}^2(\\mathcal{D}_{\\text{old}}, \\mathcal{D}_{\\text{new}}) = \\|\\mu_{\\text{old}} - \\mu_{\\text{new}}\\|^2 + \\text{trace}(\\Sigma_{\\text{old}} + \\Sigma_{\\text{new}} - 2\\Sigma_{\\text{cross}}) $$ <p>When the Maximum Mean Discrepancy (MMD) between recent and historical embedding distributions exceeds a threshold, trigger alerts.</p>","tags":["advanced","embeddings","drift"]},{"location":"part-4-advanced/continual-online-learning/#practical-signals","title":"Practical Signals","text":"Signal Indicates Action Centroid drift &gt; 5% Data distribution changed Retrain IVF centroids Recall drop &gt; 3% Index quality degraded Rebuild graph Query-result distance increase Embedding space diverged Re-embed or fine-tune","tags":["advanced","embeddings","drift"]},{"location":"part-4-advanced/continual-online-learning/#194-online-index-updates","title":"19.4 Online Index Updates","text":"","tags":["advanced","embeddings","drift"]},{"location":"part-4-advanced/continual-online-learning/#incremental-vs-periodic-rebuild","title":"Incremental vs. Periodic Rebuild","text":"<pre><code>flowchart TD\n    A{Update frequency?}\n    A --&gt;|Minutes| B[Incremental: insert into live HNSW]\n    A --&gt;|Daily| C[Periodic: nightly rebuild from scratch]\n    A --&gt;|Weekly| D[Full: rebuild + parameter re-tune]</code></pre>","tags":["advanced","embeddings","drift"]},{"location":"part-4-advanced/continual-online-learning/#shadow-index-pattern","title":"Shadow Index Pattern","text":"<ol> <li>Build a new index in the background</li> <li>Run a recall test against ground truth</li> <li>If quality \u2265 threshold, swap atomically</li> <li>Roll back if quality regresses</li> </ol>","tags":["advanced","embeddings","drift"]},{"location":"part-4-advanced/continual-online-learning/#references","title":"References","text":"<ol> <li>Kusupati, A., et al. (2022). Matryoshka Representation Learning. NeurIPS.</li> <li>Shen, Y., et al. (2020). Backwards-Compatible Representation Learning. CVPR.</li> </ol>","tags":["advanced","embeddings","drift"]},{"location":"part-4-advanced/future-directions/","title":"Chapter 21 \u2014 Future Directions","text":"","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#21-future-directions","title":"21. Future Directions","text":"<p>Vector databases are a rapidly evolving field. This chapter surveys emerging research directions and architectural trends that will shape the next generation of similarity search systems.</p>","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#211-learned-indexes","title":"21.1 Learned Indexes","text":"","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#beyond-hand-crafted-data-structures","title":"Beyond Hand-Crafted Data Structures","text":"<p>Traditional indexes (HNSW, IVF) use fixed algorithms. Learned indexes replace components with neural networks trained on the actual data distribution.</p> $$ \\text{Index}(\\mathbf{q}) = f_\\theta(\\mathbf{q}) \\xrightarrow{\\text{predicts}} \\text{position in sorted data} $$","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#applications-to-vector-search","title":"Applications to Vector Search","text":"Component Traditional Learned Partitioning k-means (IVF) Neural partitioning function Routing Nearest centroid Learned router (which partition to search) Distance L2 / cosine Learned metric (Mahalanobis, etc.) Quantization PQ centroids Anisotropic / rotation-optimized (ScaNN) <p>ScaNN is already a learned index</p> <p>Google's ScaNN learns anisotropic quantization that accounts for how quantization error affects the ranking, not just reconstruction.</p>","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#212-vector-sql-and-declarative-query-languages","title":"21.2 Vector SQL and Declarative Query Languages","text":"","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#the-convergence-of-sql-and-vector-search","title":"The Convergence of SQL and Vector Search","text":"<pre><code>-- Future: first-class vector operations in SQL\nSELECT title, summary,\n       vector_distance(embedding, embed('climate change effects')) AS score\nFROM documents\nWHERE category = 'science'\n  AND publication_date &gt; '2023-01-01'\nORDER BY score ASC\nLIMIT 20;\n</code></pre>","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#emerging-standards","title":"Emerging Standards","text":"System Approach pgvector PostgreSQL extension (<code>&lt;-&gt;</code> operator) DuckDB VSS Extension for analytical workloads SingleStore Native vector type + dot_product() LanceDB SQL-like API over columnar vector storage Turbopuffer Vector-native with SQL filter expressions","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#213-neuromorphic-and-in-memory-computing","title":"21.3 Neuromorphic and In-Memory Computing","text":"","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#processing-in-memory-pim","title":"Processing-in-Memory (PIM)","text":"<p>Move computation to the data instead of moving data to the CPU:</p> <pre><code>flowchart LR\n    subgraph \"Traditional\"\n        MEM1[Memory] --&gt;|\"Data movement&lt;br/&gt;bottleneck\"| CPU1[CPU]\n    end\n    subgraph \"PIM\"\n        MEM2[Memory + Compute] --&gt;|Results only| CPU2[CPU]\n    end</code></pre>","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#analog-computing-for-distance","title":"Analog Computing for Distance","text":"<p>RRAM (Resistive RAM) crossbar arrays can compute matrix-vector products in $O(1)$ time:</p> $$ \\mathbf{y} = W \\mathbf{x} \\quad \\text{computed in a single analog step} $$ <p>This could enable constant-time brute-force search over millions of vectors.</p>","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#optical-computing","title":"Optical Computing","text":"<p>Photonic processors perform Fourier transforms at the speed of light, enabling: - $O(1)$ inner product computation - Massive parallelism (wavelength division multiplexing) - Ultra-low power consumption</p>","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#214-multi-modal-and-unified-databases","title":"21.4 Multi-Modal and Unified Databases","text":"","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#beyond-separate-vector-stores","title":"Beyond Separate Vector Stores","text":"<p>Future databases will natively handle heterogeneous data types in a single system:</p> Data Type Representation Index Text Dense embedding HNSW Images CLIP vectors HNSW Structured Scalar columns B-tree Graphs Node embeddings Graph + HNSW Time series Segment embeddings IVF","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#the-universal-embedding-space","title":"The Universal Embedding Space","text":"<p>Models like ImageBind (Meta) and ONE-PEACE suggest a future where all modalities exist in a single embedding space, enabling truly cross-modal search.</p>","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#215-sustainable-and-efficient-search","title":"21.5 Sustainable and Efficient Search","text":"","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#energy-cost-of-vector-search","title":"Energy Cost of Vector Search","text":"$$ \\text{Energy per query} = \\text{distances computed} \\times \\text{energy per FLOP} $$ <p>At datacenter scale (billions of queries/day), vector search energy consumption is non-trivial. Research directions:</p> <ul> <li>Cascade search: Binary quantization \u2192 SQ4 \u2192 full precision (3-stage)</li> <li>Early termination: Stop when result quality is \"good enough\"</li> <li>Workload-aware scheduling: Batch queries for GPU efficiency</li> <li>Near-data processing: Reduce data movement</li> </ul>","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#216-apache-iceberg-as-a-vector-storage-layer","title":"21.6 Apache Iceberg as a Vector Storage Layer","text":"","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#the-problem-with-proprietary-storage-formats","title":"The Problem with Proprietary Storage Formats","text":"<p>Every vector database today invents its own internal file format for segments, indexes, and metadata. Milvus has its own binary format, Qdrant stores segments differently, and Weaviate has yet another layout. This means your data is locked in. If you want to migrate from Milvus to Qdrant, you must fully export, re-embed, and re-ingest everything\u2014a process that can take days for billion-scale datasets.</p>","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#what-is-apache-iceberg","title":"What is Apache Iceberg?","text":"<p>Apache Iceberg is an open table format originally designed by Netflix for massive analytical data lakes. It sits on top of commodity object storage (S3, GCS, Azure Blob) and provides:</p> <ul> <li>Schema evolution: Add or remove columns (including embedding columns) without rewriting existing data files.</li> <li>Time-travel queries: Query the state of your vector index as it was at any historical snapshot (e.g., \"What did my embeddings look like last Tuesday?\").</li> <li>Partition evolution: Change how your vectors are physically partitioned across files without a full data migration.</li> <li>ACID transactions: Concurrent writers can safely insert and compact segments without corrupting the table.</li> </ul>","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#how-to-use-iceberg-when-building-a-vector-db","title":"How to Use Iceberg When Building a Vector DB","text":"<p>If you are designing a vector database from scratch, instead of inventing a proprietary segment format, you can use Iceberg as your universal storage layer:</p> <ol> <li>Vector Table Schema: Define an Iceberg table with columns like <code>id BIGINT</code>, <code>embedding FIXED_SIZE_BINARY(3072)</code> (for 768 \u00d7 f32), and <code>metadata STRING</code>.</li> <li>Segment Flushing: When your in-memory buffer is full (see Chapter 7 Assignment), instead of writing a custom <code>.bin</code> segment file, write a Parquet data file registered in the Iceberg catalog. Each \"segment\" becomes an Iceberg partition.</li> <li>Compaction as Iceberg Maintenance: The compaction thread from Chapter 9 maps directly to Iceberg's built-in <code>rewrite_data_files</code> operation, which merges small files and removes tombstoned rows.</li> <li>Interoperability: Because Iceberg is an open standard, your users can query the raw vector data directly using Spark, Trino, DuckDB, or Polars without going through your database's proprietary API. This is incredibly powerful for data science workflows.</li> </ol> <pre><code>flowchart LR\n    subgraph YourVectorDB [\"Your Custom Vector DB\"]\n        WAL[Write-Ahead Log] --&gt; Buffer[In-Memory Buffer]\n        Buffer --&gt; |Flush Segment| Iceberg\n        QE[\"Query Engine&lt;br/&gt;HNSW Search\"] --&gt; |Read Vectors| Iceberg\n    end\n\n    subgraph Iceberg [\"Apache Iceberg Table (Open Format)\"]\n        Catalog[(\"Iceberg Catalog&lt;br/&gt;Nessie / Hive\")] \n        S3[(\"Object Storage&lt;br/&gt;S3 / GCS / MinIO\")]\n        Catalog --&gt; S3\n    end\n\n    subgraph External [\"External Analytics (No Lock-In)\"]\n        Spark[Apache Spark]\n        DuckDB[DuckDB]\n        Polars[Polars]\n    end\n\n    Iceberg --&gt; Spark\n    Iceberg --&gt; DuckDB\n    Iceberg --&gt; Polars\n\n    style YourVectorDB fill:#e3f2fd,stroke:#1e88e5\n    style Iceberg fill:#fff3e0,stroke:#f57c00\n    style External fill:#e8f5e9,stroke:#4caf50</code></pre> <p>LanceDB is already pioneering this approach. Its Lance format is conceptually very similar to an Iceberg table optimized for vector workloads. The industry is converging towards open table formats as the universal storage substrate.</p>","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#217-adbc-arrow-database-connectivity-for-vector-interchange","title":"21.7 ADBC (Arrow Database Connectivity) for Vector Interchange","text":"","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#the-problem-with-custom-clients","title":"The Problem with Custom Clients","text":"<p>Every vector database ships its own Python/Rust/Go SDK with its own serialization format. If you want to bulk-load 50 million embeddings from a pandas DataFrame into Milvus, the SDK serializes each row into JSON or Protobuf, sends it over gRPC, and the server deserializes it back into floats. This serialization overhead dominates ingestion time for large datasets\u2014often more time is spent packing/unpacking data than actually building the index.</p>","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#what-is-adbc","title":"What is ADBC?","text":"<p>ADBC (Arrow Database Connectivity) is a new database-agnostic API standard built on top of Apache Arrow, the universal in-memory columnar format. Think of it as a modern replacement for ODBC/JDBC, but designed for columnar, high-throughput analytical workloads instead of row-by-row transactional systems.</p> <p>The critical innovation is zero-copy data exchange. Because Arrow defines a standardized memory layout for arrays of floats, a client can hand a massive Arrow RecordBatch of 1 million embedding vectors directly to the database driver without any serialization or deserialization whatsoever. The database receives a pointer to the exact same memory the client was using.</p>","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#how-to-use-adbc-when-building-a-vector-db","title":"How to Use ADBC When Building a Vector DB","text":"<p>If you are building a vector database from scratch, implementing an ADBC driver gives you instant interoperability with the entire Arrow ecosystem:</p> <ol> <li> <p>Bulk Ingestion via Arrow Flight: Instead of accepting vectors via a slow REST API one-at-a-time, expose an Arrow Flight endpoint. The client sends a stream of Arrow RecordBatches containing millions of float arrays. Your database receives them as zero-copy column pointers, dramatically accelerating batch imports.</p> </li> <li> <p>Native DataFrame Integration: Data scientists working in Python can use <code>pyarrow</code> or <code>polars</code> DataFrames to prepare embeddings, then push them directly into your database via the ADBC driver\u2014no JSON conversion, no row-by-row SDK calls.</p> </li> <li> <p>Cross-Database Portability: If your database speaks ADBC, a user can trivially pipe data between your system and DuckDB, Postgres, Snowflake, or any other ADBC-compatible system using a universal API.</p> </li> </ol> <pre><code># Future: Ingesting vectors via ADBC (zero-copy, no serialization)\nimport adbc_driver_manager\nimport pyarrow as pa\n\n# 1 million 768-D embeddings, already in Arrow format\nembeddings = pa.table({\n    \"id\": pa.array(range(1_000_000)),\n    \"vector\": pa.FixedSizeListArray.from_arrays(\n        pa.array(all_floats, type=pa.float32()), 768\n    ),\n    \"text\": pa.array(all_texts),\n})\n\n# Zero-copy bulk ingest via ADBC\nwith adbc_driver_manager.connect(driver=\"your_vectordb\") as conn:\n    with conn.cursor() as cur:\n        cur.adbc_ingest(\"embeddings_table\", embeddings, mode=\"append\")\n        # Millions of vectors transmitted with ZERO serialization overhead\n</code></pre>","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#the-convergence-iceberg-adbc-vector-search","title":"The Convergence: Iceberg + ADBC + Vector Search","text":"<p>The most powerful architectural vision for a next-generation vector database combines all three:</p> Layer Technology Role Client API ADBC / Arrow Flight Zero-copy bulk ingestion and query results Storage Format Apache Iceberg + Parquet Open, portable, ACID-compliant segment storage Compute Engine Custom HNSW/IVF C++ kernel High-performance in-memory graph search <p>This architecture means your vector database is never a data silo. Users can ingest terabytes of embeddings at wire speed, query them via your optimized HNSW engine, and simultaneously analyze the raw data with Spark or DuckDB\u2014all without ever copying or converting a single byte.</p>","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#218-open-research-questions","title":"21.8 Open Research Questions","text":"Question Why It Matters Can we build ANN indexes with provable guarantees matching LSH but practical like HNSW? Theory-practice gap How to efficiently handle 10K+ dimension embeddings from frontier models? Curse of dimensionality Can vector DBs natively support continuous learning without full re-indexing? Operational cost How to achieve sub-microsecond vector search for edge devices? IoT and mobile Can we verify search results without revealing the database? Zero-knowledge proofs Can Iceberg/Lance become the universal open storage format for embeddings? Vendor lock-in elimination Will ADBC displace proprietary vector DB SDKs for bulk data movement? Ingestion performance","tags":["advanced","future","research"]},{"location":"part-4-advanced/future-directions/#references","title":"References","text":"<ol> <li>Kraska, T., et al. (2018). The Case for Learned Index Structures. SIGMOD.</li> <li>Guo, R., et al. (2020). Accelerating Large-Scale Inference with Anisotropic Vector Quantization (ScaNN). ICML.</li> <li>Sebastian, Y., et al. (2023). Analog In-Memory Computing for Neural Network Acceleration. Nature Electronics.</li> <li>Apache Iceberg Documentation. Table Spec v2. https://iceberg.apache.org/spec/</li> <li>Apache Arrow ADBC Documentation. https://arrow.apache.org/adbc/</li> </ol>","tags":["advanced","future","research"]},{"location":"part-4-advanced/in-database-ml-and-feature-stores/","title":"Chapter 24 \u2014 In-Database ML and Feature Stores","text":"","tags":["advanced","machine-learning","architecture","postgresml","feature-stores"]},{"location":"part-4-advanced/in-database-ml-and-feature-stores/#24-in-database-ml-and-feature-stores","title":"24. In-Database ML and Feature Stores","text":"<p>Traditionally, data architecture forces a strict separation between \"Storage\" and \"Compute\". Data sits in a database (like PostgreSQL or Weaviate), and Machine Learning happens in a separate Python process (like a PyTorch microservice). </p> <p>If you want to re-rank search results or classify a user, your Python microservice must execute a database query, pull 1,000 heavy rows over the network interface, deserialize them into a pandas DataFrame, run the ML model, and throw the data away. </p> <p>This Network I/O bottleneck dominates the latency of AI applications. This chapter covers the emerging architectural patterns designed to eliminate this bottleneck: pushing ML into the database, and orchestrating these pipelines via Feature Stores.</p>","tags":["advanced","machine-learning","architecture","postgresml","feature-stores"]},{"location":"part-4-advanced/in-database-ml-and-feature-stores/#241-in-database-machine-learning","title":"24.1 In-Database Machine Learning","text":"<p>Instead of pulling massive amounts of data to the compute, In-Database ML pushes the compute directly to the data. By running neural networks and aggregations deep inside the database kernel, systems eliminate network I/O, serialization overhead, and microservice complexity.</p>","tags":["advanced","machine-learning","architecture","postgresml","feature-stores"]},{"location":"part-4-advanced/in-database-ml-and-feature-stores/#postgresml","title":"PostgresML","text":"<p>PostgresML is an architecture that perfectly exemplifies this trend. Built as an extension on top of PostgreSQL, it fundamentally alters what a database is capable of.</p> <p>Instead of writing a Python microservice to generate user embeddings, you load massive models (like XGBoost, LightGBM, or Hugging Face Transformers) directly into PostgreSQL's shared memory buffers.</p> <pre><code>-- Generate embeddings dynamically INSIDE the SQL query engine\nSELECT \n    title,\n    pgml.embed('intfloat/e5-small-v2', content) AS content_embedding\nFROM blog_posts\nWHERE published_at &gt; '2024-01-01';\n</code></pre> <p>Why this matters: 1. Zero Data Movement: The text strings never leave the database RAM. The transformer model executes locally on the database CPU/GPU, instantly outputting the <code>float32[]</code> array right next to the row. 2. Transactional ML: A trigger can be configured so that whenever a row is <code>INSERT</code>ed, the database automatically invokes the model internally to generate the embedding, guaranteeing the vector index is never out of sync with the raw text.</p>","tags":["advanced","machine-learning","architecture","postgresml","feature-stores"]},{"location":"part-4-advanced/in-database-ml-and-feature-stores/#featurebase-and-specialized-bitmaps","title":"FeatureBase and Specialized Bitmaps","text":"<p>While PostgresML handles deep learning, systems like FeatureBase tackle the analytics and feature-generation side of ML using radically different mathematics.</p> <p>If you want to train an ML model on user behavior, you often need to calculate massive aggregations (e.g., \"Find all users aged 25-30 who bought an iPhone in the last hour\").  FeatureBase uses Roaring Bitmaps, B-trees, and internally bit-sliced integer representation to execute these aggregations at millions-of-rows-per-millisecond speeds. ML models (like linear regression or clustering) can be compiled to execute directly against these compressed internal bitmaps without ever extracting the data into a standard flat Python array.</p>","tags":["advanced","machine-learning","architecture","postgresml","feature-stores"]},{"location":"part-4-advanced/in-database-ml-and-feature-stores/#242-orchestration-and-feature-stores-for-ml","title":"24.2 Orchestration and Feature Stores for ML","text":"<p>If you begin pushing compute into various databases (Vectors in Qdrant, ML in PostgresML, Analytics in Snowflake), how do data scientists keep track of the thousands of \"Features\" necessary to power Retrieval-Augmented Generation (RAG) and recommendation systems?</p> <p>Enter the Feature Store.</p> <pre><code>flowchart TD\n    subgraph Data Sources\n        S3[(Data Lake / S3)]\n        Kafka{{Streaming / Kafka}}\n    end\n\n    subgraph Feature Computation\n        Spark[Spark / Flink]\n        SQL[dbt / SQL Engines]\n    end\n\n    subgraph Virtual Feature Store Orchestration\n        Registry[\"Feature Registry&lt;br/&gt;(Featureform)\"]\n    end\n\n    subgraph Serving Layers\n        Online[(\"Online Store&lt;br/&gt;Redis / Vector DB\")]\n        Offline[(\"Offline Store&lt;br/&gt;Iceberg / Parquet\")]\n    end\n\n    subgraph ML Pipeline\n        Train[Model Training]\n        Infer[Real-Time RAG / Inference]\n    end\n\n    S3 --&gt; Spark\n    Kafka --&gt; Spark\n    Spark --&gt;|Define Features| Registry\n\n    Registry --&gt;|Batch sync| Offline\n    Registry --&gt;|Sub-ms cache sync| Online\n\n    Offline --&gt;|Fetch history| Train\n    Online --&gt;|Fetch current state| Infer\n\n    style Registry fill:#ffe0b2,stroke:#f57c00\n    style Online fill:#c8e6c9,stroke:#388e3c\n    style Offline fill:#bbdefb,stroke:#1976d2</code></pre>","tags":["advanced","machine-learning","architecture","postgresml","feature-stores"]},{"location":"part-4-advanced/in-database-ml-and-feature-stores/#virtual-feature-stores-featureform","title":"Virtual Feature Stores (Featureform)","text":"<p>The original feature stores (like Uber's Michelangelo) were monolithic databases in themselves. Modern architecture favors Virtual Feature Stores like Featureform. </p> <p>A virtual feature store acts like \"Terraform for ML features.\" It is declarative. You don't store your vectors inside Featureform; instead, you write configurations that tell the system: \"Calculate this embedding in PostgresML, cache the vector in Qdrant for real-time search, and store the historical logs of the embeddings in an Iceberg table on S3 for offline training.\"</p>","tags":["advanced","machine-learning","architecture","postgresml","feature-stores"]},{"location":"part-4-advanced/in-database-ml-and-feature-stores/#streaming-vs-batch-unification","title":"Streaming vs. Batch Unification","text":"<p>The core existential problem a Feature Store solves is Offline/Online Skew.</p> <ul> <li>Offline Store (Batch): Data scientists need historically accurate logs of exactly what an embedding or feature looked like 6 months ago to properly train a model without data leakage. </li> <li>Online Store (Streaming): Production RAG systems need ultra-fast, sub-millisecond access to the absolute most current version of a vector to serve a live user query.</li> </ul> <p>Feature Stores conceptually treat data streams (via Kafka or Pulsar) as immutable logs. They fan the data out simultaneously: pushing the fresh updates to the fast Vector DB (Online), while appending the historical record to the Data Lake (Offline), ensuring both production servers and data scientists are looking at the exact same mathematical truth.</p>","tags":["advanced","machine-learning","architecture","postgresml","feature-stores"]},{"location":"part-4-advanced/in-database-ml-and-feature-stores/#conclusion","title":"Conclusion","text":"<p>As the AI ecosystem matures, the boundaries between the \"Vector Database\", the \"Relational Database\", and the \"Machine Learning Model\" will continue to blur. Architectures that minimize the physical distance between the stored bytes and the neural network will fundamentally dominate the next decade of performance engineering.</p>","tags":["advanced","machine-learning","architecture","postgresml","feature-stores"]},{"location":"part-4-advanced/in-database-ml-and-feature-stores/#references","title":"References","text":"<ol> <li>PostgresML Documentation. In-Database Machine Learning. https://postgresml.org/docs/</li> <li>Featureform Documentation. The Virtual Feature Store. https://docs.featureform.com/</li> <li>Roaring Bitmaps. Consistently faster and smaller compressed bitmaps. https://roaringbitmap.org/</li> </ol>","tags":["advanced","machine-learning","architecture","postgresml","feature-stores"]},{"location":"part-4-advanced/privacy-preserving-search/","title":"Chapter 18 \u2014 Privacy-Preserving Vector Search","text":"","tags":["advanced","privacy","encryption"]},{"location":"part-4-advanced/privacy-preserving-search/#18-privacy-preserving-vector-search","title":"18. Privacy-Preserving Vector Search","text":"<p>Embeddings leak information \u2014 a user's query embedding reveals their intent, and stored embeddings can be inverted to reconstruct original content. This chapter covers cryptographic and systems-level techniques for private vector search.</p>","tags":["advanced","privacy","encryption"]},{"location":"part-4-advanced/privacy-preserving-search/#181-why-embeddings-are-sensitive","title":"18.1 Why Embeddings Are Sensitive","text":"<p>Embedding inversion attacks</p> <p>Recent work shows that text embeddings can be inverted to reconstruct the original input with high fidelity. Storing plaintext embeddings is equivalent to storing the original data.</p>","tags":["advanced","privacy","encryption"]},{"location":"part-4-advanced/privacy-preserving-search/#threat-model","title":"Threat Model","text":"Threat Description Mitigation Curious server DB operator reads stored embeddings Encryption at rest Query sniffing Attacker observes query embeddings Encrypted queries Membership inference Determine if a specific document is in the DB Differential privacy Embedding inversion Reconstruct original text from embedding Dimensionality reduction, noise","tags":["advanced","privacy","encryption"]},{"location":"part-4-advanced/privacy-preserving-search/#182-homomorphic-encryption-he","title":"18.2 Homomorphic Encryption (HE)","text":"","tags":["advanced","privacy","encryption"]},{"location":"part-4-advanced/privacy-preserving-search/#concept","title":"Concept","text":"<p>Compute distances on encrypted vectors without decrypting:</p> $$ d(\\text{Enc}(\\mathbf{q}), \\text{Enc}(\\mathbf{x})) = \\text{Enc}(d(\\mathbf{q}, \\mathbf{x})) $$","tags":["advanced","privacy","encryption"]},{"location":"part-4-advanced/privacy-preserving-search/#practical-limitations","title":"Practical Limitations","text":"Aspect Plaintext HE (BFV/CKKS) L2 distance ~1 ns ~10\u2013100 ms Slowdown 1\u00d7 $10^7$\u2013$10^8$\u00d7 Vector packing N/A Batch vectors into single ciphertext <p>CKKS scheme for approximate arithmetic</p> <p>The CKKS scheme supports approximate fixed-point arithmetic on encrypted data \u2014 suitable for distance computations that don't need exact results.</p>","tags":["advanced","privacy","encryption"]},{"location":"part-4-advanced/privacy-preserving-search/#183-secure-multi-party-computation-mpc","title":"18.3 Secure Multi-Party Computation (MPC)","text":"<p>Split the computation between two non-colluding parties:</p> <ul> <li>Client holds the query vector</li> <li>Server holds the database</li> </ul> <p>Neither party learns the other's inputs. The client only learns the top-$k$ result IDs.</p>","tags":["advanced","privacy","encryption"]},{"location":"part-4-advanced/privacy-preserving-search/#secret-sharing","title":"Secret Sharing","text":"<p>Split each vector element into two shares:</p> $$ x = x_1 + x_2, \\quad x_1 \\text{ held by client}, \\quad x_2 \\text{ held by server} $$ <p>Distance computation requires interactive protocols (oblivious transfer), adding network round trips.</p>","tags":["advanced","privacy","encryption"]},{"location":"part-4-advanced/privacy-preserving-search/#184-differential-privacy","title":"18.4 Differential Privacy","text":"<p>Add calibrated noise to protect individual records:</p> $$ \\tilde{\\mathbf{x}} = \\mathbf{x} + \\mathcal{N}(0, \\sigma^2 I_d) $$ <p>where $\\sigma$ is calibrated to provide $(\\varepsilon, \\delta)$-differential privacy:</p> $$ \\sigma = \\frac{\\Delta_2 \\sqrt{2 \\ln(1.25/\\delta)}}{\\varepsilon} $$ $\\varepsilon$ Privacy level Recall impact 0.1 Very strong 15\u201330% recall drop 1.0 Strong 5\u201310% recall drop 10.0 Moderate &lt; 2% recall drop","tags":["advanced","privacy","encryption"]},{"location":"part-4-advanced/privacy-preserving-search/#185-trusted-execution-environments-tees","title":"18.5 Trusted Execution Environments (TEEs)","text":"<p>Run vector search inside a hardware enclave (Intel SGX/TDX, ARM CCV):</p> <pre><code>flowchart LR\n    Client --&gt;|Encrypted query| TEE[TEE Enclave]\n    TEE --&gt;|Encrypted results| Client\n    TEE --&gt; EMem[Encrypted Memory]\n    Attacker -.-&gt;|Cannot read| EMem</code></pre> Aspect Advantage Limitation Security Hardware-enforced isolation Side-channel attacks possible Performance Near-native (5\u201320% overhead) Limited enclave memory (256 MB SGX) Trust No trust in cloud operator needed Trust in CPU manufacturer","tags":["advanced","privacy","encryption"]},{"location":"part-4-advanced/privacy-preserving-search/#references","title":"References","text":"<ol> <li>Morris, J. X., et al. (2023). Text Embeddings Reveal (Almost) As Much As Text. EMNLP.</li> <li>Chen, H., et al. (2022). SEAL: Microsoft's Homomorphic Encryption Library.</li> <li>Dwork, C. (2006). Differential Privacy. ICALP.</li> </ol>","tags":["advanced","privacy","encryption"]},{"location":"part-4-advanced/real-world-case-studies/","title":"Chapter 23 \u2014 Real-World Case Studies","text":"","tags":["advanced","case-studies"]},{"location":"part-4-advanced/real-world-case-studies/#23-real-world-case-studies","title":"23. Real-World Case Studies","text":"<p>Vector databases are not just theoretical math exercises; they power the most critical features of the modern internet. This chapter profiles how three massive tech companies use vector search in production, and provides code snippets imitating their strategies so you can experiment with the concepts natively.</p>","tags":["advanced","case-studies"]},{"location":"part-4-advanced/real-world-case-studies/#231-spotify-real-time-audio-recommendations","title":"23.1 Spotify: Real-Time Audio Recommendations","text":"","tags":["advanced","case-studies"]},{"location":"part-4-advanced/real-world-case-studies/#the-problem","title":"The Problem","text":"<p>Spotify has over 100 million tracks. When a user finishes listening to a heavy metal song, Spotify must instantly recommend the next song to play. They cannot use metadata alone (e.g., matching the genre tag <code>metal</code>); they want to recommend songs with similar acoustic profiles, tempos, and \"vibes\".</p>","tags":["advanced","case-studies"]},{"location":"part-4-advanced/real-world-case-studies/#the-solution-annoy-audio-embeddings","title":"The Solution: Annoy &amp; Audio Embeddings","text":"<p>Spotify was one of the early pioneers of semantic vector search. They convert raw audio waveforms into dense embeddings via neural networks. To search the 100-million track database in under 50 milliseconds, they open-sourced a library called Annoy (Approximate Nearest Neighbors Oh Yeah).</p> <p>Annoy uses Random Projection Trees (a variant of the KD-Trees discussed in Chapter 2) rather than HNSW. It recursively splits the data using random hyperplanes, creating a forest of trees that are heavily optimized for memory-mapped read-only sharing across multiple processes.</p>","tags":["advanced","case-studies"]},{"location":"part-4-advanced/real-world-case-studies/#experiment-random-projection-trees-in-c","title":"Experiment: Random Projection Trees in C++","text":"<p>Here is an experimental snippet demonstrating how a single Split Node in an Annoy-style Random Projection Tree is structured. Try compiling this and experimenting with how the <code>margin</code> determines which branch a vector takes.</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;numeric&gt;\n\n// An Annoy-style Random Projection Node\nstruct Node {\n    std::vector&lt;float&gt; split_plane_normal;\n    float split_bias;\n    int left_child_index;\n    int right_child_index;\n};\n\n// Computes dot product to determine side of the hyperplane\nfloat get_margin(const Node&amp; node, const std::vector&lt;float&gt;&amp; item) {\n    float margin = node.split_bias;\n    for (size_t i = 0; i &lt; item.size(); ++i) {\n        margin += node.split_plane_normal[i] * item[i];\n    }\n    return margin;\n}\n\nint route_to_child(const Node&amp; node, const std::vector&lt;float&gt;&amp; query) {\n    float margin = get_margin(node, query);\n    // If margin is positive, go left. If negative, go right.\n    if (margin &gt; 0) return node.left_child_index;\n    return node.right_child_index;\n}\n\nint main() {\n    // 3-dimensional toy embedding of an audio track\n    std::vector&lt;float&gt; audio_query = {0.8f, -0.4f, 1.2f}; \n\n    // A predefined split node\n    Node root = {{1.0f, -1.0f, 0.5f}, 0.0f, 1, 2};\n\n    std::cout &lt;&lt; \"Routing audio track to child node ID: \" \n              &lt;&lt; route_to_child(root, audio_query) &lt;&lt; std::endl;\n    // Computes: (1.0*0.8) + (-1.0*-0.4) + (0.5*1.2) = 0.8 + 0.4 + 0.6 = 1.8. \n    // Margin is positive, returns left child (1).\n    return 0;\n}\n</code></pre>","tags":["advanced","case-studies"]},{"location":"part-4-advanced/real-world-case-studies/#232-pinterest-visual-search-shop-the-look","title":"23.2 Pinterest: Visual Search &amp; \"Shop the Look\"","text":"","tags":["advanced","case-studies"]},{"location":"part-4-advanced/real-world-case-studies/#the-problem_1","title":"The Problem","text":"<p>When a Pinterest user sees a photo of a living room and clicks on a specific armchair in the picture, Pinterest must instantly scan billions of products across the internet to find visually similar armchairs to sell to the user. Keywords are useless here; the user doesn't know the designer's name or color code.</p>","tags":["advanced","case-studies"]},{"location":"part-4-advanced/real-world-case-studies/#the-solution-multi-modal-hnsw","title":"The Solution: Multi-Modal HNSW","text":"<p>Pinterest generates embeddings of images using Convolutional Neural Networks (CNNs) and transformer models. They heavily rely on HNSW indexes for search.  Crucially, Pinterest uses Multi-Modal embeddings. If a user types \"mid-century leather chair\" (text), the text is converted into the exact same embedding space as the images of the chairs. The database doesn't care if the query is text or a cropped image; it's just a 256-dimensional float vector.</p>","tags":["advanced","case-studies"]},{"location":"part-4-advanced/real-world-case-studies/#experiment-hnsw-graph-initialization-in-rust","title":"Experiment: HNSW Graph Initialization in Rust","text":"<p>Here is an experimental snippet imitating the core layer structure of Pinterest's HNSW implementation in Rust. Notice how vectors are assigned a maximum layer based on a probability distribution.</p> <pre><code>use rand::Rng;\n\nconst M: usize = 16;       // Max connections per node\nconst M_MAX: usize = 32;   // Max connections at Layer 0\n\nstruct HnswNode {\n    id: usize,\n    vector: Vec&lt;f32&gt;,\n    max_layer: usize,\n    // connections[layer][neighbour_index]\n    connections: Vec&lt;Vec&lt;usize&gt;&gt;, \n}\n\nfn assign_random_layer(mult: f64) -&gt; usize {\n    let mut rng = rand::thread_rng();\n    let uniform: f64 = rng.gen_range(0.0001..1.0);\n    // Exponential decay probability: \n    // Almost everyone gets layer 0. Very few get layer 4.\n    let layer = (-uniform.ln() * mult).floor() as usize;\n    layer\n}\n\nfn main() {\n    // Multiplier often set to 1 / ln(M)\n    let m_l = 1.0 / (16.0_f64).ln(); \n    let node_layer = assign_random_layer(m_l);\n\n    let mut node = HnswNode {\n        id: 1042,\n        vector: vec![0.11, -0.9, 0.88], // \"leather chair\" embedding\n        max_layer: node_layer,\n        connections: vec![Vec::new(); node_layer + 1],\n    };\n\n    println!(\"Node {} injected at maximum layer: {}\", node.id, node.max_layer);\n}\n</code></pre>","tags":["advanced","case-studies"]},{"location":"part-4-advanced/real-world-case-studies/#233-openai-large-scale-rag-tool-retrieval","title":"23.3 OpenAI: Large-Scale RAG Tool Retrieval","text":"","tags":["advanced","case-studies"]},{"location":"part-4-advanced/real-world-case-studies/#the-problem_2","title":"The Problem","text":"<p>When ChatGPT searches the web or accesses internal enterprise documents, it cannot stuff millions of PDF pages into its context window. It must isolate the 10 most highly relevant paragraphs to read before generating an answer.</p>","tags":["advanced","case-studies"]},{"location":"part-4-advanced/real-world-case-studies/#the-solution-chunking-and-the-rag-pipeline","title":"The Solution: Chunking and the RAG Pipeline","text":"<p>OpenAI relies heavily on Retrieval-Augmented Generation (RAG). They do not embed entire books at once. Instead, they use a \"Chunking\" strategy: 1. Split the massive document into 300-token chunks. 2. Embed each chunk using the <code>text-embedding-3-small</code> model. 3. Store the chunk embeddings in a vector database (like Pinecone or Milvus). 4. When the user asks a question, embed the question, find the Top-5 closest chunks, and inject those chunks seamlessly into the LLM prompt.</p>","tags":["advanced","case-studies"]},{"location":"part-4-advanced/real-world-case-studies/#experiment-rag-semantic-chunk-scorer-in-c","title":"Experiment: RAG Semantic Chunk Scorer in C++","text":"<p>Here is an experimental snippet representing the final step of a RAG pipeline: after retrieving chunks from the Vector DB, we must rank them by relevance (cosine similarity) before passing them to the LLM. Try adding new chunks to see how the LLM decides which paragraphs to \"read\".</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\n#include &lt;algorithm&gt;\n\n// Calculate Cosine Similarity\nfloat cosine_sim(const std::vector&lt;float&gt;&amp; a, const std::vector&lt;float&gt;&amp; b) {\n    float dot = 0.0f, normA = 0.0f, normB = 0.0f;\n    for(size_t i = 0; i &lt; a.size(); ++i) {\n        dot += a[i] * b[i];\n        normA += a[i] * a[i];\n        normB += b[i] * b[i];\n    }\n    return dot / (std::sqrt(normA) * std::sqrt(normB));\n}\n\nstruct DocumentChunk {\n    std::string text;\n    std::vector&lt;float&gt; embedding;\n    float relevance_score = 0.0f;\n};\n\nint main() {\n    // User query: \"How do black holes form?\"\n    std::vector&lt;float&gt; query_emb = {0.9f, -0.2f, 0.4f, 0.8f};\n\n    // Chunks retrieved from the Vector DB\n    std::vector&lt;DocumentChunk&gt; retrieved_chunks = {\n        {\"Astronomers observe supernova explosions...\", {0.8f, -0.1f, 0.3f, 0.9f}},\n        {\"A recipe for black forest cake...\",           {-0.5f, 0.8f, 0.1f, -0.2f}},\n        {\"Gravity condenses a dying star core...\",      {0.9f, -0.3f, 0.5f, 0.7f}}\n    };\n\n    // Re-rank for the LLM Context Window\n    for (auto&amp; chunk : retrieved_chunks) {\n        chunk.relevance_score = cosine_sim(query_emb, chunk.embedding);\n    }\n\n    std::sort(retrieved_chunks.begin(), retrieved_chunks.end(), \n        [](const DocumentChunk&amp; a, const DocumentChunk&amp; b) {\n            return a.relevance_score &gt; b.relevance_score;\n        }\n    );\n\n    std::cout &lt;&lt; \"--- LLM Context Window Injection ---\" &lt;&lt; std::endl;\n    for (const auto&amp; chunk : retrieved_chunks) {\n        std::cout &lt;&lt; \"Score [\" &lt;&lt; chunk.relevance_score &lt;&lt; \"] : \" &lt;&lt; chunk.text &lt;&lt; std::endl;\n    }\n\n    return 0;\n}\n</code></pre>","tags":["advanced","case-studies"]},{"location":"part-4-advanced/vector-db-genai-agents/","title":"Chapter 20 \u2014 Vector Databases for Gen-AI Agents","text":"","tags":["advanced","rag","agents","genai"]},{"location":"part-4-advanced/vector-db-genai-agents/#20-vector-databases-for-gen-ai-agents","title":"20. Vector Databases for Gen-AI Agents","text":"<p>Vector databases are the memory backbone of LLM-powered applications. This chapter covers RAG, agentic memory, advanced retrieval patterns, and evaluation.</p>","tags":["advanced","rag","agents","genai"]},{"location":"part-4-advanced/vector-db-genai-agents/#201-rag-architecture","title":"20.1 RAG Architecture","text":"","tags":["advanced","rag","agents","genai"]},{"location":"part-4-advanced/vector-db-genai-agents/#basic-rag-pipeline","title":"Basic RAG Pipeline","text":"<pre><code>flowchart LR\n    Q[User Query] --&gt; E[Embed Query]\n    E --&gt; VDB[(Vector DB)]\n    VDB --&gt; C[Retrieved Chunks]\n    C --&gt; P[Prompt: Context + Query]\n    P --&gt; LLM[LLM]\n    LLM --&gt; A[Answer]</code></pre>","tags":["advanced","rag","agents","genai"]},{"location":"part-4-advanced/vector-db-genai-agents/#naive-vs-production-rag","title":"Naive vs. Production RAG","text":"Aspect Naive Production Retrieval Single vector search Hybrid (BM25 + vector) + re-rank Chunking Fixed 512 tokens Semantic with overlap Context Dump all chunks Select + compress relevant chunks Evaluation Manual inspection Automated faithfulness + relevance","tags":["advanced","rag","agents","genai"]},{"location":"part-4-advanced/vector-db-genai-agents/#202-advanced-retrieval-patterns","title":"20.2 Advanced Retrieval Patterns","text":"","tags":["advanced","rag","agents","genai"]},{"location":"part-4-advanced/vector-db-genai-agents/#hyde-hypothetical-document-embeddings","title":"HyDE (Hypothetical Document Embeddings)","text":"<p>Instead of embedding the query, embed a hypothetical answer:</p> <ol> <li>LLM generates a hypothetical answer to the query</li> <li>Embed the hypothetical answer</li> <li>Search the vector DB with that embedding</li> </ol> $$ \\text{HyDE}: q \\xrightarrow{\\text{LLM}} \\hat{d} \\xrightarrow{\\text{embed}} \\mathbf{v}_{\\hat{d}} \\xrightarrow{\\text{search}} \\text{results} $$ <p>Works better than query embedding because answers are more similar to stored documents than questions are.</p>","tags":["advanced","rag","agents","genai"]},{"location":"part-4-advanced/vector-db-genai-agents/#multi-step-retrieval","title":"Multi-Step Retrieval","text":"<pre><code>flowchart TD\n    Q[Query] --&gt; R1[Retrieve initial docs]\n    R1 --&gt; LLM1[LLM: refine query]\n    LLM1 --&gt; R2[Retrieve with refined query]\n    R2 --&gt; LLM2[LLM: generate answer]</code></pre>","tags":["advanced","rag","agents","genai"]},{"location":"part-4-advanced/vector-db-genai-agents/#parent-child-retrieval","title":"Parent-Child Retrieval","text":"<ul> <li>Index: Embed small chunks (256 tokens) for precise matching</li> <li>Return: The parent chunk (1024+ tokens) for richer context</li> </ul>","tags":["advanced","rag","agents","genai"]},{"location":"part-4-advanced/vector-db-genai-agents/#203-agentic-memory","title":"20.3 Agentic Memory","text":"","tags":["advanced","rag","agents","genai"]},{"location":"part-4-advanced/vector-db-genai-agents/#short-term-vs-long-term-memory","title":"Short-Term vs. Long-Term Memory","text":"Memory Type Stored in Lifetime Example Working memory LLM context window Single turn Current conversation Short-term memory Vector DB (session-scoped) Conversation Chat history embeddings Long-term memory Vector DB (persistent) Permanent User preferences, facts Episodic memory Vector DB + metadata Permanent Past interactions","tags":["advanced","rag","agents","genai"]},{"location":"part-4-advanced/vector-db-genai-agents/#memory-architecture-for-agents","title":"Memory Architecture for Agents","text":"<pre><code>flowchart TB\n    Agent --&gt; WM[\"Working Memory&lt;br/&gt;Context Window\"]\n    Agent --&gt; STM[\"Short-Term&lt;br/&gt;Session Vector DB\"]\n    Agent --&gt; LTM[\"Long-Term&lt;br/&gt;Persistent Vector DB\"]\n    Agent --&gt; Tools[External Tools]\n    STM --&gt; LTM</code></pre>","tags":["advanced","rag","agents","genai"]},{"location":"part-4-advanced/vector-db-genai-agents/#204-evaluation-frameworks","title":"20.4 Evaluation Frameworks","text":"","tags":["advanced","rag","agents","genai"]},{"location":"part-4-advanced/vector-db-genai-agents/#rag-evaluation-metrics","title":"RAG Evaluation Metrics","text":"Metric Measures Formula Faithfulness Is the answer grounded in retrieved context? $\\frac{\\text{claims supported by context}}{\\text{total claims}}$ Answer Relevancy Does the answer address the query? $\\text{cos}(\\text{embed}(q), \\text{embed}(a))$ Context Precision Are retrieved chunks relevant? $\\text{precision@}k$ with LLM-judged relevance Context Recall Are all needed chunks retrieved? $\\frac{\\text{relevant retrieved}}{\\text{total relevant}}$","tags":["advanced","rag","agents","genai"]},{"location":"part-4-advanced/vector-db-genai-agents/#llm-as-judge","title":"LLM-as-Judge","text":"<p>Use a strong LLM to evaluate retrieval and generation quality:</p> <pre><code>Given the question: {question}\nAnd the retrieved context: {context}\nAnd the generated answer: {answer}\n\nRate faithfulness (1-5): Is every claim in the answer\nsupported by the context?\n</code></pre>","tags":["advanced","rag","agents","genai"]},{"location":"part-4-advanced/vector-db-genai-agents/#frameworks","title":"Frameworks","text":"Framework Type Key Feature RAGAS Python library Automatic metrics (faithfulness, relevancy) LangSmith Platform Tracing + evaluation DeepEval Python library Unit tests for LLM outputs TruLens Python library Feedback functions","tags":["advanced","rag","agents","genai"]},{"location":"part-4-advanced/vector-db-genai-agents/#205-context-window-management","title":"20.5 Context Window Management","text":"<p>With growing context windows (128K\u20131M tokens), do we still need RAG?</p> $$ \\text{Cost}_{\\text{full context}} = O(n^2) \\quad \\text{vs.} \\quad \\text{Cost}_{\\text{RAG}} = O(k) + O(k^2) $$ Long Context RAG Latency High (process all tokens) Low (retrieve k chunks) Cost $$$$ (pay per token) $ (vector search is cheap) Accuracy \"Lost in the middle\" problem Focused on relevant chunks Scale Limited by context window Unlimited","tags":["advanced","rag","agents","genai"]},{"location":"part-4-advanced/vector-db-genai-agents/#references","title":"References","text":"<ol> <li>Lewis, P., et al. (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. NeurIPS.</li> <li>Gao, L., et al. (2023). Precise Zero-Shot Dense Retrieval without Relevance Labels (HyDE). ACL.</li> <li>Es, S., et al. (2023). RAGAS: Automated Evaluation of Retrieval Augmented Generation. arXiv.</li> </ol>","tags":["advanced","rag","agents","genai"]}]}